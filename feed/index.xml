<?xml version="1.0" encoding="UTF-8"?><rss version="2.0" xmlns:content="http://purl.org/rss/1.0/modules/content/"><channel><title>Noncombatant</title><link>https://noncombatant.org/feed/</link><description>A blog about software engineering, music, and feelings</description><managingEditor>chris@noncombatant.org (Chris Palmer)</managingEditor><pubDate>Sat, 24 Jan 2004 00:00:00 +0000</pubDate><lastBuildDate>Sun, 09 Feb 2025 20:53:11 -0800</lastBuildDate><item><title>Florilegium</title><link>https://noncombatant.org/2024/12/18/florilegium/index.content</link><description>&lt;h1>&lt;i>Florilegium&lt;/i>&lt;/h1>

&lt;p>&lt;time>18 December 2024&lt;/time>&lt;/p>

&lt;figure>
 &lt;a href="https://telltaleshimmer.bandcamp.com/album/florilegium">
 &lt;img src="front-cover-1000.jpg" width="500" height="500"
 alt="The front cover of Florilegium, showing a picture of the Pacific Ocean near Monterey Bay, California" />
 &lt;/a>
 &lt;figcaption>Ye olde fronte cover.&lt;/figcaption>
&lt;/figure>

&lt;p>About 11 months after I thought for sure we’d be done, my band &lt;a
 href="https://telltaleshimmer.com/">Telltale
 Shimmer&lt;/a> released our new EP, &lt;a
 href="https://telltaleshimmer.bandcamp.com/album/florilegium">&lt;i>Florilegium&lt;/i>&lt;/a>!
 I’m pretty happy with how it turned out. I think it’s a decent
 representation of what I was trying to achieve,
 which I call “&lt;a
 href="https://en.wikipedia.org/wiki/Discipline_(King_Crimson_album)">&lt;i>Discipline&lt;/i>&lt;/a>-era
 &lt;a href="https://en.wikipedia.org/wiki/Cocteau_Twins">Cocteau
 Twins&lt;/a>”. If you dig it, we’re working on a new
 batch of tunes. Ideally, it’ll come out in less than a year...
&lt;/p>

&lt;figure>
 &lt;a href="https://telltaleshimmer.bandcamp.com/album/florilegium">
 &lt;img src="back-cover-1000.jpg" width="500" height="500" alt="The back cover of Florilegium, showing a picture of the Pacific Ocean at sunset at Ocean Beach, San Francisco. It shows the track listing and the credits:

1: Six Weeks,
2: Remember Me,
3: 0630,
4: Fearless,
5: Spring

Matt Herman: guitar, programming, drum machine;
Chris Palmer: guitar, programming;
Ryan Kotler; bass

Mixed and mastered by Jamie Hill at Department of Energy Management, Tacoma.
Thanks to Ryan Clark and Devin Lane for helping us get there.

“Six Weeks” and “Fearless” composed by Chris. “Remember Me” composed by Chris
and Matt. “0630” and “Spring” composed by Matt. Tracks 1–4 arranged by Matt,
Chris, and Ryan. Front cover photography by Matt, back cover photography by
Chris, and design by Chris.

“Remember Me” is dedicated with love to the memory of Bill Brent." />
 &lt;/a>
 &lt;figcaption>Ye olde backe cover.&lt;/figcaption>
&lt;/figure></description><author>Chris Palmer</author><guid>2024/12/18/florilegium/index.html</guid><pubDate>Wed, 18 Dec 2024 00:00:00 +0000</pubDate></item><item><title>Styling Graphviz with CSS</title><link>https://noncombatant.org/2024/11/16/styling-graphviz-with-css/index.content</link><description>&lt;h1>Styling Graphviz with CSS&lt;/h1>

&lt;p>&lt;time>16 November 2024&lt;/time>&lt;/p>

&lt;p>Here is a nice SVG of a graph:&lt;/p>

&lt;figure>
&lt;svg width="450pt" height="114pt"
 viewBox="0.00 0.00 450.45 114.33" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
&lt;g id="graph0" class="graph" transform="scale(1 1) rotate(0) translate(4 110.33)">
&lt;!-- gourd -->
&lt;g id="node1" class="node">
&lt;title>gourd&lt;/title>
&lt;ellipse fill="none" stroke="var(--fg)" cx="36" cy="-53.16" rx="36" ry="36"/>
&lt;text text-anchor="middle" x="36" y="-49.46" font-family="Times,serif" font-size="14.00">gourd&lt;/text>
&lt;/g>
&lt;!-- pumpkin -->
&lt;g id="node2" class="node">
&lt;title>pumpkin&lt;/title>
&lt;ellipse fill="none" stroke="var(--fg)" cx="150.06" cy="-53.16" rx="42.13" ry="42.13"/>
&lt;text text-anchor="middle" x="150.06" y="-49.46" font-family="Times,serif" font-size="14.00">pumpkin&lt;/text>
&lt;/g>
&lt;!-- gourd&amp;#45;&amp;gt;pumpkin -->
&lt;g id="edge1" class="edge">
&lt;title>gourd&amp;#45;&amp;gt;pumpkin&lt;/title>
&lt;path fill="none" stroke="var(--fg)" d="M72.15,-53.16C80.27,-53.16 89.07,-53.16 97.72,-53.16"/>
&lt;polygon fill="var(--fg)" stroke="var(--fg)" points="97.76,-56.66 107.76,-53.16 97.76,-49.66 97.76,-56.66"/>
&lt;/g>
&lt;!-- squash -->
&lt;g id="node3" class="node">
&lt;title>squash&lt;/title>
&lt;ellipse fill="none" stroke="var(--fg)" cx="264.13" cy="-53.16" rx="36" ry="36"/>
&lt;text text-anchor="middle" x="264.13" y="-49.46" font-family="Times,serif" font-size="14.00">squash&lt;/text>
&lt;/g>
&lt;!-- pumpkin&amp;#45;&amp;gt;squash -->
&lt;g id="edge2" class="edge">
&lt;title>pumpkin&amp;#45;&amp;gt;squash&lt;/title>
&lt;path fill="none" stroke="var(--fg)" d="M192.15,-53.16C200.5,-53.16 209.33,-53.16 217.82,-53.16"/>
&lt;polygon fill="var(--fg)" stroke="var(--fg)" points="217.94,-56.66 227.94,-53.16 217.94,-49.66 217.94,-56.66"/>
&lt;/g>
&lt;!-- decoration -->
&lt;g id="node4" class="node">
&lt;title>decoration&lt;/title>
&lt;ellipse fill="none" stroke="var(--fg)" cx="389.29" cy="-53.16" rx="49.32" ry="49.32"/>
&lt;ellipse fill="none" stroke="var(--fg)" cx="389.29" cy="-53.16" rx="53.33" ry="53.33"/>
&lt;text text-anchor="middle" x="389.29" y="-49.46" font-family="Times,serif" font-size="14.00">decoration&lt;/text>
&lt;/g>
&lt;!-- squash&amp;#45;&amp;gt;decoration -->
&lt;g id="edge3" class="edge">
&lt;title>squash&amp;#45;&amp;gt;decoration&lt;/title>
&lt;path fill="none" stroke="var(--fg)" d="M300.42,-53.16C308.39,-53.16 317.08,-53.16 325.8,-53.16"/>
&lt;polygon fill="var(--fg)" stroke="var(--fg)" points="326,-56.66 336,-53.16 326,-49.66 326,-56.66"/>
&lt;/g>
&lt;/g>
&lt;/svg>

&lt;figcaption>A directed, acyclic gourd.&lt;/figcaption>

&lt;/figure>

&lt;p>Since &lt;a
href="https://www.mcsweeneys.net/articles/its-decorative-gourd-season-motherfuckers">Decorative
Gourd Season is coming to an end, motherfuckers&lt;/a>, this fine graph will soon
lose its relevance until next year. So it goes.&lt;/p>

&lt;p>Since I sometimes use Graphviz for articles, and now that I’m trying to make
this site respect light and dark mode preferences smoothly, I wanted to get my
graphs to do so as well. In the past, I’ve assumed light mode only, and so my
graphs look bad in dark mode — they’re a sudden flash of bright in an otherwise
dark page.&lt;/p>

&lt;p>To see it in action: If you’re in dark mode, switch to light, and vice-versa.
(On macOS, for example, you can do this in &lt;b>System Settings&lt;/b> →
&lt;b>Appearance&lt;/b>.) If it’s not easy for you to switch back and forth betwixt
the modes, here are screenshots:&lt;/p>

&lt;figure>&lt;img src="light-screenshot.png" width="719" height="416" alt="A
screenshot of a draft of this page in light mode."/>&lt;figcaption>Light mode: Like
the text, the graph is dark on a light background.&lt;/figcaption>&lt;/figure>

&lt;figure>&lt;img src="dark-screenshot.png" width="719" height="416" alt="A
screenshot of a draft of this page in dark mode."/>&lt;figcaption>Dark mode: Like
the text, the graph is light on a dark background.&lt;/figcaption>&lt;/figure>

&lt;p>It took me longer than it should have to figure out how to get this to work,
so I thought I’d write it down. These are the key things to know:&lt;/p>

&lt;ul>

&lt;li>Graphviz can indeed produce Scalable Vector Graphics (SVG) files. Woo
hoo!&lt;/li>

&lt;li>You can indeed style SVGs with CSS. (SVG is an application of XML, so things
work as you’d hope.) As always, &lt;a
href="https://developer.mozilla.org/en-US/docs/Web/SVG/Tutorial/SVG_and_CSS">Mozilla
Developer Network’s documentation&lt;/a> is good.&lt;/li>

&lt;li>You can embed SVG directly into HTML (!) — you don’t have to use an
&lt;code>img&lt;/code> tag.&lt;/li>

&lt;li>To get this to work easily and consistently, you really want to do the
direct embedding. 

&lt;/ul>

&lt;p>Crucial to all this is that the SVG be inline in the HTML, inside a
&lt;code>div&lt;/code>. I found that trying to &lt;a
href="https://graphviz.org/docs/attrs/stylesheet/">set the
&lt;code>stylesheet&lt;/code> attribute in the &lt;code>digraph&lt;/code>&lt;/a>, and then
loading the image in an HTML page with the &lt;code>img&lt;/code> tag, resulted in
Total CSS Chaos. I am nowhere near good enough at the DOM and CSS to understand
what was going on; but, thankfully, putting the SVGs inline seems to fix
things.&lt;/p>

&lt;p>This also means you can maintain just a single CSS file for your main site;
you just have to add some declarations for SVG XML elements.&lt;/p>

&lt;p>Here’s the core of my CSS that gets this working:&lt;/p>

&lt;pre>
:root {
 color-scheme: light dark;
 --fg: light-dark(#333, #ccc);
 --bg: light-dark(#fff, #333);
}

body {
 background-color: var(--bg);
 color: var(--fg);
 font-family: "Helvetica Neue";
}

.node {
 stroke: var(--fg);
 fill: var(--fg);
}

.edge {
 fill: var(--fg);
 stroke: var(--fg);
}

text {
 font-family: inherit;
 font-size: 70%;
}
&lt;/pre>

&lt;p>&lt;code>.node&lt;/code>, &lt;code>.edge&lt;/code>, and &lt;code>text&lt;/code> are the
relevant SVG elements. The rest is for the main HTML page, but it provides
variables that we’ll use in the SVG-related CSS.&lt;/p>

&lt;p>Here’s the Graphviz file:&lt;/p>

&lt;pre>
digraph {
 splines = polyline
 rankdir = LR
 &lt;b>bgcolor = transparent&lt;/b>
 node [
 shape = circle
 margin = 0.1
 width = 1
 ]
 edge [
 margin = 0.1
 ]

 gourd [ label = "gourd" ]
 pumpkin [ label = "pumpkin" ]
 squash [ label = "squash" ]
 decoration [ label = "decoration", shape = doublecircle ]

 gourd -&amp;gt; pumpkin
 pumpkin -&amp;gt; squash
 squash -&amp;gt; decoration
}
&lt;/pre>

Note the &lt;code>bgcolor = transparent&lt;/code> — that’s important.&lt;/p>

&lt;p>To render it as an SVG, and to get the output SVG to respect our CSS, we use
this pipeline:&lt;/p>

&lt;pre>
% &lt;b>dot -Tsvg test.dot | sed -E -e s'/(fill|stroke)="black"/\1="var(--fg)"/g' &amp;gt; test.svg&lt;/b>
&lt;/pre>

&lt;p>Note that the &lt;code>-E&lt;/code> option for &lt;code>sed&lt;/code> gives us POSIX
Extended regular expressions. Some &lt;code>sed&lt;/code> implementations use a
different option flag for Extended REs.&lt;/p>

&lt;p>The &lt;code>sed&lt;/code> is necessary because Graphviz inserts
&lt;code>stroke&lt;/code> and &lt;code>fill&lt;/code> attributes into the XML elements,
which override the global CSS. So, we zap ’em.&lt;/p>

&lt;p>When embedding the SVG into your HTML, you need to supply &lt;code>alt&lt;/code>
text for accessibility. Unlike &lt;code>img&lt;/code> the &lt;code>svg&lt;/code> element
doesn’t support the &lt;code>alt&lt;/code> attribute. Instead, use &lt;code>role&lt;/code>
and &lt;code>aria-label&lt;/code>:&lt;/p>

&lt;pre>
&amp;lt;svg width="200pt" height="300pt" &lt;b>role="img"&lt;/b> &lt;b>aria-label="Some
descriptive text goes here"&lt;/b>
 viewBox="0.00 0.00 242.00 260.00" xmlns="http://www.w3.org/2000/svg"
 xmlns:xlink="http://www.w3.org/1999/xlink"&amp;gt;
&lt;/pre>

&lt;p>There’s probably an easier way to do this, but this is what I’ve got so
far.&lt;/p></description><author>Chris Palmer</author><guid>2024/11/16/styling-graphviz-with-css/index.html</guid><pubDate>Sat, 16 Nov 2024 00:00:00 +0000</pubDate></item><item><title>More Fun With The Known Exploited Vulnerabilities Catalog</title><link>https://noncombatant.org/2023/12/29/more-fun-with-kev/index.content</link><description>&lt;h1>More Fun With The Known Exploited Vulnerabilities Catalog&lt;/h1>

&lt;p>&lt;time>29 December 2023&lt;/time>&lt;/p>

&lt;p>Happily, &lt;a
href="https://cwe.mitre.org/top25/archive/2023/2023_kev_insights.html">MITRE has
analyzed and characterized the bugs in the Known Exploited Vulnerabilities (KEV)
Catalog of 2023&lt;/a>:&lt;/p>

&lt;blockquote>&lt;p>In 2021, the &lt;a
href="https://www.dhs.gov/cisa/cybersecurity-division">Cybersecurity and
Infrastructure Security Agency (CISA)&lt;/a>
began publishing the “&lt;a
href="https://www.cisa.gov/known-exploited-vulnerabilities-catalog">Known
Exploited Vulnerabilities (KEV) Catalog&lt;/a>.” Entries in this catalog are
vulnerabilities that have been reported through the &lt;a
href="https://www.cve.org/">Common Vulnerabilities and Exposures (CVE®)&lt;/a>
program and are observed to be (or have been) actively exploited.&lt;/p>&lt;/blockquote>

&lt;p>I think this part in particular is important for software engineers and
management to be aware of:&lt;/p>

&lt;blockquote>&lt;p>CISA recommends that organizations monitor the KEV catalog and
use its content to help prioritize remediation activities in their systems to
reduce the likelihood of compromise.&lt;/p>&lt;/blockquote>

&lt;p>Last year I did &lt;a href="/2022/04/22/itw-taxonomy/">a similar thing&lt;/a> (see
also &lt;a
href="https://docs.google.com/spreadsheets/d/1JeN3F8EG6A_ckb7PDCHIuAocR8W-6UEu9kKoctJaF08/edit#gid=1509787727">the
spreadsheet&lt;/a>), with a substantially different classification system but with
essentially the same outcome.&lt;/p>

&lt;p>Hand-waving away the differences in the bug classification for a moment, we
see that MITRE got a similar result as I did: they got 46% memory unsafety (with
use-after-free (UAF) leading), while my (incomplete) result was 40% memory
unsafety. So we’re in the same ballpark, which is nice.&lt;/p>

&lt;p>Of the various kinds of memory unsafety, why should UAF be so prominent in
known exploitation in 2023? My take is that for arbitrarily complex object
graphs, &lt;a href="/2023/05/29/complexities-of-allocation/">nothing but
heap-walking garbage collection is reliable for achieving temporal safety&lt;/a>.
(GC; as opposed to less expensive lifetime management approaches like reference
counting, arena allocation, and so on.) Temporal safety is much harder in
general to fix efficiently than is spatial unsafety.&lt;/p>

&lt;p>Moreover, browsers — which by definition must have complex object graphs (due
to for example the HTML DOM, JavaScript, and cross-process IPC with entangled
object lifetimes) — are naturally a big focus of exploit developers’ attention.
For efficiency reasons, browsers tend not to use GC for much of the browser’s
own internals. I think that accounts for the prominence of UAF in the 2023
catalog.&lt;/p>

&lt;p>Let’s consider MITRE’s classification system, though.&lt;/p>

&lt;h2>Taxonomic Tangles&lt;/h2>

&lt;p>At its core, I find &lt;a href="https://cwe.mitre.org/">the Common Weaknesses
Enumeration taxonomy&lt;/a> (CWE) to be trying for more precision than we can get
or even need, and that it obscures more than it enlightens. (&lt;a
href="/2022/07/10/fraught-vdbs/">I find the same is true of the Common
Vulnerability Scoring System&lt;/a> (CVSS).)&lt;/p>

&lt;p>For example, consider the 2nd- and 3rd-most prevalent bug classes, &lt;a
href="https://cwe.mitre.org/data/definitions/122.html">CWE-122 heap-based buffer
overflow&lt;/a> and &lt;a
href="https://cwe.mitre.org/data/definitions/787.html">CWE-787 out-of-bounds
write&lt;/a>. It’s not immediately clear what the important differences between
these 2 taxa are. After reading their definitions, I find it even less clear.
Were the heap-overflows all reads, not writes? Were the OOB writes all on the
stack?&lt;/p>

&lt;p>At the high level of analysis we are doing here — that is, helping managers
and engineers allocate their time and attention most effectively — the read vs.
write distinction matters, but I’m not sure the heap vs. stack (vs. &lt;a
href="https://en.wikipedia.org/wiki/.bss">BSS&lt;/a>) part is the biggest deal. It
matters to exploit developers, but the solutions look similar and have similar
costs to develop.&lt;/p>

&lt;p>There is also a &lt;a
href="https://cwe.mitre.org/data/definitions/788.html">CWE-788 access of memory
location after end of buffer&lt;/a> taxon. Where does that fit in?&lt;/p>

&lt;p>This is important, because it might be that the 2nd- and 3rd-most significant
categories actually outrank UAF, if you treat them as essentially the same: as
spatial unsafety. That might significantly impact an engineering team’s
cost/benefit analysis: solving temporal safety is very hard (expensive), while
solving spatial safety is typically much easier (cheaper). Consider &lt;a
href="https://github.com/abseil/abseil-cpp/blob/lts_2023_08_02/absl/container/inlined_vector.h#L363">a
C++ &lt;code>vector&lt;/code> type&lt;/a>:&lt;/p>

&lt;pre>
// `InlinedVector::operator[](...)`
//
// Returns a `reference` to the `i`th element of the inlined vector.
reference operator[](size_type i) ABSL_ATTRIBUTE_LIFETIME_BOUND {
 &lt;b>ABSL_HARDENING_ASSERT(i &amp;lt; size());&lt;/b>
 return data()[i];
}
&lt;/pre>

&lt;p>If the biggest security problem of 2023 can be solved by sprinkling 1 line of
code in the right places in core libraries, that’s a very different story than
if the biggest problem requires fancy allocation and deallocation strategies, as
solving UAF typically does. Allocation and deallocation necessarily have a much
greater impact on software efficiency and development cost than does the spatial
safety fix above.&lt;/p>

&lt;p>Similarly, the 4th-biggest problem of 2023 in MITRE’s analysis is &lt;a
href="https://cwe.mitre.org/data/definitions/20.html">CWE-20 improper input
validation&lt;/a>. As defined, that could be a key contributing factor to all of
the other top 9 problems — and often is. (That
&lt;code>ABSL_HARDENING_ASSERT&lt;/code> above is proper input validation, for
example.)&lt;/p>
 
&lt;p>Along the same lines, type confusion (#8) could lead to spatial unsafety,
could be an exploitable outcome of UAF, and could be part of the exploitation of
deserialization of untrusted data (#6).&lt;/p>

&lt;h2>Keep Calm And Engineer On&lt;/h2>

&lt;p>Although CWE is Kind Of A Lot, MITRE’s analysis is, at a high level, correct
and useful in directing our work:&lt;/p>

&lt;ol>

&lt;li>memory unsafety is the biggest problem
(#1, #2, #3, and at least some of #4 and #8)&lt;/li>

&lt;li>the next biggest class of problem is what I called &lt;code>eval&lt;/code> bugs
(#5, #6, possibly #8)&lt;/li>

&lt;li>after that, it’s all about what I called logic and configuration bugs (#7,
#9, #10)&lt;/li>

&lt;/ol>

&lt;p>Our goal should be to get things to where logic and (rarely) configration
bugs are our biggest problems. To get there, we gotta hammer on memory unsafety
and &lt;code>eval&lt;/code>.&lt;/p>

&lt;p>Finally, if spatial unsafety really is the current biggest problem, that is
great news. Time to go write a bunch of 1-liners, and &lt;a
href="https://research.swtch.com/testing">write tests&lt;/a>! 🙂&lt;/p>

&lt;p>And, as I am reminded, turn all those pointers into &lt;code>span&lt;/code>s.
😉&lt;/p></description><author>Chris Palmer</author><guid>2023/12/29/more-fun-with-kev/index.html</guid><pubDate>Fri, 29 Dec 2023 00:00:00 +0000</pubDate></item><item><title>Comments On Comments</title><link>https://noncombatant.org/2023/08/27/comments/index.content</link><description>&lt;h1>Comments On Comments&lt;/h1>

&lt;p>&lt;time>27 August 2023&lt;/time>&lt;/p>

&lt;p>Programmers sometimes argue about whether comments are good, or bad, or bad
	but necessary, or better than no comments, and so on. It’s one of those debates
	where everyone is right part of the time, and nobody really convinces anybody,
	and then we do it again next month.&lt;/p>

&lt;p>Maybe a year or so ago, some colleagues and I were going around this
	merry-go-round again, and Drew Fisher actually shed some light on the discussion
	that I hadn’t seen before. He said, “Comments should explain why, not what.” I
	realized it’s the &lt;i>what&lt;/i> comments that I dislike — they are redundant at
	best, and contradict the actual code at worst (which happens frequently, in my
	experience). It’s the &lt;i>why&lt;/i> comments that I like, and I bet most of us
	do.&lt;/p>

&lt;p>There seem to be at least 3 kinds of comments in software code:&lt;/p>

&lt;dl>

	&lt;dt>&lt;i>should&lt;/i> comments&lt;/dt>
	&lt;dd>that talk about what the code should do, or
		what callers should do;&lt;/dd>

	&lt;dt>&lt;i>what&lt;/i> comments&lt;/dt>
	&lt;dd>that talk about what code does; and&lt;/dd>

	&lt;dt>&lt;i>why&lt;/i> comments&lt;/dt>
	&lt;dd>that explain why the code does what it does, or
		why or when callers should call it.&lt;/dd>

&lt;/dl>

&lt;p>The state of comments in many codebases is not ideal. Often, we can and
	should&lt;/p>

&lt;ul>
	&lt;li>replace &lt;i>should&lt;/i> comments with code that checks;&lt;/li>
	&lt;li>replace &lt;i>what&lt;/i> comments with meaningful identifiers; and&lt;/li>
	&lt;li>explain &lt;i>why&lt;/i> more often and more thoroughly.&lt;/li>
&lt;/ul>

&lt;p>Code examples in this post are in Go, since I work in a Go shop these
	days.&lt;/p>

&lt;h2>Replace Should Comments With Code&lt;/h2>

&lt;p>Here’s an example of a &lt;i>should&lt;/i> comment (that also does not explain
	why):&lt;/p>

&lt;pre>
// RunCommand runs command with the correct arguments for our application.
//
// The command should be one of "pumpkin", "noodle", or "tootle".
func RunCommand(command string) error {
	cmd := exec.Command(command, "woop", "boing")
	cmd.Stdout = os.Stdout
	cmd.Stderr = os.Stderr
	return cmd.Run()
}
&lt;/pre>

&lt;p>The &lt;code>command&lt;/code> argument is a shell command, so we can imagine that
	the &lt;i>why&lt;/i> is that we need to restrict the commands to 1 of a few known-safe
	commands — we don’t want to create a shell injection vulnerability! But it’s not
	great to make the reader imagine or guess. We should tell them.&lt;/p>

&lt;p>This code enforces the should and avoids the vulnerability — it’s safe even
	if the authors of callers didn’t read the comment:&lt;/p>

&lt;pre>
var SafeCommands = []string{
	"pumpkin",
	"noodle",
	"tootle",
}

// RunCommand runs command (which must be one of the SafeCommands) with the
// correct arguments for our application.
func RunCommand(command string) error {
	if !slices.Contains(SafeCommands, command) {
		return fmt.Errorf("%q is not in SafeCommands", command)
	}
	cmd := exec.Command(command, "woop", "boing")
	cmd.Stdout = os.Stdout
	cmd.Stderr = os.Stderr
	return cmd.Run()
}
&lt;/pre>

&lt;p>Explaining why commands must be safe is a good idea, too:&lt;/p>

&lt;pre>
// SafeCommands limits the commands that RunCommand will run. This limit is
// necessary because we must prevent shell injection vulnerabilities and
// because even without injection, some commands are dangerous to run. Before
// you change this list, get approval from the SREs.
var SafeCommands = []string{
	"pumpkin",
	"noodle",
	"tootle",
}
&lt;/pre>

&lt;p>This is now pretty good: we’ve replaced a should comment with an assertion
	that stops bad things from happening, and we explain why it’s necessary to stop
	bad things and why commands can be bad.&lt;/p>

&lt;p>Personally, I’m still not entirely satisfied with this for 2 reasons:&lt;/p>

&lt;ol>

	&lt;li>I’d like for attempted invocations of unsafe commands to fail early, at
		compile time rather than at run time.&lt;/li>

	&lt;li>The comments are duplicative, and will need to be updated if the names
		&lt;code>RunCommand&lt;/code> or &lt;code>SafeCommands&lt;/code> change. People don’t always
		remember to do this when making changes, and then the comments refer to things
		that no longer exist.
	&lt;/li>

&lt;/ol>

&lt;p>This code, which creates a type that callers outside the current package
	can’t construct a meaningful instance of, gets closer to that ideal:&lt;/p>

&lt;pre>
// SafeCommands limits the commands that RunCommand will run. This limit is
// necessary because we must prevent shell injection vulnerabilities and
// because even without injection, some commands are dangerous to run.
type SafeCommand struct {
	command string
}

// Before you change or add to these SafeCommands, get approval from the SREs.
var Pumpkin SafeCommand = SafeCommand{command: "pumpkin"}
var Noodle SafeCommand = SafeCommand{command: "noodle"}
var Tootle SafeCommand = SafeCommand{command: "tootle"}

// RunCommand runs command with the correct arguments for our application.
func RunCommand(command SafeCommand) error {
	cmd := exec.Command(command.command, "woop", "boing")
	cmd.Stdout = os.Stdout
	cmd.Stderr = os.Stderr
	return cmd.Run()
}
&lt;/pre>

&lt;p>Callers outside this package cannot construct a meaningful, non-zero instance
	of &lt;code>SafeCommand&lt;/code> because all 1 of its fields, &lt;code>command&lt;/code>,
	begins with a lower-case letter. In Go, identifiers that begin with lower-case
	letters are visible only from inside the package.&lt;/p>

&lt;p>Note that I removed the assertion &lt;code>slices.Contains(SafeCommands,
command)&lt;/code>. Now we use the &lt;code>SafeCommand&lt;/code> type to enforce that
	commands are safe.&lt;/p>

&lt;aside>Update 28 August 2023: Jacob Hoffman-Andrews pointed out that we could
	even make the type private, by naming it &lt;code>safeCommand&lt;/code>. But having a
	public function that takes a private type feels weird to me. I slightly prefer
	having the zero-value of &lt;code>SafeCommand&lt;/code> be meaningless and hence
	safe.&lt;/aside>

&lt;p>From inside the package, it is still possible to create an arbitrary
	&lt;code>SafeCommand&lt;/code>. Depending on the situation, dynamic safety checking
	may also still be necessary. Even if it is, I like the inherent
	documentation-like quality of the new type name and the named global instances.
	If you create a minimal package such that all callers are outside the package,
	you may be able to leave the dynamic check out.
&lt;/p>

&lt;p>This way of doing things is a bit outside the Go cultural norm, but I hope
	it’s not too far outside.&lt;/p>

&lt;h2>Replace What Comments With Names&lt;/h2>

&lt;p>Type names, variable names, function names, and so on (identifiers) are all
	documentation. Many or most what comments are obviated by carefully chosen,
	meaningful identifiers. This is the Javadoc problem: Most Javadoc tediously
	repeats information that is already present in the identifiers themselves.&lt;/p>

&lt;p>What comments are the most likely to get out of sync with the actual code,
	which is often worse than not having comments at all. Readers easily get
	confused as to whether the comment or the code is correct, especially in the
	absence of tests.&lt;/p>

&lt;p>I often see long functions broken up into sections headed with what comments.
	It’s often better to replace the sections with calls to smaller (usually)
	private functions that do the job, and whose names do the work of the what
	comment.&lt;/p>

&lt;p>Code full of what comments, like this:&lt;/p>

&lt;pre>
func DownloadAndVerifyThing(path string) error {
	// Build the URL for the thing
	...

	// Fetch the URL
	...

	// Now verify the file
	...
}
&lt;/pre>

&lt;p>can become:&lt;/p>

&lt;pre>
func DownloadAndVerifyThing(path string) error {
	url := buildURL(path)
	pathname, err := fetchURL(url)
	if err != nil {
		return error
	}
	return verifyFile(pathname)
}

func buildURL(path string) *URL {
	return &amp;amp;URL{
		...
	}
}

func fetchURL(u *URL) (string, error) {
	...
}

func verifyFile(pathname string) error {
	...
}
&lt;/pre>

&lt;p>Now, &lt;code>DownloadAndVerifyThing&lt;/code> is shorter, contains less state, and
	is more obviously a composition of several tasks.&lt;/p>

&lt;h2>Explain Why Thoroughly&lt;/h2>

&lt;p>Depending on the situation, there may be many questions starting with “Why?”
	that the reader of your code might have. Try to anticipate and answer them. Here
	are some ideas:&lt;/p>

&lt;ul>
	&lt;li>Why is it necessary?&lt;/li>
	&lt;li>Why is it implemented this way and not in some other way?&lt;/li>
	&lt;li>Why is it so complicated? Are all these special cases/fancy
		algorithms/complex data structures necessary?&lt;/li>
	&lt;li>Why is it so simple? Don’t we need high efficiency/to handle more error
		conditions/to be more generic/et c.?&lt;/li>
	&lt;li>Why is it here and not somewhere else?&lt;/li>
	&lt;li>Why is it important to fix/refactor/change/not change?&lt;/li>
&lt;/ul></description><author>Chris Palmer</author><guid>2023/08/27/comments/index.html</guid><pubDate>Sun, 27 Aug 2023 00:00:00 +0000</pubDate></item><item><title>Ergonomics, Resource Lifetimes, And Object Graphs</title><link>https://noncombatant.org/2023/05/29/complexities-of-allocation/index.content</link><description>&lt;h1>Ergonomics, Resource Lifetimes, And Object Graphs&lt;/h1>

&lt;p>&lt;time>29 May 2023&lt;/time>&lt;/p>

&lt;p>This is a smol thought on how resource acquisition and release strategies
affect the ergonomics of object lifetimes and the complexity of object graphs.
&lt;i>Resource&lt;/i> generally means any or all of: memory, objects, files, locks,
sockets, et c.&lt;/p>

&lt;p>Whenever a program requires complex object graphs, complex lifetimes, or
deterministic release of resources, but the language does not make those things
ergonomic to express, bugs will inevitably ensue. Examples include (but are not
limited to) trying to manage cyclic graphs with &lt;a
href="https://en.wikipedia.org/wiki/Resource_acquisition_is_initialization">RAII&lt;/a>
(e.g. classic HTML DOM and JavaScript binding implementations); any language
with explicit release (e.g. any C program that allocates on the heap, opens
files, or holds locks); and programs for which deterministic resource release is
critical to correctness but when automatic release is non-deterministic (e.g.
Java’s &lt;code>finalize&lt;/code>).&lt;/p>

&lt;p>The kinds of bugs you might ‘enjoy’ if your language cannot ergonomically
express the relationships between your resources vary according to the kinds of
resources you need to acquire and release. Examples:&lt;/p>

&lt;dl>

&lt;dt>memory&lt;/dt> &lt;dd>Space inefficiency; use-after-free bugs&lt;/dd>

&lt;dt>locks&lt;/dt> &lt;dd>Deadlocks; time inefficiency (holding a lock too long);
forgetting to release a lock&lt;/dd>

&lt;dt>files and handles&lt;/dt> &lt;dd>File descriptor and handle exhaustion due to
keeping them open too long; data loss due to failing to synchronize a write
before program exit&lt;/dd>

&lt;/dl>

&lt;p>&lt;a
href="https://noncombatant.org/2016/01/30/everyone-needs-secure-usability/">Everyone
needs secure usability&lt;/a>, if we hope to consistently produce correct and safe
software.&lt;/p>

&lt;p>For simple examples of what I mean by these strategies (except for GC, which
hopefully everyone is familiar with from experience in Go, Python, Java, et c.;
and global static analysis, which you can read about &lt;a
href="https://doc.rust-lang.org/1.8.0/book/references-and-borrowing.html">as it
is used in Rust&lt;/a>), see &lt;a href="examples.cc">examples.cc&lt;/a>. These examples
use memory as the resource, but keep in mind the same idea applies to other
kinds of resources.&lt;/p>

&lt;table>

&lt;tr>
&lt;th>Allocation Strategy&lt;/th>
&lt;th>Brief Characterization&lt;/th>
&lt;th>Ergonomic For Lifetimes&lt;/th>
&lt;th>Ergonomic for Object Graph Complexities&lt;/th>
&lt;th>Guarantee Of Resource Release&lt;/th>
&lt;/tr>

&lt;tr>
&lt;td>caller acquires, caller releases implicitly&lt;/td>
&lt;td>Static or stack storage, released on termination or &lt;code>return&lt;/code>
(respectively)&lt;/td>
&lt;td>static, stack-local&lt;/td>
&lt;td>plain old data (no references); or possible references to objects of same or
longer lifetimes&lt;/td>
&lt;td>typically deterministic&lt;sup>†&lt;/sup>&lt;/td>
&lt;/tr>

&lt;tr>
&lt;td>caller acquires, caller releases explicitly&lt;/td>
&lt;td>Heap or other external resource released with an explicit call
(&lt;code>free&lt;/code>, &lt;code>delete&lt;/code>, &lt;code>close&lt;/code>, et c.)&lt;/td>
&lt;td>not ergonomic&lt;sup>＊&lt;/sup>&lt;/td>
&lt;td>not ergonomic&lt;/td>
&lt;td>deterministic; subject to programmer error&lt;/td>
&lt;/tr>

&lt;tr>
&lt;td>callee acquires, caller releases implicitly&lt;/td>
&lt;td>Types (e.g. &lt;code>string&lt;/code>, &lt;code>vector&lt;/code>, &lt;a
href="https://en.cppreference.com/w/cpp/thread/scoped_lock">&lt;code>scoped_lock&lt;/code>&lt;/a>,
et c.) that manage resources internally and release them in their destructors,
which are implicitly called at the end of the scope&lt;/td>
&lt;td>static, stack-local&lt;/td>
&lt;td>acyclic graph; possible references to objects of same or longer
lifetimes&lt;/td>
&lt;td>typically deterministic&lt;sup>†&lt;/sup>&lt;/td>
&lt;/tr>

&lt;tr>
&lt;td>callee acquires, caller releases explicitly&lt;/td>
&lt;td>Functions and types that wrap resource acquisition but still require
explicit release, e.g. &lt;code>asprintf&lt;/code>/&lt;code>free&lt;/code>, &lt;a
href="https://www.gnu.org/software/libc/manual/html_node/Controlling-Buffering.html#index-setvbuf">&lt;code>setvbuf&lt;/code>&lt;/a>,
&lt;code>open&lt;/code>/&lt;code>close&lt;/code>, et c.&lt;/td>
&lt;td>not ergonomic&lt;sup>＊&lt;/sup>&lt;/td>
&lt;td>not ergonomic&lt;/td>
&lt;td>deterministic&lt;sup>‡&lt;/sup>; subject to programmer error&lt;/td>
&lt;/tr>

&lt;tr>
&lt;td>anyone acquires, anyone releases when ref count is 0&lt;/td>
&lt;td>Reference-counting smart pointers, like &lt;code>shared_ptr&lt;/code>, &lt;a
href="https://doc.rust-lang.org/std/rc/struct.Rc.html">&lt;code>Rc&lt;/code>&lt;/a>, and
&lt;a
href="https://doc.rust-lang.org/std/sync/struct.Arc.html">&lt;code>Arc&lt;/code>&lt;/a>.&lt;/td>
&lt;td>any&lt;/td>
&lt;td>acyclic graph; possible references to objects of same or longer
lifetimes&lt;/td>
&lt;td>typically deterministic when thread-local; subject to leaks via cyclic
references&lt;/td>
&lt;/tr>

&lt;tr>
&lt;td>anyone acquires, global garbage collection&lt;/td>
&lt;td>Languages with a garbage collector in its runtime, such as Lisp, JavaScript,
Python, Go, et c.&lt;/td>
&lt;td>any&lt;/td>
&lt;td>arbitrary graph of objects of arbitrary lifetimes&lt;/td>
&lt;td>non-deterministic; subject to leaks if program terminates before collection
completes&lt;/td>
&lt;/tr>

&lt;tr>
&lt;td>anyone acquires, global static analysis ensures implicit release&lt;/td>
&lt;td>Languages that statically analyze explicit and/or deduced lifetime
annotations that become part of an object’s type (see e.g. &lt;a
href="https://en.wikipedia.org/wiki/Substructural_type_system#Linear_type_systems">linear
typing&lt;/a>).&lt;/td>
&lt;td>inversely proportional to the complexity of entangled lifetimes&lt;/td>
&lt;td>arbitrary graph of objects with references to objects of same or longer
lifetimes&lt;/td>
&lt;td>typically deterministic when thread-local&lt;sup>†&lt;/sup>&lt;/td>
&lt;/tr>

&lt;/table>

&lt;small>

&lt;p>† Although one can imagine implicit but non-deterministic release, I don’t
know of a language that has it in a static or stack-local context (but see GC).
RAII is the generalized form of these strategies.&lt;/p>

&lt;p>‡ Go’s &lt;code>defer&lt;/code> is a special case: an explicit expression of
non-deterministic release.&lt;/p>

&lt;p>＊ Arena acquisition and release (when resources acquired during a given
epoch are released together) can ease the difficulty that arises when objects of
different lifetimes become entangled in a graph. The costs are that resource
release within an arena might not be deterministic, and that some resources may
have longer lifetimes than strictly necessary.&lt;/p>

&lt;/small>

&lt;aside>

&lt;p>Thanks to David Adrian and Jon Callas for reading earlier drafts of this post
and nudging me to make it less unclear. If it’s still too gnomic, drop me a
line. ☺️&lt;/p>

&lt;/aside></description><author>Chris Palmer</author><guid>2023/05/29/complexities-of-allocation/index.html</guid><pubDate>Mon, 29 May 2023 00:00:00 +0000</pubDate></item><item><title>Protel, SOS, And The DMS-100</title><link>https://noncombatant.org/2023/05/21/protel-sos-dsm-100/index.content</link><description>&lt;h1>Protel, SOS, And The DMS-100&lt;/h1>

&lt;p>&lt;time>21 May 2023&lt;/time>&lt;/p>

&lt;p>&lt;a href="https://en.wikipedia.org/wiki/Protel">Protel&lt;/a>, the The PRocedure
 Oriented Type Enforcing Language, and the operating system SOS (for the Digital
 Multiplex Switch, DMS-100) that was built with it, give us an interesting
 snapshot of the early history of software engineering (as opposed to
 programming, and as opposed to computing science: programming integrated over
 time). Naturally, my focus is on the safety affordances of the language, but the
 Nortel engineers had a whole lot of modern design going on.&lt;/p>

&lt;p>The language was in use starting in 1975, so it’s almost as old as C, and
 also used for systems programming. It’s a familiar ALGOL derivative. The
 official papers I could find (so far) are short and serve only to tantalize:&lt;/p>

&lt;ul>

 &lt;li>&lt;a href="https://ieeexplore.ieee.org/document/762490">Protel: a high level
 language for telephony&lt;/a> by Foxall, Joliat, Kamel, and Miceli, 1979&lt;/li>

 &lt;li>&lt;a href="https://dl.acm.org/doi/pdf/10.5555/800078.802525">Experience With A
 Modular Typed Language: Protel&lt;/a> by Cashin, Joliat, Kamel, and Lasker (&lt;a
 href="cashin-experience-with-protel.pdf">local copy&lt;/a>), 1981&lt;/li>

&lt;/ul>

&lt;p>I also found some useful reminiscences from a former Nortel engineer, Frazer
 Clement:&lt;/p>

&lt;ul>

 &lt;li>&lt;a href="https://messagepassing.blogspot.com/2009/04/protel-i.html">Protel
 I&lt;/a>&lt;/li>

 &lt;li>&lt;a href="https://messagepassing.blogspot.com/2009/04/protel-ii.html">Protel
 II&lt;/a>&lt;/li>

 &lt;li>&lt;a href="https://messagepassing.blogspot.com/2008/12/what-is-sos.html">What
 Is SOS?&lt;/a>&lt;/li>

 &lt;li>&lt;a href="https://messagepassing.blogspot.com/2009/01/what-is-sos-part-ii.html">What
 Is SOS? Part II&lt;/a>&lt;/li>

 &lt;li>&lt;a href="https://messagepassing.blogspot.com/2009/03/what-is-sos-part-iii.html">What
 Is SOS? Part III&lt;/a>&lt;/li>

&lt;/ul>

&lt;p>There are more (offline, sadly) citations at &lt;a href="https://museum.eecs.yorku.ca/collections/show/18">The York
 University
 Computer Museum&lt;/a>. Searching the web for some of the citations can get you
 closer, but the holy grails that I haven’t found yet are H. Johnson, “PROTEL: A
 programming Language for Large Real-Time Applications” (1984); and &lt;i>Protel
 Technical Notes, BNR, Language Development Group&lt;/i>; issues: vol. 1, nr. 1 – 7,
 1980.&lt;/p>

&lt;p>The broad view these sources provide of Protel and SOS is of a type-checked
 and spatially memory-safe systems programming language, compiled into
 dynamically linkable and swappable shared objects, which all run as real-time,
 pre-emptively scheduled threads in a single shared address space.&lt;/p>

&lt;p>The systems ran with volatile storage as their primary storage, rather than
 treating volatile storage as a fast cache for non-volatile storage. Instead,
 production systems had redundant power supplies and battery-backed power, and
 used an explicit delineation of memory types for reliability and recovery.
 Certain memories were explicitly temporary, while others would be restored from
 disk or tape only in escalated outages. See &lt;a
 href="https://messagepassing.blogspot.com/2008/12/what-is-sos.html">Clement,
 especially “Multiple memory types”&lt;/a>.&lt;/p>

&lt;p>Protel’s type system was somewhat richer than C; from Foxall, et al.:&lt;/p>

&lt;blockquote>
 &lt;pre>
TYPE digit-value, terminal-id {0 TO 9}
 status_condition {busy, idle, blocked, ready},
 out_of_service BOOL,
 protocol_ptr PTR TO status_condition;

TYPE digit_register TABLE [0 TO 19] OF digit_value,
 special_feature SET {abbreviated_dial, add_on,
 call_transfer, do_not_disturb},
 time_interval
 STRUCT
 amount {0 TO 255},
 unit {ten_ms, secs, mins, hours}
 ENDSTRUCT;
&lt;/pre>
&lt;/blockquote>

&lt;p>I find ranged integers notable; &lt;a href="https://github.com/google/integers/blob/main/ranged.h">even now, we have
 to roll our own&lt;/a>, but I suspect their ergonomic definition could have
 prevented many bugs.&lt;/p>

&lt;p>Foxall, et al. describe descriptors:&lt;/p>

&lt;blockquote>A descriptor consists of two parts: a descriptor part and a table
 part. The descriptor part contains the table element count, the size of these
 elements, and a pointer to the base of the table part. The table part contains
 the elements of the current array. At execution time a descriptor may be made to
 point at any table of the correct type. This results in modification of the
 element count and pointer fields of the descriptor part.&lt;/blockquote>

&lt;p>The area type seems to provide a form of abstract class inheritance via
 C-&lt;code>union&lt;/code>-like structured type punning:&lt;/p>

&lt;blockquote>
 &lt;pre>
TYPE daddy AREA (6 * byte-width)
 i integer
ENDAREA;

TYPE son AREA REFINES daddy
 t TABLE [0 TO 15] OF BOOL
ENDAREA;

TYPE daughter AREA REFINES daddy
 j integer,
 k BOOL
ENDAREA;
&lt;/pre>
&lt;/blockquote>

&lt;p>I don’t see discussion of down-casting safety with areas, though. As for C
 &lt;code>union&lt;/code>s and C++ without RTTI, areas may be unsafe.
&lt;/p>

&lt;p>Protel also had function types:&lt;/p>

&lt;blockquote>
 &lt;pre>
TYPE get_channel PROC (terminal terminal_id)
 RETURNS integer;
TYPE transfer PROC (REF t time_interval,
 UPDATES feature_table DESC OF BOOL);
&lt;/pre>
&lt;/blockquote>

&lt;h2>Early Modern Engineering&lt;/h2>

&lt;p>Although that method of operation is different from what we use now, we can
 see from these sources that Protel, SOS, and the DMS-100 embodied very early
 forms of what we now consider a baseline for modern software engineering and
 site reliability engineering culture. Some examples:&lt;/p>

&lt;ul>
 &lt;li>
 &lt;p>A complete suite of language support tooling (the Protel Library System, PLS
 and PLS-II), including &lt;a href="https://en.wikipedia.org/wiki/Source_Code_Control_System">a source code
 control system (SCCS)&lt;/a>/software configuration management system (SCM). From
 Cashin, et al.:&lt;/p>

 &lt;blockquote>In a production environment, however, the need for parallel support
 of both old and new software is a fact of life. Therefore, a successor, PLS-II,
 was designed to simplify the handling of multiple versions of both source code
 and system structure. A tool called source manager, similar in spirit to SCCS
 [DHM 78], is used to simplify maintenance and reduce storage for nearly
 identical source versions. Compatible lineups of system versions are maintained
 in the PLS database which refers to the named issues kept by source
 manager.&lt;/blockquote>
 &lt;/li>

 &lt;li>
 &lt;p>Recognition of interfaces as executable, enforceable documentation and
 automated discovery of dependencies at compile- and run-time (Cashin, et al.,
 “Interfaces as Documentation”).&lt;/p>
 &lt;/li>

 &lt;li>
 &lt;p>Technical structures aligned with social structures (“Modularity as a
 Project Manager’s Tool”, Cashin et al.). This is perhaps more arguable and more
 fluid, now.&lt;/p>
 &lt;/li>

 &lt;li>
 &lt;p>Recognition of the need to ‘shift bugs left’, preferably discovering them
 during type-checking (Cashin, et al.):&lt;/p>

 &lt;blockquote>By performing strict type checking on intermodule references, we
 have found that many of the errors which, in other languages, would have been
 detected at run time are flagged by the compiler. This permits easy repair early
 in the development process when bugs can be fixed cheaply.&lt;/blockquote>
 &lt;/li>

 &lt;li>
 &lt;p>The familiar pain of long compilation times, exacerbated by thorough
 type checking, in section “Building Systems”, Cashin et al. But: “We feel that
 the difficulty inherent in this process is preferable to the mammoth debugging
 sessions which are required when analogous changes are made to programs written
 in more loosely typed languages.”
 &lt;/p>
 &lt;/li>

 &lt;li>
 &lt;p>Access control enforced by the type system (as seen in the JVM and the .NET
 CLR, for example) (Cashin, et al.):&lt;/p>

 &lt;blockquote>We have found multiple interfaces to be an extremely useful concept.
 They allow the separation of module functions by user. Thus, functions intended
 for general users may be separated from those intended for more ‘privileged’
 users. For example, a file system may have a general user interface which
 supports operations such as &lt;code>OPEN&lt;/code>, &lt;code>CLOSE&lt;/code>,
 &lt;code>GET&lt;/code> and &lt;code>PUT&lt;/code>. A second, more privileged, interface may
 support operations which are only used by maintenance and audit
 software.
 &lt;/blockquote>
 &lt;/li>

 &lt;li>
 &lt;p>Dynamic configuration via function pointers (which Cashin, et al. call
 “procedure variables”; see “Modularity
 as a Tool for Flexible Configuration”). This includes the possibility of
 selecting implementations at run-time:&lt;/p>

 &lt;blockquote>Since interface specifications allow a clear distinction between
 what a module provides and how it provides it, it is possible to design a single
 interface and several implementations for the same module. Any of these
 implementations can then be used transparently in different system
 configurations.&lt;/blockquote>
 &lt;/li>

 &lt;li>
 &lt;p>Recognition of the complexity of dependency management, even in purely
 1st-party codebases (see “Type Transitivity” in Cashin, et al.).&lt;/p>
 &lt;/li>

 &lt;li>
 &lt;p>An early form of &lt;a href="https://semver.org/">semantic versioning&lt;/a>.
 From “Configuration Control” in Cashin, et al.:&lt;/p>

 &lt;blockquote>A version code consists of two parts: A major number that is
 incremented when non-upwards compatible changes are made and a minor number
 incremented when upwards compatible changes are made. Many, but by no means all,
 interface changes are upwards compatible. The check used for consistency is as
 follows: when a module is loaded, the major number of each module in its
 &lt;code>USES&lt;/code> list is compared with that of the version of the module
 already existing in the system. If they are not equal, the configuration is
 inconsistent. If they are, then compare the minor numbers. If the minor number
 in the &lt;code>USES&lt;/code> list is greater than that of an existing module then it
 is possible that the module to be loaded relies on features not yet implemented
 in the existing module and the configuration is inconsistent.
 &lt;/blockquote>
 &lt;/li>

 &lt;li>
 &lt;p>Early understanding of &lt;a href="https://www.hyrumslaw.com/">Hyrum’s
 Law&lt;/a>. From Cashin, et al.: “Although implementation sections are hidden from
 the outside world, there is a fundamental problem in ensuring that an
 implementation change has not altered the semantics of the interface, even when
 there is no direct change to the interface itself. The detailed implications of
 changes to all users requires careful consideration which is not encouraged by
 the knowledge that most changes really are well hidden and do not compromise
 system integrity.”&lt;/p>
 &lt;/li>

 &lt;li>
 &lt;p>The &lt;code>DESC&lt;/code> (“descriptor”) type was what we now call
 &lt;code>span&lt;/code> or &lt;code>slice&lt;/code>: A pointer to a (sub-)region of
 elements, together with the number of elements in that (sub-)region. This
 provided spatial safety — the bounds were checked. They also recognized that
 built-in mechanisms for safety can yield efficiency improvements. From
 Clement:
 &lt;/p>

 &lt;blockquote>A Protel &lt;code>DESC&lt;/code>riptor is used to refer to a range of
 elements in an array of &amp;lt;type&amp;gt;. It is used in the same way [as] an array —
 with a subs[c]ript as an lvalue or rvalue to an expression (though the usual
 meaning of those terms is confused by &lt;a href="https://en.wikipedia.org/wiki/Protel#GAZINTA">the Gozinta
 operator&lt;/a>!).
 The compiler is aware of the of the slice being &lt;code>DESC&lt;/code>ribed, and by
 inference the size of the elements. In the storage allocated to the
 &lt;code>DESC&lt;/code> itself, it stores a pointer to the zeroth element and an
 upperbound in terms of elements. In this way it can provide bounds checking on
 accesses through the &lt;code>DESC&lt;/code>. When an out-of-bounds exception is hit,
 the actual upperbound and the supplied subscript are available in the exception
 report, often allowing debugging straight from the trace. The array slice
 abstraction can be a nice way to deal with zero-copy in a protocol
 stack.
 &lt;/blockquote>

 &lt;p>Thus it would seem that Canadian telecommunications systems programming
 language designers were, as usual, more polite than their cousins a little to
 the south.&lt;/p>
 &lt;/li>

 &lt;li>
 &lt;p>An A/B update scheme not entirely unlike what we now use in e.g. Android
 and ChromiumOS; see &lt;a href="https://messagepassing.blogspot.com/2009/03/what-is-sos-part-iii.html">the
 “One Night(mare) Process” in Clement&lt;/a>.&lt;/p>
 &lt;/li>

&lt;/ul>

&lt;h2>Musings&lt;/h2>

&lt;p>I used to think (&lt;a href="https://en.wikipedia.org/wiki/Singularity_(operating_system)#Security_design">and
 so did the designers of Microsoft’s Singularity operating system&lt;/a>, so at
 least I was in good company) that language safety could obviate protected memory
 (as mediated by a privileged supervisor). Clearly, the SOS designers were hoping
 for that, too, and like the Singularity designers they really wanted to get rid
 of the overhead of context switching and virtual memory. (The overhead is
 amazingly high! We’ve just come to accept it as normal, which really &lt;a
 href="https://alexgaynor.net/2019/apr/21/modern-c++-wont-save-us/">puts
 micro-performance concerns into perspective&lt;/a>.)&lt;/p>

&lt;p>Similarly, &lt;a href="https://www.usenix.org/conference/enigma2021/presentation/palmer">it’s
 obvious (even to me) now&lt;/a> that memory protection alone can never suffice:
 untrustworthy programs can call and corrupt a program even from outside its
 protection zone (and even, of course, from other machines entirely). Add to that
 side-channels and the practical difficulty of maximally reducing the privilege
 of programs in real-world systems, and you have a recipe for sadness.&lt;/p>

&lt;p>Having no memory protection does make language safety paramount — clearly, we
 must have at least one of language safety and protected memory. But we also know
 that there will always be unavoidable zones of language un-safety, even if they
 are few and small. (Although it’s worth noting that, according to Foxall, et
 al., “Furthermore, it was decided that PROTEL should be the only implementation
 language — no assembly language was provided for DMS-100.”) In the end, even
 Singularity had to provide virtual memory protection. I do think, though, that
 strong language safety provides trustworthiness that can allow us to reduce the
 proliferation of memory protected address spaces, and hence to regain some
 efficiency.&lt;/p>

&lt;p>Here’s a simple example of scripting in the DMS-100 shell — it was still in
 use at least as late as 2012:&lt;/p>

&lt;iframe width="560" height="315" src="https://www.youtube.com/embed/6r151EuVlfQ" title="YouTube video player"
 frameborder="0" allow="accelerometer; autoplay;
clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen loading="lazy">&lt;/iframe>

&lt;p>And, finally, your moment of Zen (Cashin, et al.):&lt;/p>

&lt;blockquote>Rather than increasing complexity by allowing module nesting as in
 ADA, our experience leads us to believe that even our current structure may be
 more complex than necessary. Instead, it may be sufficient to have a structure
 consisting of a linear chain of interface sections and a single implementation
 section. This would increase the efficiency of the support system since symbolic
 information would no longer need to be placed in implementation section object
 files thus eliminating the need for a linker.&lt;/blockquote></description><author>Chris Palmer</author><guid>2023/05/21/protel-sos-dsm-100/index.html</guid><pubDate>Sun, 21 May 2023 00:00:00 +0000</pubDate></item><item><title>size_t Is Not int</title><link>https://noncombatant.org/2023/02/12/int-size-t/index.content</link><description>&lt;h1>&lt;code>size_t&lt;/code> Is Not &lt;code>int&lt;/code>&lt;/h1>

&lt;p>&lt;time>12 February 2023&lt;/time>&lt;/p>

&lt;aside>
 &lt;p>&lt;b>Update, 13 February:&lt;/b> I made an amusing and instructive error,
 detailed below!&lt;/p>
&lt;/aside>

&lt;p>Many C and C++ programmers write code as if they believe that
 &lt;code>size_t&lt;/code> is a &lt;code>typedef&lt;/code> for, or otherwise equivalent to,
 &lt;code>signed int&lt;/code>. Such code is unnecessarily buggy and unsafe, because
 that belief is not true. It never could have been true, and never has been.
 Yet
 classes of bugs are pervasive because the false belief persists.
&lt;/p>

&lt;h2>Definitions&lt;/h2>

&lt;p>Let’s look at the first real C standard, C89. (Well, &lt;a
 href="https://port70.net/~nsz/c/c89/c89-draft.html">a copy of
 the draft&lt;/a>,
 since that’s all we can get for free.) Modern C and C++ standards documents
 state matters somewhat more completely (and sometimes more clearly), but I
 want
 to show that the distinction between &lt;code>size_t&lt;/code> and &lt;code>int&lt;/code>
 goes back 2 generations. In any case it is fair to say that code written after
 1989 must show awareness of this crucial distinction.&lt;/p>

&lt;p>&lt;a href="https://port70.net/~nsz/c/c89/c89-draft.html#4.1.5">Section
 4.1.5&lt;/a> defines the type &lt;code>size_t&lt;/code>:&lt;/p>

&lt;blockquote>&lt;code>size_t&lt;/code>[,] which is the unsigned integral type of the
 result of the &lt;code>sizeof&lt;/code> operator;&lt;/blockquote>

&lt;p>&lt;a href="https://port70.net/~nsz/c/c89/c89-draft.html#3.3.3.4">Section
 3.3.3.4, The &lt;code>sizeof&lt;/code> operator&lt;/a>, explains what
 &lt;code>sizeof&lt;/code>
 is all about:
&lt;/p>

&lt;blockquote>

 &lt;p>The &lt;code>sizeof&lt;/code> operator yields the size (in bytes) of its operand,
 which may be an expression or the parenthesized name of a type. The size is
 determined from the type of the operand, which is not itself evaluated. The
 result is an integer constant.&lt;/p>

 &lt;p>[...] When applied to an operand that has array type, the result is the
 total
 number of bytes in the array. When applied to an operand that has structure
 or
 union type, the result is the total number of bytes in such an object,
 including
 internal and trailing padding.&lt;/p>

 &lt;p>The value of the result is implementation-defined, and its type (an
 unsigned
 integral type) is &lt;code>size_t&lt;/code> defined in the &amp;lt;stddef.h&amp;gt;
 header.&lt;/p>

 &lt;p>[...] A principal use of the &lt;code>sizeof&lt;/code> operator is in
 communication
 with routines such as storage allocators and I/O systems. A
 storage-allocation
 function might accept a size (in bytes) of an object to allocate and return
 a
 pointer to void. For example:&lt;/p>

 &lt;pre>
extern void *alloc();
double *dp = alloc(sizeof *dp);
&lt;/pre>

 &lt;p>[...] Another use of the &lt;code>sizeof&lt;/code> operator is to compute the
 number of members in an array:&lt;/p>

 &lt;pre>
sizeof array / sizeof array[0]
&lt;/pre>

&lt;/blockquote>

&lt;p>In the example, &lt;code>alloc&lt;/code> is a hypothetical memory allocation
 function, but we find also that C89’s actual allocation functions,
 &lt;code>calloc&lt;/code>, &lt;code>malloc&lt;/code>, and &lt;code>realloc&lt;/code>, also use
 &lt;code>size_t&lt;/code> for their size arguments&lt;a id="fn1_back">&lt;/a>&lt;a
 href="#fn1">①&lt;/a>. For example, from &lt;a
 href="https://port70.net/~nsz/c/c89/c89-draft.html#4.10.3.3">section
 4.10.3.3&lt;/a>:
&lt;/p>

&lt;blockquote>
 &lt;pre>
void *malloc(size_t size);
&lt;/pre>
&lt;/blockquote>

&lt;p>and similarly, &lt;a
 href="https://port70.net/~nsz/c/c89/c89-draft.html#4.10.3.1">&lt;code>calloc&lt;/code>
 is defined as&lt;/a>:&lt;/p>

&lt;blockquote>
 &lt;pre>
void *calloc(size_t nmemb, size_t size);
&lt;/pre>
&lt;/blockquote>

&lt;p>Although &lt;a
 href="https://port70.net/~nsz/c/c89/c89-draft.html#3.3.2.1">section 3.3.2.1,
 Array subscripting&lt;/a>, says only vaguely that a subscript of an array
 “shall
 have integral type”, we know from the above that that integral type must
 ultimately be &lt;code>size_t&lt;/code>. This is for 2 reasons.&lt;/p>

&lt;p>First, &lt;code>size_t&lt;/code> must be an unsigned integral value with the width
 of a machine word, so that it can be possible for a C program to index any
 position in the machine’s address space. (See &lt;a
 href="#practical-implications">Practical Implications&lt;/a>.)&lt;/p>

&lt;p>Second, since it’s unsigned, &lt;code>size_t&lt;/code> may have twice (or more) the
 positive range of a &lt;code>signed int&lt;/code>. So if the subscript type were
 &lt;code>signed int&lt;/code>, it might be possible to allocate (using
 &lt;code>size_t&lt;/code>) an array with more elements than can be indexed (using
 &lt;code>int&lt;/code>).
&lt;/p>

&lt;p>&lt;b>Therefore, we must conclude that &lt;code>size_t&lt;/code> is the only correct
 type for all sizes, lengths, object counts, and indices/subscripts.&lt;/b> C89
 and
 its standard library use it pervasively for these purposes; not just in
 allocation functions but in functions like &lt;code>strlen&lt;/code>,
 &lt;code>memset&lt;/code>, &lt;code>memcpy&lt;/code> — &lt;a
 href="https://port70.net/~nsz/c/c89/c89-draft.html#A.3.12">all those old
 friends&lt;/a>.
&lt;/p>

&lt;a id="practical-implications">&lt;/a>
&lt;h2>Practical Implications&lt;/h2>

&lt;p>I have a 64-bit machine with 32 GiB of memory. On this system,
 &lt;code>int&lt;/code> is 32 bits and &lt;code>size_t&lt;/code> is 64. Using C++ to get
 access to &lt;code>std::is_signed&lt;/code>, we see:
&lt;/p>

&lt;pre>
% &lt;b>cat &lt;a href="types.cc">types.cc&lt;/a>&lt;/b>
#include &amp;lt;stdio.h&amp;gt;
#include &amp;lt;limits&amp;gt;
#include &amp;lt;type_traits&amp;gt;

using namespace std;

int main() {
 constexpr bool is_int_signed = is_signed&amp;lt;int&amp;gt;::value;
 printf("sizeof(int): %zu; signed: %d\n", sizeof(int), is_int_signed);
 printf("largest int value: %d\n", numeric_limits&amp;lt;int&amp;gt;::max());

 constexpr bool is_uint_signed = is_signed&amp;lt;unsigned&amp;gt;::value;
 printf("sizeof(unsigned): %zu; signed: %d\n", sizeof(unsigned), is_uint_signed);
 printf("largest unsigned value: %u\n", numeric_limits&amp;lt;unsigned&amp;gt;::max());

 constexpr bool is_size_t_signed = is_signed&amp;lt;size_t&amp;gt;::value;
 printf("sizeof(size_t): %zu; signed: %d\n", sizeof(size_t), is_size_t_signed);
 printf("largest size_t value: %zu\n", numeric_limits&amp;lt;size_t&amp;gt;::max());
}
% &lt;b>make types &amp;&amp; ./types&lt;/b>
clang++ -Weverything -Werror -std=c++20 types.cc -o types
sizeof(int): 4; signed: 1
largest int value: 2147483647
sizeof(unsigned): 4; signed: 0
largest unsigned value: 4294967295
sizeof(size_t): 8; signed: 0
largest size_t value: 18446744073709551615
&lt;/pre>

&lt;p>As you can see, if &lt;code>malloc&lt;/code> and friends took &lt;code>int&lt;/code>
 arguments, it would be possible to allocate only 2 GiB (2,147,483,647 bytes).
 Even if these functions took &lt;code>unsigned int&lt;/code> arguments, it would be
 possible to allocate only 4 GiB (4,294,967,295 bytes). For my fancy modern
 machine, these would be unacceptable limitations.&lt;/p>

&lt;p>On a 32-bit machine, which can only address 4 GiB, &lt;code>size_t&lt;/code> is
 indeed equivalent to &lt;code>uint32_t int&lt;/code>. But on a 64-bit machine,
 &lt;code>size_t&lt;/code> must be equivalent to &lt;code>uint64_t&lt;/code>, and so it is.
 That is why this works:
&lt;/p>

&lt;pre>
% &lt;b>cat &lt;a href="large.c">large.c&lt;/a>&lt;/b>
#include &amp;lt;stdio.h&amp;gt;
#include &amp;lt;stdlib.h&amp;gt;
#include &amp;lt;string.h&amp;gt;

int main() {
 size_t gib = 1 &amp;lt;&amp;lt; 30;
 size_t ten_gib = 10 * gib;
 printf("About to allocate %zu bytes\n", ten_gib);
 char* large = malloc(ten_gib);
 memset(large, 'A', ten_gib);
 printf("The last byte is: %c\n", large[ten_gib - 1]);
}
% &lt;b>make large &amp;&amp; time ./large&lt;/b>
clang -Weverything -Werror -std=c2x large.c -o large
About to allocate 10737418240 bytes
The last byte is: A
./large 2.49s user 3.40s system 90% cpu 6.540 total
&lt;/pre>

&lt;p>Even on a 32-bit machine, where &lt;code>size_t&lt;/code> is &lt;code>uint32_t&lt;/code>,
 i.e. there is no difference in width, the difference in signedness still
 matters. You might think that, on machines of this era, since the kernel used
 up
 half of the 4 GiB the address space and userland got the other half, it would
 be
 OK for &lt;code>size_t&lt;/code> to be a signed 32-bit type — you can only allocate
 at
 most 2 GiB anyway, right?&lt;/p>

&lt;p>Well, no. First, it is possible, desirable, and commonplace for &lt;a
 href="https://www.kernel.org/doc/html/v5.0/vm/highmem.html">the kernel to
 use 1
 GiB of the address space, leaving 3 GiB for userland&lt;/a> on 32-bit systems.
 If
 you want to write a program to operate on 2.5 GiB of data, &lt;code>size_t&lt;/code>
 being unsigned makes that possible.&lt;/p>

&lt;p>Second, you might not be writing code for a traditional operating system that
 puts the kernel and userland in the same address space (albeit with different
 page protections). You might be writing code for a special system for which
 even
 the application runs in kernel mode and needs to access all 4 GiB of the
 address
 space. Again, &lt;code>size_t&lt;/code> being unsigned makes that possible.&lt;/p>

&lt;h2>Bugs&lt;/h2>

&lt;p>Using &lt;code>int&lt;/code> as the type for sizes and subscripts would in
 principle lead not just to unnecessary limitations, but &lt;b>actually does&lt;/b>
 lead to unnecessary bugs.&lt;/p>

&lt;p>To see why and how, first remember that signed integer overflow is undefined
 behavior (UB) in C and C++. From &lt;a
 href="https://port70.net/~nsz/c/c89/c89-draft.html#A.6.2">appendix 6.2&lt;/a>:
&lt;/p>

&lt;blockquote>

 &lt;p>The behavior in the following circumstances is undefined:&lt;/p>

 &lt;p>[...]&lt;/p>

 &lt;li>An arithmetic operation is invalid (such as division or modulus by 0) or
 produces a result that cannot be represented in the space provided (such as
 overflow or underflow) (3.3).&lt;/li>

&lt;/blockquote>

&lt;p>That is, an expression such as &lt;code>INT_MAX + n&lt;/code> (where &lt;var>n&lt;/var>
 is an &lt;code>int&lt;/code> greater than 0) has no particular meaning, and the
 compiler can therefore interpret it to mean anything. Usually this means the
 compiler will optimize away code that ‘cannot’ happen, or make other
 assumptions
 that might not match your own. Therefore, statements and expressions that
 exercise UB cannot in general be correct. Even if code with UB &lt;b>appears&lt;/b>
 to
 work, the people affected by that code are just getting lucky. For now. New
 inputs, or new compilers, might change the program’s behavior.&lt;/p>

&lt;p>However, in &lt;a
 href="https://port70.net/~nsz/c/c89/c89-draft.html#3.1.2.5">section
 3.1.2.5&lt;/a>,
 C89 provides a carve-out for unsigned arithmetic:&lt;/p>

&lt;blockquote>A computation involving unsigned operands can never overflow,
 because a result that cannot be represented by the resulting unsigned integer
 type is reduced modulo the number that is one greater than the largest value
 that can be represented by the resulting unsigned integer type.&lt;/blockquote>

&lt;p>That is, arithmetic on unsigned types is modular arithmetic: &lt;code>UINT_MAX
+ 1&lt;/code> is defined to wrap back around to 0, like the odometer in a car.&lt;/p>

&lt;p>This has important implications for correctness in memory allocation and
 subscripting. For example, this code has several bugs:&lt;/p>

&lt;pre>
 int count = ...;

 // Implicit cast from `size_t` to `int`; possible (though not in this case)
 // truncation.
 int size = sizeof(Thing);

 // The signed multiplication could overflow and is technically UB. If
 // you’re lucky, your implementation might define it to be modular, and
 // to wrap. But then you’re allocating a region that cannot hold `count`
 // `Thing`s — it will have wrapped around to a too-small value.
 //
 // In any case, the result of the multiplication is cast to `size_t` for
 // the call to `malloc`, which may result in &lt;a href="https://en.wikipedia.org/wiki/Sign_extension">sign extension&lt;/a>, which
 // might result in even more weirdness.
 Thing* things = malloc(count * size); 

 // At this point, if the allocation succeeded and if `things` points to a
 // region of memory large enough to hold `count` `Thing`s, it’s pure luck.
 // This code is incorrect, even if it ‘seems to work’.

 for (int i = 0; i &amp;lt; count; i++) {
 things[i] = ...;
 }
&lt;/pre>

&lt;p>Code like this is widespread; I’ve seen it in the wild many times. Especially
 when the value of &lt;code>count&lt;/code> and/or the data that get copied into
 &lt;code>things&lt;/code> come from an untrustworthy source (like the network), such
 code is often straightforwardly exploitable&lt;a id="fn2_back">&lt;/a>&lt;a
 href="#fn2">②&lt;/a>.
&lt;/p>

&lt;p>We can make code like this less incorrect by doing something like this:&lt;/p>

&lt;pre>
#include &amp;lt;stdckdint.h&amp;gt;

// ...

 const size_t count = ...;
 const size_t size = sizeof(Thing);
 size_t total;
 if (ckd_mul(&amp;amp;total, count, size)) {
 return ENOMEM;
 }
 Thing* things = malloc(total);
&lt;/pre>

&lt;p>&lt;code>ckd_mul&lt;/code> is a standard C23 function that returns true if the
 multiplication overflowed. Yes, &lt;a
 href="https://gustedt.wordpress.com/2022/12/18/checked-integer-arithmetic-in-the-prospect-of-c23/">C
 will introduce checked arithmetic in November 2023&lt;/a>, 51 entire years
 after
 the language was born. Until then, you can (and should) use &lt;a
 href="https://clang.llvm.org/docs/LanguageExtensions.html#checked-arithmetic-builtins">non-standard
 compiler intrinsics&lt;/a>, or you can try to roll your own check:&lt;/p>

&lt;pre>
#include &amp;lt;stdbool.h&amp;gt;
#include &amp;lt;stddef.h&amp;gt;

// &lt;b>Update:&lt;/b> This is wrong! See below.
bool check_mul(size_t* result, size_t x, size_t y) {
 size_t r = x * y;
 if (r &amp;lt; x || r &amp;lt; y) {
 return true;
 }
 *result = r;
 return false;
}

// ...

 const size_t count = ...;
 const size_t size = sizeof(Thing);
 size_t total = 0;
 if (check_mul(&amp;amp;total, count, size)) {
 return ENOMEM;
 }
&lt;/pre>

&lt;p>&lt;s>Note that you &lt;b>must&lt;/b> use unsigned types in functions like
 &lt;code>check_mul&lt;/code> above! (I.e. the ‘check if result was smaller’
 style.)&lt;/s> If you use signed types, the multiplication may overflow and
 will
 thus be undefined, and the compiler will therefore typically assume that
 overflow cannot happen. Then it will likely ‘optimize’ the code by removing
 your
 ‘dead’ &lt;code>if&lt;/code> block — removing your safety check.&lt;/p>

&lt;aside>
 &lt;p>&lt;b>Update:&lt;/b> Inevitably, sigh 😅, I got this wrong, which I would have
 noticed if I had done an exhaustive check of &lt;code>uint32_t&lt;/code> as I did
 for another problem, below. (There’s a lesson there!) Jann Horn points out
 that “you can get a multiplication overflow and still have a result that is
 bigger than the two operands”, e.g. 0x10000 * 0x11000 = 0x110000000. Thank
 you, Jann! Let’s stick with stdckdint.h or compiler intrinsics.&lt;/p>
&lt;/aside>

&lt;p>If you need to check signed arithmetic, you must check limits before doing
 the potentially undefined operation. For example:&lt;/p>

&lt;pre>
#include &amp;lt;stdbool.h&amp;gt;
#include &amp;lt;stddef.h&amp;gt;

bool checked_mul(int* result, int x, int y) {
 if (x == 0 || y == 0) {
 *result = 0;
 return false;
 }
 if (x &amp;lt; 0 || y &amp;lt; 0) {
 // TODO: You have even more work to do. See e.g.
 // https://github.com/coreutils/gnulib/blob/master/lib/intprops-internal.h#L370
 // for a type-generic macro that handles all cases. `ckd_mul` and the
 // non-standard intrinsics are lookin’ pretty good right about now... 😉
 abort(); 
 }
 if (INT_MAX / x &amp;lt; y || INT_MAX / y &amp;lt; x) {
 return true;
 }
 *result = x * y;
 return false;
}
&lt;/pre>

&lt;p>If that all sounds like a pain in the ass (because it is), you can use
 &lt;code>calloc&lt;/code>. In C23 (see section 7.24.3.2 of &lt;a
 href="https://open-std.org/JTC1/SC22/WG14/www/docs/n3054.pdf">the C23
 draft&lt;/a>), and in responsible implementations going back 15+ years,
 &lt;code>calloc&lt;/code> is defined to check the &lt;code>count * size&lt;/code>
 multiplication and to return &lt;code>NULL&lt;/code> if the product is too
 large&lt;a id="fn3_back">&lt;/a>&lt;a href="#fn3">③&lt;/a>.
&lt;/p>

&lt;p>Basically, do not use &lt;code>malloc&lt;/code> directly. Idiomatic usage is
 typically incorrect and unsafe. Security reviewers like to find some easy
 pickins by looking at a codebase, running &lt;code>grep -ri alloc *&lt;/code>, and
 looking for overflowing arithmetic expressions. They can find a lot of fun
 stuff. (Try it yourself! You can do much more along these lines with &lt;a
 href="https://github.com/weggli-rs/weggli">weggli by Felix Wilhelm et
 al&lt;/a>.)&lt;/p>

&lt;h3>These Bugs Are Old And Subtle&lt;/h3>

&lt;p>In &lt;a
 href="https://ai.googleblog.com/2006/06/extra-extra-read-all-about-it-nearly.html">Extra,
 Extra - Read All About It: Nearly All Binary Searches and Mergesorts are
 Broken&lt;/a>, by Joshua Bloch in 2006, we learn that even the simple binary
 search
 turns out to be buggy due to the use of the wrong subscript type. In 2
 languages, no less! Java was defined to use &lt;code>int&lt;/code> as its array
 index
 type, and &lt;code>int&lt;/code> is defined as a signed 32-bit integer. Unlike C,
 Java
 &lt;code>int&lt;/code> is defined to have modular behavior on overflow, like C’s
 unsigned types.
&lt;/p>

&lt;p>The buggy line is in finding a new midpoint for the search:&lt;/p>

&lt;blockquote>
 &lt;pre>
int mid = (low + high) / 2;
&lt;/pre>
&lt;/blockquote>

&lt;p>In C, this is UB and there are no guarantees whatsoever. (Bloch says that “In
 C this causes an array index out of bounds with unpredictable results”, but
 spatial unsafety is the outcome only if the people affected by your program
 are
 ‘lucky’ and the arithmetic overflow is implemented to have modular behavior.
 But
 there’s no guarantee of that, so the C version of this program has extra bonus
 UB: arithmetic overflow and buffer overflow.)&lt;/p>

&lt;p>In Java, the code is incorrect but safe, because the arithmetic overflow is
 defined and the invalid array access is defined. This is why I like to say,
 “Java actually is what people imagine C to be.” What is UB in C is very often
 well-defined in Java.&lt;/p>

&lt;p>That said, Java is still wrong to have used &lt;code>int&lt;/code> as the array
 index type, even if only because it is an unnecessary limitation on program
 data
 size (as discussed above). But it also leads to this incorrectness problem
 — in
 Java, the program will &lt;code>throw&lt;/code> when it actually could have
 successfully completed the binary search. Bloch notes that 1 way to fix it is
 to
 use (you guessed it) unsigned arithmetic:&lt;/p>

&lt;blockquote>

 &lt;p>Probably faster, and arguably as clear is:&lt;/p>

 &lt;pre>
int mid = (low + high) &amp;gt;&amp;gt;&amp;gt; 1;
&lt;/pre>

 &lt;p>In C and C++ (where you don’t have the &lt;code>&amp;gt;&amp;gt;&amp;gt;&lt;/code> operator),
 you can do this:&lt;/p>

 &lt;pre>
mid = ((unsigned int)low + (unsigned int)high)) &amp;gt;&amp;gt; 1;
&lt;/pre>

&lt;/blockquote>

&lt;p>Those approaches will work when &lt;code>low&lt;/code> and &lt;code>high&lt;/code> are
 &lt;code>int&lt;/code>s and thus their sum will always fit in &lt;code>unsigned
int&lt;/code>.
&lt;/p>

&lt;p>But if we used the correct index type, &lt;code>size_t&lt;/code>, we don’t have the
 extra headroom of &lt;code>unsigned&lt;/code> — it’s already unsigned — so we need
 to
 actually ensure that the overflow does not happen. Bloch’s first solution,&lt;/p>

&lt;blockquote>
 &lt;pre>
int mid = low + ((high - low) / 2);
&lt;/pre>
&lt;/blockquote>

&lt;p>is the only one that yields the correct midpoint in all cases.&lt;/p>

&lt;p>To see why, consider an extreme case, in which we are indexing a giant array
 of bytes that holds all bytes in the address space. We can see that
 calculating
 the true midpoint requires care in modular arithmetic, both for 32- and 64-bit
 sizes. (For the 64-bit case, pretend for the moment that we can afford that
 much
 RAM, and that we have a machine that actually does use all 64 bits for
 addressing bytes.)&lt;/p>

&lt;pre>
% &lt;b>cat &lt;a href="midpoint.c">midpoint.c&lt;/a>&lt;/b>
#include &amp;lt;assert.h&amp;gt;
#include &amp;lt;inttypes.h&amp;gt;
#include &amp;lt;limits.h&amp;gt;
#include &amp;lt;stdio.h&amp;gt;

int main() {
 {
 static_assert(sizeof(unsigned) == sizeof(uint32_t),
 "Assuming `unsigned` is `uint32_t`");
 printf("32-bit:\n");
 const uint32_t low = UINT_MAX - 2;
 const uint32_t high = UINT_MAX;
 uint32_t mid = (low + high) / 2;
 printf("(%" PRIu32 " + %" PRIu32 ") / 2 = %" PRIu32 "\n", low, high, mid);

 mid = low + ((high - low) / 2);
 printf("%" PRIu32 " + ((%" PRIu32 " - %" PRIu32 ") / 2) = %" PRIu32 "\n",
 low, high, low, mid);
 }

 {
 static_assert(sizeof(size_t) == sizeof(uint64_t),
 "Assuming `size_t` is `uint64_t`");
 printf("64-bit:\n");
 const uint64_t low = SIZE_T_MAX - 2;
 const uint64_t high = SIZE_T_MAX;
 uint64_t mid = (low + high) / 2;
 printf("(%" PRIu64 " + %" PRIu64 ") / 2 = %" PRIu64 "\n", low, high, mid);

 mid = low + ((high - low) / 2);
 printf("%" PRIu64 " + ((%" PRIu64 " - %" PRIu64 ") / 2) = %" PRIu64 "\n",
 low, high, low, mid);
 }
}
% &lt;b>make midpoint &amp;&amp; ./midpoint&lt;/b>
clang -Weverything -Werror -std=c2x midpoint.c -o midpoint
32-bit:
(4294967293 + 4294967295) / 2 = 2147483646
4294967293 + ((4294967295 - 4294967293) / 2) = 4294967294
64-bit:
(18446744073709551613 + 18446744073709551615) / 2 = 9223372036854775806
18446744073709551613 + ((18446744073709551615 - 18446744073709551613) / 2) = 18446744073709551614
&lt;/pre>

&lt;p>Obviously, on a 64-bit machine, we are highly unlikely to find ourselves
 exercising this edge case. ☺️ (Although &lt;a
 href="https://www.qualys.com/2020/05/19/cve-2005-1513/remote-code-execution-qmail.txt">don’t
 get &lt;b>too&lt;/b> complacent&lt;/a>.) But as you can see, with 32-bit
 &lt;code>size_t&lt;/code>, we are well within range of trouble. (See demo below.)
&lt;/p>

&lt;p>In any case, I would rather have such foundational functions as binary search
 be correct because they are correct, rather than ‘good enough’ contingent on
 the
 limitations of the platform the program runs on.&lt;/p>

&lt;p>That said, on a 64-bit machine, we can emulate and exhaustively test what
 would happen in a 32-bit machine if we were to use &lt;code>uint32_t&lt;/code> to
 emulate &lt;code>size_t&lt;/code> as the index type. My example program, &lt;a
 href="exhaustive.c">exhaustive.c&lt;/a>, creates an
 array with 4 billion elements,
 and then attempts to use binary search to find all of them. It shows that if
 you
 use an unsigned index type, you have to use (as midpoint.c suggests) the
 &lt;code>low + ((high - low) / 2)&lt;/code> method to get a correct program. Using
 the
 correct arithmetic takes about 6 minutes on my laptop:
&lt;/p>

&lt;pre>
% &lt;b>date ; time ./exhaustive c ; date&lt;/b>
Sat Feb 11 22:35:47 PST 2023
Created sorted array of `uint32_t` values.
./exhaustive c 347.17s user 8.99s system 95% cpu 6:13.90 total
Sat Feb 11 22:42:01 PST 2023
&lt;/pre>

&lt;p>The incorrect arithmetic gets stuck in an infinite loop, unable to find a
 valid midpoint (as midpoint.c suggested will happen). In this example, I gave
 up
 after 18 minutes:&lt;/p>

&lt;pre>
% &lt;b>date ; time ./exhaustive i ; date&lt;/b>
Sat Feb 11 22:42:29 PST 2023
Created sorted array of `uint32_t` values.
^C
./exhaustive i 1031.42s user 18.88s system 95% cpu 18:22.13 total
&lt;/pre>

&lt;h2>Conclusion&lt;/h2>

&lt;p>Types matter. That ‘everything is an &lt;code>int&lt;/code> in C’ is no more true
 than that ‘everything is a list in Lisp’ — and we should be glad of that! &lt;a
 href="https://en.wikipedia.org/wiki/B_(programming_language)">The nearly
 typeless B language&lt;/a>, and the untyped lambda calculus, are insufficient
 as
 programming tools. Application-domain types clearly matter, but primitive
 types
 matter too — perhaps especially, since higher-level types and functions are
 built on the primitives.&lt;/p>

&lt;p>Proofs of correctness of binary search are valid only on the assumption that
 languages can easily express correct integer arithmetic. (&lt;a
 href="https://www.cs.cornell.edu/courses/cs211/2006sp/Lectures/L06-Induction/binary_search.html">See
 this one, for example&lt;/a>.) In fact, of course, our programming languages
 make
 expressing even simple arithmetic incredibly difficult and unwieldy. A
 complete
 proof must take the failures of real-world language design into account. This
 gap between theory and practice, between computing science and software
 engineering, is wider than people sometimes realize&lt;a id="fn4_back">&lt;/a>&lt;a
 href="#fn4">④&lt;/a>.&lt;/p>

&lt;p>As for the not-fully-correct solution being “probably faster”, that is
 unlikely to be significant. The practical performance difference between
 &lt;code>mid = ((unsigned int)low + (unsigned int)high)) &amp;gt;&amp;gt; 1&lt;/code> and
 &lt;code>int mid = low + ((high - low) / 2)&lt;/code> is 1 additional subtraction
 operation on registers, i.e. 1 machine cycle. (&lt;a
 href="https://godbolt.org/z/sPqTG96fd">The &lt;code>/ 2&lt;/code> gets
 optimized to
 &lt;code>&amp;gt;&amp;gt; 1&lt;/code> on a modern optimizing compiler&lt;/a>.) In a loop
 involving non-local accesses to main memory — you’re jumping around in the
 array, not processing it in a linear, cache-friendly way — that fraction of
 a nanosecond is not going to make or break the performance-fitness of your
 program.
&lt;/p>

&lt;p>Assuming we’re already using the best available data structures and
 algorithms, the most significant way to make programs faster is by increasing
 parallelism. In general, correctness and safety are crucial to achieving
 parallelism. Observing the distinctions between types is a particularly
 effective way to improve program correctness and safety.&lt;/p>

&lt;p>In any case, we’ve been living with unnecessarily buggy C/C++ programs since
 1989, even accounting for all the other kinds of bugs inherent and special to
 C/C++. 33 years of entirely preventable bugs and exploitable vulnerabilities,
 all because it’s too hard to express the 1 thing computers actually do:
 arithmetic.&lt;/p>

&lt;p>A good engineer never blames their tools. But a good engineer is always
 searching for the best available tools.&lt;/p>

&lt;hr />

&lt;p>&lt;a id="fn1">&lt;/a>&lt;a href="#fn1_back">&lt;b>1.&lt;/b>&lt;/a> K&amp;amp;R, 2nd edition,
 page 187 shows a version of &lt;code>malloc&lt;/code> taking &lt;code>unsigned&lt;/code>,
 while p. 167 has it correct as &lt;code>size_t&lt;/code>. It seems likely that
 K&amp;amp;R
 just forgot to update the example on p. 187 when updating the book for the 2nd
 edition, which was updated to describe C89.&lt;/p>

&lt;p>&lt;a id="fn2">&lt;/a>&lt;a href="#fn2_back">&lt;b>2.&lt;/b>&lt;/a> When interviewing
 security-focused engineers, I often ask them to spot the bugs in code like
 this,
 and to explain how it could be exploited.&lt;/p>

&lt;p>&lt;a id="fn3">&lt;/a>&lt;a href="#fn3_back">&lt;b>3.&lt;/b>&lt;/a> If application-specific
 macro-benchmarks and testing show that &lt;code>calloc&lt;/code>’s zeroing memory
 makes the program too slow for its purpose, you can define your own allocation
 function that checks the multiplication and then passes the result to
 &lt;code>malloc&lt;/code>. Of course, this point only applies if your application
 has
 performance fitness tests. Unless you have such tests, &lt;code>calloc&lt;/code> is
 not too slow.
&lt;/p>

&lt;p>&lt;a id="fn4">&lt;/a>&lt;a href="#fn4_back">&lt;b>4.&lt;/b>&lt;/a> It reminds me a bit of
 how with big-O notation, we ignore constant factors because in principle they
 don’t matter — but in practice, for actual inputs to algorithms implemented on
 actual computers, the constant factors can be decisive.&lt;/p></description><author>Chris Palmer</author><guid>2023/02/12/int-size-t/index.html</guid><pubDate>Sun, 12 Feb 2023 00:00:00 +0000</pubDate></item><item><title>“The Emperor’s Old Clothes”</title><link>https://noncombatant.org/2023/01/15/hoare-emperors-old-clothes/index.content</link><description>&lt;h1>“The Emperor’s Old Clothes”&lt;/h1>

&lt;p>&lt;time>15 January 2023&lt;/time>&lt;/p>

&lt;p>Tony Hoare provided my favorite definition of security in his Turing Award
 lecture “The Emperor’s Old Clothes”:&lt;/p>

&lt;blockquote>The first principle was security: The principle that every
 syntactically incorrect program should be rejected by the compiler and that
 every syntactically correct program should give a result or an error message
 that was predictable and comprehensible in terms of the source language program
 itself&lt;/blockquote>

&lt;p>He mentions spatial memory safety in particular, as it is the first and
 unavoidable kind of unsafety we encounter. (I’d say both as individuals, when we
 start learning C and assembly, and also in the history of software development
 — programs in the era he is talking about often did not have object lifetimes
 other than static and stack, so temporal safety was less of an issue.)&lt;/p>

&lt;p>But if we work through the implications of Hoare’s 1st principle, it becomes
 clear that safety must mean (at least) all of spatial and temporal memory
 safety, and also type safety. It’s worth noting that the need for lifetime
 safety was recognized &lt;a
 href="https://en.wikipedia.org/wiki/Garbage_collection_(computer_science)#:~:text=Garbage%20collection%20was%20invented%20by,manual%20memory%20management%20in%20Lisp.">and
 implemented&lt;/a> almost immediately after the first dynamic language was
 invented. And we know &lt;a
 href="https://qconlondon.com/london-2009/qconlondon.com/london-2009/speaker/Tony+Hoare.html">he
 regrets inventing meaningless references&lt;/a>.&lt;/p>

&lt;p>So Hoare wants for machines to never be &lt;i>weird&lt;/i>, in &lt;a
 href="http://www.dullien.net/thomas/weird-machines-exploitability.pdf">Thomas
 Dullien’s sense&lt;/a>. It must at least be possible to program a computer, even if
 difficult. This is especially important given the unavoidable complexity of
 programming:&lt;/p>

&lt;blockquote>Programmers are always surrounded by complexity; we cannot avoid it.
 Our applications are complex because we are ambitious to use our computers in
 ever more sophisticated ways. Programming is complex because of the large number
 of conflicting objectives for each of our programming projects. If our basic
 tool, the language in which we design and code our programs, is also
 complicated, the language itself becomes part of the problem rather than part of
 its solution.&lt;/blockquote>

&lt;p>Unwarranted complexity, such as weirdness and &lt;a href="https://en.cppreference.com/w/cpp">underspecified and
 inconsistent
 APIs&lt;/a>, becomes hostile to safety, utility, efficiency, &lt;a href="https://www.acm.org/code-of-ethics">our
 ethical duty&lt;/a>, and cost.&lt;/p>

&lt;a id="law">
 &lt;p>11 years after Hoare, some people in New Jersey would also go on
 to implement another dialect of Algol. But they ignored this 1st principle of
 system design. For 51 years, we have accepted extremely — and increasingly! —
 weird and unnecessarily complex machines as normal. It’s hard to overstate how
 much software engineering regressed in the 1970s. 50 years later, we have not
 dug ourselves out of the pit. There are people who benefit from this state of
 affairs. Hoare had a spicy take on that:&lt;/p>

 &lt;blockquote>In any respectable branch of engineering, failure to observe such
 elementary precautions would have long been against the law.&lt;/blockquote>
&lt;/a>

&lt;p>I’m actually not sure it’s true that it would &lt;i>long&lt;/i> have been against
 the law; much product safety regulation was relatively new at the time he wrote
 this. In any case, the seemingly in-the-weeds topic of memory safety is now &lt;a
 href="https://www.atlanticcouncil.org/content-series/buying-down-risk/memory-safety/">a
 topic of policy discussion&lt;/a>. (See also &lt;a
 href="https://www.atlanticcouncil.org/content-series/buying-down-risk/home/">the
 whole Buying Down Risk series&lt;/a>.)&lt;/p>

&lt;p>Hoare’s 2nd principle of language design is in the same vein. I’ll take the
 liberty of re-phrasing it a bit, for emphasis: Efficiency (particularly
 space-efficiency) is critical — both for its own sake, &lt;i>but also so that you
 can use the headroom to further improve reliability&lt;/i>. He even goes as far as
 to say “rugged”, which is such a beautiful vision for software.&lt;/p>

&lt;p>3rd and 4th are developer experience principles: Composition must be
 efficient, so that we can use it heavily; and, the write/test/debug loop must be
 low-latency.&lt;/p>

&lt;p>As ‘obvious’ as these principles may seem, it’s fun to think: which
 programming environments do you use that reliably satisfy all 4? I think there
 are a few (woo hoo!) but that we don’t often enough demand that this be the
 baseline.&lt;/p>

&lt;p>I love Hoare’s lecture/essay so much because it is such a pithy summary of
 hard-won and deep insights into many aspects of software development: safety,
 obviously, but also usability, reliability, business management, project and
 program management. &lt;a href="https://dl.acm.org/doi/pdf/10.1145/358549.358561">The copy on ACM’s
 site&lt;/a> is a fairly janky PDF, so I’ve reformatted it as &lt;a
 href="/hoare-emperors-old-clothes-turing-award/">plain HTML&lt;/a> for easier
 reading and correct copying and pasting. (The PDF’s text is OCR with errors,
 alas.)&lt;/p>

&lt;p>See also &lt;a href="https://blog.acolyer.org/2016/09/07/the-emperors-old-clothes/">Adrian
 Colyer’s similar paean&lt;/a>! And you might like Hoare’s &lt;a
 href="https://people.dsv.su.se/~jpalme/s1/hoare.html">Software Design: A
 Parable&lt;/a>.&lt;/p></description><author>Chris Palmer</author><guid>2023/01/15/hoare-emperors-old-clothes/index.html</guid><pubDate>Sun, 15 Jan 2023 00:00:00 +0000</pubDate></item><item><title>The Fraught Utility Of Vulnerability Disclosure Databases</title><link>https://noncombatant.org/2022/07/10/fraught-vdbs/index.content</link><description>&lt;h1>The Fraught Utility Of Vulnerability Disclosure Databases&lt;/h1>

&lt;p>&lt;time>10 July 2022&lt;/time>&lt;/p>

&lt;p>Do we need vulnerability databases? Are the ones we have working? Should we
 do something else? How can we improve our overall approach to the “WTF is going
 on?” problem?&lt;/p>

&lt;p>My strong bias is toward the scientific method — which requires open inquiry
 and easy access to knowledge — and against unreliable or false metrics. I also
 strongly resist any make-work or boondoggling that is not directly relevant to
 understanding how software works and fails, and making it work more
 goodlier.&lt;/p>

&lt;p>So, I tried to think about vulnerability databases, and what all we might
 want from them. First, some definitions.&lt;/p>

&lt;h2>Definitions&lt;/h2>

&lt;dl>

 &lt;dt>Developer:&lt;/dt>
 &lt;dd>An organization which (or lone hacker who) develops
 software.&lt;/dd>

 &lt;dt>Developer communications:&lt;/dt>
 &lt;dd>Communications from developers about
 vulnerabilities, including bug trackers, release notes, Knowledge Base articles,
 code review and CI/CQ, et c.&lt;/dd>

 &lt;dt>Researcher:&lt;/dt>
 &lt;dd>An organization which (or lone hacker who) hunts for
 vulnerabilities in software.&lt;/dd>

 &lt;dt>Researcher communications:&lt;/dt>
 &lt;dd>Communications from researchers about
 vulnerabilities, including bug trackers, advisories, blog posts, exploits, and
 Twitter threads.&lt;/dd>

 &lt;dt>Deployer:&lt;/dt>
 &lt;dd>An organization or person who is using some software to
 achieve a goal.&lt;/dd>

 &lt;dt>Vulnerability database program (VDB):&lt;/dt>
 &lt;dd>An organization that tracks,
 describes, and/or issues alerts for vulnerabilities.&lt;/dd>

&lt;/dl>

&lt;h2>Vulnerability Databases&lt;/h2>

&lt;p>What might we want in a VDB?&lt;/p>

&lt;ul>

 &lt;li>Information about the nature of the vulnerability, including:
 &lt;ul>
 &lt;li>specific versions of specific products affected;&lt;/li>
 &lt;li>attack pathways (e.g. unauthenticated internet attacker, authenticated local
 user account, et c.);&lt;/li>
 &lt;li>proof of concept (PoC) exploit, unit test, or other test: proof that the bug
 is real and that the fix works;&lt;/li>
 &lt;li>availability of the fix;&lt;/li>
 &lt;li>workarounds;&lt;/li>
 &lt;li>mitigating factors;&lt;/li>
 &lt;li>the type of bug (e.g. heap buffer overflow, SQL injection); and&lt;/li>
 &lt;li>the specific locus of the bug (e.g. the login flow, the network-facing
 &lt;code>FooHandler&lt;/code>, the kernel-mode driver, et c.).
 &lt;/li>
 &lt;/ul>
 &lt;/li>

 &lt;li>Searchability: a unique ID (or a keyword) that search engines can easily
 find. The IDs must be unique, and there should not be multiple IDs for the same
 bug.&lt;/li>

 &lt;li>Authoritativeness: ideally, most of the community will recognize a given
 information source as ✨ The Last Word ✨ in vulnerabilities for the range of
 software it covers.&lt;/li>

 &lt;li>Alert quality: timely, relevant, and actionable alerts.&lt;/li>

 &lt;li>Low overhead: for developers to add new entries to the database must be easy
 and fast. Researchers should therefore be able to get IDs for their discoveries
 quickly.&lt;/li>

&lt;/ul>

&lt;p>I made a rough comparison of 4 sources of vulnerability information:&lt;/p>

&lt;table>

 &lt;tr>
 &lt;th class="bottom">Source&lt;/th>
 &lt;th class="bottom">Information&lt;/th>
 &lt;th class="bottom">Searchability&lt;/th>
 &lt;th class="bottom">Authoritativeness&lt;/th>
 &lt;th class="bottom">Alert Quality&lt;/th>
 &lt;th class="bottom">Overhead&lt;/th>
 &lt;/tr>

 &lt;tr>
 &lt;th>CVE&lt;/th>
 &lt;td>&lt;a href="/2022/04/22/itw-taxonomy/">Poor&lt;/a>&lt;/td>
 &lt;td>Good&lt;/td>
 &lt;td>Low, due to poor information&lt;/td>
 &lt;td>&lt;a id="fn1_back">&lt;/a>Highly varying&lt;a href="#fn1">①&lt;/a>&lt;/td>
 &lt;td>High&lt;/td>
 &lt;/tr>

 &lt;tr>
 &lt;th>&lt;a href="https://www.openwall.com/ove/">OVE&lt;/a>&lt;/th>
 &lt;td>None; provides only IDs&lt;/td>
 &lt;td>Good&lt;/td>
 &lt;td>None; provides only IDs&lt;/td>
 &lt;td>None; provides only IDs&lt;/td>
 &lt;td>&lt;a href="https://en.wikipedia.org/wiki/Machine_epsilon">epsilon&lt;/a>&lt;/td>
 &lt;/tr>

 &lt;tr>
 &lt;th>Developer communications&lt;/th>
 &lt;td>&lt;a id="fn2_back">&lt;/a>Highly varying&lt;a href="#fn2">②&lt;/a>&lt;/td>
 &lt;td>Good&lt;/td>
 &lt;td>&lt;a id="fn3_back">&lt;/a>‘Should be’ ideal but varies with information quality&lt;a href="#fn3">③&lt;/a>&lt;/td>
 &lt;td>Good&lt;/td>
 &lt;td>None beyond what is inherently necessary&lt;/td>
 &lt;/tr>

 &lt;tr>
 &lt;th>Researcher communications&lt;/th>
 &lt;td>Varying; often good&lt;/td>
 &lt;td>Poor&lt;/td>
 &lt;td>Varying; sometimes good&lt;/td>
 &lt;td>Varying; sometimes good&lt;/td>
 &lt;td>None beyond what is inherently necessary&lt;/td>
 &lt;/tr>
&lt;/table>

&lt;p>From this I observe a few things:&lt;/p>

&lt;p>&lt;b>Developer communications have the best ability to meet all our
 requirements:&lt;/b> developers (should) have the best knowledge about the software
 they create, full information about the nature of the bug, full information
 about the fix, and full information about remediation. Sometimes developers do
 meet our requirements, and that is great. Ideally, they always would. All too
 often, they don’t, and keeping communications high quality requires constant
 effort and skill from program managers.&lt;/p>

&lt;p>&lt;b>Researcher communications have a great ability to meet our information
 requirements in particular.&lt;/b> Sometimes they do, and that is great. Sometimes,
 they can be more authoritative than reticent developers.&lt;/p>

&lt;p>&lt;b>CVE’s clearest benefit seems to be an authoritative source of unique ID
 numbers,&lt;/b> plus whatever information the developer might provide (usually very
 little). But in my experience the coordination cost is high for developers, and
 as a result developers often minimize their use of CVE. Hence OVE: the argument
 goes that if all CVE reliably does for us is make numbers, well, we can do that
 far more cheaply.&lt;/p>

&lt;p>&lt;b>We might benefit if program managers of VDBs stopped accepting poor, late,
 and un-actionable information from developers.&lt;/b> The CVE program, as the most
 widely recognized VDB, has an opportunity to raise the bar across the industry
 by calling out such reticent developers, citing the needs of and benefits to the
 public and basic science.&lt;/p>

&lt;p>For example, imagine if a VDB tagged entries with a message like “Developer
 declined to provide meaningful information” when the vendor provided a
 meaningless description of the vulnerability. That might exert some salutary
 pressure on developers.&lt;/p>

&lt;p>&lt;b>We would benefit if VDBs made it easier for the developer to commit
 current information to the database.&lt;/b> For example, CVE-2022-2294, which is
 currently being exploited in the wild, is documented &lt;a
 href="https://chromereleases.googleblog.com/2022/07/stable-channel-update-for-desktop.html">in
 Chrome’s 4 July 2022 release notes&lt;/a>, but &lt;a
 href="https://cve.mitre.org/cgi-bin/cvename.cgi?id=CVE-2022-2294">the CVE
 entry&lt;/a> as of 8 July contains no information, saying only:&lt;/p>

&lt;blockquote>** RESERVED ** This candidate has been reserved by an organization
 or individual that will use it when announcing a new security problem. When the
 candidate has been publicized, the details for this candidate will be
 provided.&lt;/blockquote>

&lt;p>Perhaps the CVE entry will be eventually consistent with the Chrome release
 notes, hopefully including a link to the bug tracker. (&lt;a
 href="https://chromium.googlesource.com/chromium/src/+/master/docs/security/security-labels.md#Drop-Restrict_View_SecurityTeam_SecurityNotify_From-Old-And-Fixed-Bugs">Chrome
 policy&lt;/a> is to make security bugs public 14 weeks after the fix has shipped,
 so a link to the bug tracker will become valuable in time.)&lt;/p>

&lt;h2>Prioritizing Vulnerability Response&lt;/h2>

&lt;p>What do we want in a vulnerability ‘scoring’ system? (Do we want a
 vulnerability scoring system?)&lt;/p>

&lt;p>As an experiment, I imagined a hypothetical easy to use, network-based,
 denial of service (DoS — not &lt;a
 href="https://en.wikipedia.org/wiki/Denial-of-service_attack#Distributed_DoS">DDoS&lt;/a>)
 attack, and tried to score it with CVSS. I assumed there is an existing exploit
 that doesn’t completely take down a service, but causes it to consume lots of
 time and/or space.&lt;/p>

&lt;p>&lt;a id="fn4_back">&lt;/a>For example, imagine a database query that, for some
 reason, is slow in a given database engine. It is for some reason (less than SQL
 injection, more than just using the site normally) remotely-triggerable. Perhaps
 an attacker can make some unauthenticated web request that invokes this
 expensive query, and it’s expensive only because the query planner has a bug
 — normally, the query would be efficient&lt;a href="#fn4">④&lt;/a>.&lt;/p>

&lt;p>The CVSS vector I got is&lt;/p>

&lt;pre>
AV:N/AC:L/PR:N/UI:N/S:U/C:N/I:N/A:L/E:F/RL:U/RC:C/CR:X/IR:X/AR:H/MAV:N/MAC:L/MPR:N/MUI:N/MS:U/MC:N/MI:N/MA:L
&lt;/pre>

&lt;p>which scores 6.0 in &lt;a href="https://nvd.nist.gov/vuln-metrics/cvss/v3-calculator">NIST’s CVSS 3.1
 calculator&lt;/a>.&lt;/p>

&lt;p>Since that string is just noise, let’s look at a graphic:&lt;/p>

&lt;figure>&lt;img src="calculator.png" width="1024" height="302" alt="A screenshot of
the NIST CVSS calculator showing the hypothetical bug with a score of 6.0" loading="lazy" />
 &lt;figcaption>More readable, though not more
 informative.&lt;/figcaption>
&lt;/figure>

&lt;p>What does “6.0” mean? Is it high enough to call &lt;a
 href="https://en.wikipedia.org/wiki/Site_reliability_engineering">the on-call
 SRE&lt;/a>? Do we only get out of bed for 7.5 or higher? (Why 7.5?) Is this bug bad
 enough to call the vendor to complain — or sue?&lt;/p>

&lt;p>Some people might use CVSS to make that kind of decision. It is, after all, a
 score telling you how severe a problem is.&lt;/p>

&lt;p>But there is no single threat model, so there can be no single score that
 suits all audiences. Not everyone who uses the DoS-able database engine makes
 that kind of inefficient query. Not all deployers of vulnerable platforms need
 to worry, even if the bug is present — maybe their servers are overprovisioned
 relative to their load.&lt;/p>

&lt;p>But what about a shopping site? What about a shopping site during the winter
 holiday season? Such a deployer can put a concrete dollar value on the cost of
 downtime, and that cost changes from quarter to quarter. In turn, that will
 change how the deployer prioritizes different vulnerabilities.&lt;/p>

&lt;p>Nor do the scores map to real-world costs and risks — will a vulnerability
 with a CVSS score of 10.0 cost you twice as much as (or, say, 5 orders of
 magnitude more than) one with a score of 5.0? The question is nonsensical
 because nobody has the same cost model, either.&lt;/p>

&lt;p>The CVSS people are aware of these problems, and have tried to address them.
 From &lt;a href="https://www.first.org/cvss/user-guide">the CVSS User
 Guide&lt;/a>:&lt;/p>

&lt;blockquote>
 &lt;p>&lt;b>2.1. CVSS Measures Severity, not Risk&lt;/b>&lt;/p>

 &lt;p>The CVSS Specification Document has been updated to emphasize and clarify the
 fact that CVSS is designed to measure the severity of a vulnerability and should
 not be used alone to assess risk.&lt;/p>

 &lt;p>Concerns have been raised that the CVSS Base Score is being used in situations
 where a comprehensive assessment of risk is more appropriate. The CVSS v3.1
 Specification Document now clearly states that the CVSS Base Score represents
 only the intrinsic characteristics of a vulnerability which are constant over
 time and across user environments. The CVSS Base Score should be supplemented
 with a contextual analysis of the environment, and with attributes that may
 change over time by leveraging CVSS Temporal and Environmental Metrics. More
 appropriately, a comprehensive risk assessment system should be employed that
 considers more factors than simply the CVSS Base Score. Such systems typically
 also consider factors outside the scope of CVSS such as exposure and threat.&lt;/p>
&lt;/blockquote>

&lt;p>CVSS 3.0 and greater were (presumably) devised to address the problem of
 nonsensical scores, such as that &lt;a href="https://heartbleed.com/">Heartbleed&lt;/a> — a bug that lets unauthenticated
 internet attackers read secrets out of a server’s memory — &lt;a
 href="https://nvd.nist.gov/vuln/detail/cve-2014-0160">scored only 5.0 at the
 time&lt;/a>. (Click the &lt;b>CVSS Version 2.0&lt;/b> button to see it.) At least in the
 case of Heartbleed, CVSS 3 results in scores that seem more ‘intuitively
 accurate’ — to those of us assuming a particular class of threat model.&lt;/p>

&lt;p>However, I find that section quoted above to be a bit of a cop-out, given how
 people have reported using CVSS to me. People are using it to make operational
 decisions. It also feels insufficient: it’s not just that risk is different for
 different people at different times, it’s that severity can vary too!&lt;/p>

&lt;p>Imagine that a hypothetical shopping app deployer has deployed the DoS-able
 database such that each query runs in a sandboxed and resource-limited process.
 The deployers have tested their sandbox resource limits such that 99.99% of true
 shopping queries succeed, while queries that exceed the memory limit or use more
 than some number of milliseconds of compute time are killed. For this deployer,
 the severity of the bug goes way down, nearly to zero, even though the cost of
 successful attack has stayed the same. This deployer has effectively mitigated
 the bug. (This deployment strategy can mitigate many potential bugs, and can
 change how the deployer prioritizes a wide variety of vulnerabilities.)&lt;/p>

&lt;p>Another problem with CVSS is its &lt;a href="https://en.wikipedia.org/wiki/False_precision">false precision&lt;/a>. If you
 look at the calculator, you’ll see that the ‘measurements’ you can make about a
 vulnerability are of very coarse ‘precision’, e.g. None – Low – High, or (for
 Exploit Code Maturity) Not Defined – Unproven – PoC – Functional – High. The
 measurements are in tertiles, quartiles, and quintiles, yet the calculator
 produces results purporting 2 significant figures (e.g. 6.2). This is an
 illusion produced by the arithmetic of the CVSS scoring procedure, not actual
 measurements of real bug severity.&lt;/p>

&lt;p>I have my doubts about whether the severity of vulnerabilities can be scored
 at all, especially without lots and lots of deployer-specific context. Even with
 that context, you still also need a well-grounded cost model — but it is very
 difficult to get one. Not all users that a given deployer is serving will share
 a given model, so you may need many cost models. And then you need a way to
 balance the concerns of all your constituents — another complex and
 hard-to-ground model. In real life, people make risk decisions much more
 qualitatively than we or they would like to believe.&lt;/p>

&lt;p>That doesn’t mean we shouldn’t strive for well-grounded quantitative models!
 Just that we need to be prepared to act without them, and that CVSS is not
 one.&lt;/p>

&lt;p>If we do away with the spurious numbers and just treat CVSS as purely
 qualitative — which it is, &lt;b>and which is fine!&lt;/b> — we’d have a more honest
 and safer-to-use system. (Nobody is really worrying about the difference between
 7.6 and 7.4 anyway. At least I hope not.) The basic qualities that CVSS
 encompasses are all important and useful, and account for many of the desiderata
 at the top of this post.&lt;/p>

&lt;h2>Conclusion&lt;/h2>

&lt;p>The combination of CVE + CVSS gives us some of what we want, and we could
 have more of it at lower cost if any of a few magical things happened:&lt;/p>

&lt;ul>

 &lt;li>Developers provided meaningful information in their own vulnerability
 databases&lt;/li>

 &lt;li>Developers provided meaningful information to VDBs&lt;/li>

 &lt;li>VDBs made it easier for developers to keep entries current and accurate&lt;/li>

 &lt;li>VDBs rejected information-free entries or called them out as such&lt;/li>

 &lt;li>Coordination costs were lowered, such as by removing the ‘global lock’ in
 the CVE database (as OVE proposes to do, and which could be done by giving each
 &lt;a href="https://www.cve.org/ProgramOrganization/CNAs">CNA&lt;/a> its own
 ‘namespace’ to issue numbers in)
 &lt;/li>

 &lt;li>The CVSS program embraced its inherent qualitativeness, and shed the
 pseudo-quantities.&lt;/li>

&lt;/ul>

&lt;p>However, it will never be possible to beat the information richness,
 searchability, or authoritativeness of a well-run developer communications
 program. (This is especially true for projects that are open source as well as
 being well-run.) Also great are well-run researcher communications programs — &lt;a
 href="/2022/04/22/itw-taxonomy/">Taxonomy Of In-The-Wild Exploitation&lt;/a> was
 only possible because so many researchers wrote so many great blog posts and
 PoCs. (Thank you!)&lt;/p>

&lt;p>Additionally, there will always be vulnerabilities that are known and fixed
 but which don’t get VDB entries. &lt;b>In my experience, the majority of
 vulnerabilities go un-numbered&lt;/b>, and for those vulnerabilities, this whole
 discussion is moot. This is not a fault of any VDB program: although reducing
 the friction of working with the program would help, we will always need to
 prepare for vulnerabilities that aren’t announced or tracked. You never get
 perfect global coordination, no matter how low the friction. And sometimes
 developers don’t even realize (or want to admit) that they are fixing a
 vulnerability (as opposed to just a regular bug). And sometimes their own bug
 trackers are already easier to use and more useful than a global database.&lt;/p>

&lt;p>Therefore no VDB can ever be the sole trigger for action on the part of
 deployers. The only reliable way to get all the available fixes is to track the
 latest stable version. No matter how good any VDB gets, that will always be true
 — and deployers who do so will be insulated from gaps and mistakes on the part
 of developers and of VDB programs.&lt;/p>

&lt;p>For the sake of public safety — and, honestly, just for the pride of
 engineering excellence — we must improve the quality and discoverability of
 vulnerability information, and reduce the cost of providing and getting it.
 There’s a lot of room for us to do a lot better as a community. The status quo
 is not working.&lt;/p>

&lt;hr />

&lt;p>&lt;a id="fn1">&lt;/a>&lt;a href="#fn1_back">&lt;b>1.&lt;/b>&lt;/a> When CVE alerts are of
 low quality, it is not typically the ‘fault’ of the CVE program itself. Software
 development organizations must provide timely, relevant, and actionable
 information; if they don’t, there’s not much the CVE program can do.&lt;/p>

&lt;p>&lt;a id="fn2">&lt;/a>&lt;a href="#fn2_back">&lt;b>2.&lt;/b>&lt;/a> Some developer bug
 trackers are great and have most or all of the properties we want. This is
 typically, but neither inherently nor historically only, seen in the trackers
 for open source projects. But other developers provide very little information,
 intentionally hide information, or don’t even have bug trackers at all.&lt;/p>

&lt;p>&lt;a id="fn3">&lt;/a>&lt;a href="#fn3_back">&lt;b>3.&lt;/b>&lt;/a> When the developer’s bug
 tracker is information-poor, then researchers’ bug trackers, advisories, and
 blogs become more authoritative.&lt;/p>

&lt;p>&lt;a id="fn4">&lt;/a>&lt;a href="#fn4_back">&lt;b>4.&lt;/b>&lt;/a> I once really had a bug
 like this, on a security review engagement years ago. The client told me that
 their biggest fear was that 1 tenant in their multi-tenant platform would starve
 other tenants of resources, so they had strict quotas around CPU time and memory
 allocation. I was able to make &lt;a
 href="https://stackoverflow.com/questions/44487537/why-does-naive-string-concatenation-become-quadratic-above-a-certain-length">the
 string allocation routine in their language runtime go quadratic&lt;/a> in a way
 that their quota system couldn’t see, but which I could and did time remotely. I
 fired off a few pathological requests, and the development server became
 unresponsive. So I wrote it up and went to lunch, since I couldn’t test any
 more. For this client, it was the most high-priority bug to fix; but for others,
 it might not matter as much or at all.&lt;/p></description><author>Chris Palmer</author><guid>2022/07/10/fraught-vdbs/index.html</guid><pubDate>Sun, 10 Jul 2022 00:00:00 +0000</pubDate></item><item><title>Still Waiting For A Defense Of Cryptoassets</title><link>https://noncombatant.org/2022/06/11/still-waiting-for-defense-cryptoassets/index.content</link><description>&lt;h1>Still Waiting For A Defense Of Cryptoassets&lt;/h1>

&lt;p>&lt;time>11 June 2022&lt;/time>&lt;/p>

&lt;p>In response to &lt;a href="https://concerned.tech/">the Letter in Support of
 Responsible Fintech Policy&lt;/a>, a factual and reasonable call for Congress to
 resist intense lobbying from crypto-speculators and venture capitalists&lt;a href="#fn1" id="fn1_back">①&lt;/a>,
 cryptographer Matthew Green has responded
 with a blog post &lt;a href="https://blog.cryptographyengineering.com/2022/06/09/in-defense-of-cryptocurrency/">In
 defense of crypto(currency)&lt;/a> that doesn’t effectively rebut the letter to
 Congress. Instead, he confirms most of their points.&lt;/p>

&lt;p>(I say &lt;i>cryptoassets&lt;/i>, not &lt;i>cryptocurrencies&lt;/i>, because they’re not
 viable as currencies: they’re designed to be &lt;a href="https://en.wikipedia.org/wiki/Deflation">deflationary&lt;/a> and
 have proven
 &lt;a href="https://www.coindesk.com/price/bitcoin/">absurdly volatile&lt;/a>. Of
 course, &lt;a href="https://en.wikipedia.org/wiki/Greater_fool_theory">the greater
 fool&lt;/a> left holding the bag will find they’re not assets in the colloquial
 sense, either.)
&lt;/p>

&lt;p>I wouldn’t normally bother writing about cryptoassets, because they’re absurd
 and &lt;a href="https://web3isgoinggreat.com/">immediately discredit themselves&lt;/a>
 better than I could. However, Green’s defense is interesting because he has
 significant credentials and experience in cryptography. He is also a
 co-developer of a leading privacy-protective (&lt;a href="https://www.coindesk.com/price/zcash/">and deflationary&lt;/a>)
 cryptoasset,
 &lt;a href="https://z.cash/">Zcash&lt;/a>. So we can reasonably hope for
 better-informed and coherent arguments than we normally see from
 crypto-boosters.
&lt;/p>

&lt;p>But the fact that a uniquely-qualified expert in the field is not able to
 rebut legitimate concerns, including the ones he raises, is interesting enough
 to comment on. Like Green, I’m sure I’ll regret this.&lt;/p>

&lt;blockquote>
 &lt;h2>Objection: “Cryptocurrency is terrible for the
 environment”&lt;/h2>
&lt;/blockquote>

&lt;p>Green cedes this point. His rebuttal is that we can fix that with
 what he agrees is oligarchy:&lt;/p>

&lt;blockquote>Proof-of-stake systems are not perfect: they still lead to some
 centralization of power, since in this paradigm the rich tend to get richer.
 However it’s hard to claim that the result will be worse than the
 semi-centralized mess that proof-of-work mining has turned into.&lt;/blockquote>

&lt;p>While &lt;a href="https://ethereum.org/en/energy-consumption/">boosters estimate
 that proof-of-stake will reduce energy consumption by 3 orders of magnitude&lt;/a>,
 it’s worth noting that oligarchy is very bad, actually&lt;a href="#fn2" id="fn2_back">②&lt;/a>. It’s something we should
 be looking to solve, not
 exacerbate. People who don’t like centralization should, in theory, agree; but,
 of course, most anarcho-capitalists believe that &lt;b>they&lt;/b> will get to be &lt;a
 href="https://madmax.fandom.com/wiki/Immortan_Joe">Immortan Joe&lt;/a>. When you
 scratch the surface of anarcho-capitalism you typically find feudalism, as we do
 here.&lt;/p>

&lt;p>So we don’t seem to have any solution to the theoretical&lt;a href="#fn3" id="fn3_back">③&lt;/a> computing science
 problem of distributed consensus that
 isn’t also hugely destructive to the world in some way. Green presents no
 argument that the best way to solve “the semi-centralized mess that
 proof-of-work mining has turned into” is anything other than simply not doing
 PoW or PoS.&lt;/p>

&lt;p>To round this section out, Green repeats the punchline that Ethereum 2 is
 coming &lt;a href="https://www.coindesk.com/business/2022/04/13/ethereum-merge-no-longer-expected-in-june/">Real
 Soon Now&lt;/a>, and mentions in passing that &lt;a
 href="https://foreignpolicy.com/2021/05/23/cryptocurrency-chia-waste-resources-bitcoin/">wasting
 hard drives&lt;/a> is also an option.&lt;/p>

&lt;blockquote>
 &lt;h2>Objection: “Public blockchains can never support banking
 features like transaction reversal.”&lt;/h2>
&lt;/blockquote>

&lt;p>Green’s rebuttal seems to be twofold: (1) stablecoins are centralized and
 hence can freeze or burn money; and (2) smart contracts could say anything,
 including provisions for reversal.&lt;/p>

&lt;p>In the cryptoasset ideology, centralization is The Big Problem That Must Be
 Solved (Unless We Get To Be The Feudal Lords, In Which Case Centralization Is
 Awesome). So presenting centralization as a solution is not functional as a
 rebuttal.&lt;/p>

&lt;p>There’s also the small matter that &lt;a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3888752">stablecoins
 are basically a rebirth of the ‘wildcat’ banks of the 19th century&lt;/a> — hardly
 a compelling vision for the future.&lt;/p>

&lt;p>It might be true that smart contracts could have provisions for reversal, but
 the reality on the ground today is that ‘code is law’, those ‘laws’ don’t
 typically have reversal provisions, and they end up being &lt;a
 href="https://news.ycombinator.com/item?id=27665297">“self-funding bug
 bounties”&lt;/a> that just destroy people’s ‘assets’ in an automated way.&lt;/p>

&lt;p>Green does not mention that stablecoins have a history of being &lt;a
 href="https://crypto-anonymous-2021.medium.com/the-bit-short-inside-cryptos-doomsday-machine-f8dcf78a64d3">fantastically
 crimey&lt;/a> and/or &lt;a
 href="https://www.cnet.com/personal-finance/crypto/luna-crypto-crash-how-ust-broke-and-whats-next-for-terra/">not
 even a little bit stable&lt;/a>.&lt;/p>

&lt;p>So perhaps the letter authors are wrong that public blockchains can “never”
 support transaction reversal. Anyway, the combination of reversible +
 decentralized doesn’t exist now. Perhaps there will be a flurry of innovation in
 the area of smart contracts that enable refunds, but we’d still face the
 question of why that’s better than regular bank databases.&lt;/p>

&lt;blockquote>
 &lt;h2>Objection: “Cryptocurrency doesn’t scale [or the fees are too
 damned high]”&lt;/h2>
&lt;/blockquote>

&lt;p>Again, Green starts out by confirming the critics’ point. He reassures us
 that the problem is &lt;a href="https://wiki.c2.com/?SimpleMatterOfProgramming">A
 Simple Matter Of Programming&lt;/a>, but cautions us that while the ideal speed-up
 would be 100x — within an order of magnitude of what Visa can handle on a
 non-holiday now with 1970s technology, so maybe borderline feasible — the
 reality won’t be that big.&lt;/p>

&lt;p>Nicholas Weaver, one of the lead signers of the letter, has &lt;a
 href="https://www.usenix.org/publications/loginonline/web3-fraud">a different
 back-of-the-envelope calculation&lt;/a>:&lt;/p>

&lt;blockquote>

 &lt;p>Estimating the cost (measured in ‘gas’) of an arbitrary computation is
 complex but let’s assume that we are only interested in the most simple
 operation: 256 bit integer addition. Each addition costs 3 gas each. So on a
 worldwide basis this system rates at 600,000 adds per second.&lt;/p>

 &lt;p>Compare this amount of compute to a Raspberry Pi 4, a $45 single-board
 computer which has four processors running at 1.5 GHz. Each core has 2 ALUs and
 it will take 4 instructions to perform a 256 bit addition, as the basic unit for
 the Raspberry Pi (and most other modern computers) is 64 bits. So each core has
 a peak performance of 750,000,000 adds per second for a total peak of
 3,000,000,000 adds per second. Put bluntly, the Ethereum “world computer” has
 roughly 1/5,000 of the compute power of a Raspberry Pi 4!&lt;/p>

&lt;/blockquote>

&lt;p>By Weaver’s critical estimate, even the big dream of a 100x speed-up is not
 enough to make the Ethereum network a good use of the planet’s computational
 resources. Nor would the Ethereum Foundation’s claim of a 2000x speed-up enable
 the Ethereum network to outpace a Raspberry Pi.&lt;/p>

&lt;p>Green also confirms that&lt;/p>

&lt;blockquote>Many defenders have tried to paint the electricity consumption of
 Bitcoin and other PoW currencies as “green” or define it as a form of energy
 storage. This is dishonest nonsense: estimates hold that at east 60% of mining
 energy consumption still comes from fossil sources.&lt;/blockquote>

&lt;p>Perhaps some other defense of cryptocurrencies will hold. Let’s see:&lt;/p>

&lt;blockquote>
 &lt;h2>Objection: “There is no privacy on blockchains (or there is too
 much privacy)”&lt;/h2>
&lt;/blockquote>

&lt;p>There has, in fact, been innovation in cryptoasset privacy, and Green’s own
 work demonstrates that.&lt;/p>

&lt;p>Unfortunately, that’s very bad, even if also potentially good in some way. &lt;a
 href="https://cryptonews.com/exclusives/blockchain-and-the-utopia-of-a-anarcho-capitalist-society-2763.htm">The
 anarcho-capitalist dream of cryptoassets&lt;/a> — i.e. &lt;a
 href="https://www.antipope.org/charlie/blog-static/2013/12/why-i-want-bitcoin-to-die-in-a.html">tax
 evasion and money-laundering&lt;/a> — is one of the only parts of the cryptoasset
 dream that reliably comes true in practice. The cryptoasset economy has been a
 huge ‘success’ in enabling &lt;a
 href="https://blog.chainalysis.com/reports/2022-crypto-crime-report-preview-ransomware/">ransomware&lt;/a>,
 &lt;a href="https://blog.chainalysis.com/reports/law-enforcement-agencies-cryptocurrency/">CSAM&lt;/a>,
 and &lt;a
 href="https://www.reuters.com/technology/us-ties-north-korean-hacker-group-lazarus-huge-cryptocurrency-theft-2022-04-14/">Kim
 Jong Un’s nuclear program&lt;/a> (on top of the more mundane phenomenon of regular
 people losing their money).
&lt;/p>

&lt;p>It’s not clear why people who want functioning government, un-abused
 children, and fewer nuclear weapons would welcome a more-private cryptoasset.
 Perhaps there is an argument that the potential benefits would outweigh the
 actual harms we endure right now, but Green doesn’t make it in this article, and
 doesn’t contend with the harms.&lt;/p>

&lt;p>Green attempts to paint the status quo as equivalently risky as the current
 systems of exchange:&lt;/p>

&lt;blockquote>But at very least they’ll be better than our current
 collect-it-all-and-then-hand-it-to-hackers approach, which certainly has not
 done us very many favors.&lt;/blockquote>

&lt;p>but it’s hard not to see cryptoassets as even more accurately described as
 “handing it to hackers”.&lt;/p>

&lt;blockquote>
 &lt;h2>So why do I care about any of this?&lt;/h2>
&lt;/blockquote>

&lt;p>In this section, Green presents the problems that cryptoassets should
 supposedly solve, and which should motivate a long blog post to defend
 cryptoassets. Buried the lede, tbh, but:&lt;/p>

&lt;ul>

 &lt;li>Credit card fees are too high&lt;/li>
 &lt;li>Credit cards are still prone to the same kinds of fraud as in 1995&lt;/li>
 &lt;li>We don’t have privacy in our payments&lt;/li>
 &lt;li>You can’t pay with your phone unless you want to give control to
 corporations&lt;/li>
 &lt;li>Regulatory capture&lt;/li>

&lt;/ul>

&lt;p>After 4,000 words in defense of cryptoassets, this is the
 &lt;s>lede&lt;/s>conclusion:
&lt;/p>

&lt;blockquote>

 &lt;p>I don’t know if blockchains are the solution to this problem. [...]&lt;/p>

 &lt;p>So while I don’t know if cryptocurrency will be the answer, I’m just hopeful
 that something will be.&lt;/p>

&lt;/blockquote>

&lt;p>So at the end of what could be a strong defense of cryptoassets, we find that
 they are not in fact defensible, and that the letter to Congress is basically
 right on every point.&lt;/p>

&lt;p>But, the problems Green identifies are real, and it would be good to solve
 them. So let’s consider how cryptoassets deal with these problems.&lt;/p>

&lt;p>Credit card fees are too high: As Green notes, cryptoasset fees are not
 exactly low. &lt;a
 href="https://www.theverge.com/2021/11/24/22800995/constitutiondao-refund-progress-steep-gas-fees-cryptocurrency">In
 some cases, they’re a deal-breaker&lt;/a>. They are also far more volatile. And
 there is no viable solution at hand, in Green’s post or elsewhere.&lt;/p>

&lt;p>Credit cards are still prone to fraud: Clearly, this is as true today as it
 was in 1995. Unfortunately, cryptoassets have not only not reduced fraud but
 have brought us new and exciting additional forms of fraud. “Back in my day,”
 I’ll say, “we had fewer forms of financial fraud!” The grandkids roll their eyes
 in disbelief.&lt;/p>

&lt;p>We don’t have privacy in our payments: As above, this is a policy debate that
 we can and should have. Whatever approach to payment privacy we take, it will
 have to do something to mitigate the severe harms that sort-of-private and
 pseudonymous cryptocurrencies have enabled and exacerbated.&lt;/p>

&lt;p>And it will require a nuanced construction of privacy, which is often
 presented as — but which is not — a simple binary condition. (It’s not even as
 simple as a spectrum along a single axis.) There does not yet appear to be a
 plausible approach on the table that provides people privacy (however defined)
 and yet stops at least some large-scale, society-damaging crime. Maybe
 someday.&lt;/p>

&lt;p>You can’t pay with your phone without giving control to corporations: That
 does seem to be true, whether it’s to Apple, Google, Safaricom (which operates
 M-Pesa in Kenya), PayPal, Zelle, or various state-capital corporations in China.
 Since Green dismisses existing state and government solutions, I take it he
 would only be satisfied by currency purely run on distributed consensus. Thus he
 appears to embrace the anarcho-capitalist dream, but doesn’t have anything to
 say (in this article) about what would check and balance capital power &lt;a
 href="https://www.washingtonpost.com/opinions/2020/04/10/when-you-drown-government-bathtub-people-die/">once
 government is “drowned in the bathtub”&lt;/a>.&lt;/p>

&lt;p>Regulatory capture: Recall that the letter to Congress was from concerned
 experts &lt;b>warning legislators to be wary of regulatory capture by speculators
 and VCs&lt;/b> — and, again, Green says he broadly agrees with the lead signers’
 spirit — so it’s hard to see how cryptoassets are a solution to regulatory
 capture. In fact that’s the problem at hand!&lt;/p>

&lt;h2>Conclusion&lt;/h2>

&lt;p>Green’s defense of cryptoassets is no more coherent than what we’ve seen
 before. But it does have the virtue of honesty, which inevitably makes it a very
 weak defense of cryptoassets.&lt;/p>

&lt;p>The Letter in Support of Responsible Fintech Policy stands as reasonable
 advice to legislators, and cryptoassets still look like &lt;a href="https://webcomicname.com/post/152958755984">a
 change for the
 worse&lt;/a>.&lt;/p>

&lt;hr />

&lt;p>&lt;a id="fn1">&lt;/a>
 &lt;a href="#fn1_back">&lt;b>1.&lt;/b>&lt;/a> I also signed it, but
 was not a lead signer nor an author of it. I was not involved in any way; I just
 think the authors are right.
&lt;/p>

&lt;p>&lt;a id="fn2">&lt;/a>
 &lt;a href="#fn2_back">&lt;b>2.&lt;/b>&lt;/a> If I could just
 interject for a moment, what people typically refer to as PoS is, in fact,
 proof-of-oligarchy, or as I’ve recently taken to calling it, PoO.
&lt;/p>

&lt;p>&lt;a id="fn3">&lt;/a>
 &lt;a href="#fn3_back">&lt;b>3.&lt;/b>&lt;/a> I mean
 &lt;i>theoretical&lt;/i> in the technical sense, not in a colloquial sense of
 “unimportant”. It would be useful to have a solution to the distributed
 consensus problem. But we don’t need a solution so badly that burning the Earth
 is a good idea, and we don’t need one that furthers anarcho-capitalism.
&lt;/p></description><author>Chris Palmer</author><guid>2022/06/11/still-waiting-for-defense-cryptoassets/index.html</guid><pubDate>Sat, 11 Jun 2022 00:00:00 +0000</pubDate></item><item><title>Getting A Bit More From The Minor Pentatonic</title><link>https://noncombatant.org/2022/06/01/a-bit-more-from-the-minor-pentatonic/index.content</link><description>&lt;h1>Getting A Bit More From The Minor Pentatonic&lt;/h1>

&lt;p>&lt;time>1 June 2022&lt;/time>&lt;/p>

&lt;p>Guitar players are always bangin’ on the familiar “blues box”: the standard
pentatonic scale shape. (Example 🄰, below, shows it in E minor.)&lt;/p>

&lt;p>But, there are 4 other modes of a 5-note scale. &lt;a
href="https://en.wikipedia.org/wiki/Pentatonic_scale#Pentatonic_scales_found_by_running_up_the_keys_C,_D,_E,_G_and_A">Wikipedia
shows them in A Minor/C Major&lt;/a>, but we’ll continue to start from E, since
we’re guitar players. Examples 🄱, 🄲, 🄳, and 🄴 show new box shapes for those 4
modes, going down from E Minor (the viii/i scale degree), to D Blues Major (the
VII scale degree), to B Blues Minor (the v scale degree), to A Suspended (the iv
scale degree), to G Major (the III scale degree).&lt;/p>

&lt;p>In these examples, take a look at the fretting-hand fingerings I suggest. In
most cases, you can stick to a friendly “1 finger per fret” pattern. But there
is 1 stretch: In A Suspended, I mostly stay in the 5th position except that I
stretch back with my ① to get the B note on the G string (4th fret). And there
are some places where I use ② and ④ instead of the more comfortable ① and ③ and
① and ④ grips. I find this to be good exercise.&lt;/p>

&lt;p>Wikipedia gives many names for the modes, based on their usage in several
cultures. Note that they use “blues” not in what I consider the usual way — i.e.
a pentatonic scale with an additional ‘blue’ note, the ♭5 in Minor and the ♭3 in
Major scales — but to refer to modes that resemble, but are not quite the same
as, Pentatonic Minor and Pentatonic Major.&lt;/p>

&lt;p>Note that we use upper-case Roman numerals for major scales and chords, like
G = III, and lower-case numerals for minor scales and chords, like E = i and B =
v.&lt;/p>

&lt;p>You might wonder why, for example, we call the VII scale, D Blues Major, a
&lt;i>major&lt;/i> scale — it has no 3rd (no F), so it can’t really be major or minor,
right? Well, (a) we have to call it something; and (b) in the key of E minor,
D’s major 3rd (F♯) is present. So if you were playing in the modes of E
Pentatonic Minor, but you absolutely had to play an F of some kind, it’d most
likely be an F♯. So in a pinch the mode based on D is notionally ‘major’.&lt;/p>

&lt;p>Similarly, the mode based on A would be ‘minor’ if we absolutely had to pick.
(E Minor has C natural, A’s minor 3rd.)&lt;/p>

&lt;p>In example 🄵, I show some open-position chords. These are 4-note chords that
this scale generates. In a normal 7-note diatonic scale, the notes of a 4-note
chord are usually the 1st, 3rd, 5th, and 7th degrees: the 7th chords. But in a
pentatonic scale, we aren’t necessarily going to get those specific scale
degrees for a given chord — they might not be present. In such cases, I chose
the note 1 scale degree down from the expected note. For example, where there is
no 3rd, I use the 2nd (see the chords based on D and A). Where there is no 7th,
I use the 6th (see the chords based on D and G). For the chord starting from B,
there is no 5th (would be F♯), so I went down and selected the 4th (E).&lt;/p>

&lt;p>But you could make other choices!&lt;/p>

&lt;p>Normally, when you’re playing your 12-bar blues and jamming in your
pentatonic box, you play the i, iv, and v chords (in E: Em(7), Am(7), and
Bm(7)). But those chords use some notes that don’t strictly exist in this
pentatonic scale. By sticking strictly to the notes of this scale, we get what I
think are more interesting chords.&lt;/p>

&lt;iframe src="more-from-pentatonic.pdf" width="100%" height="500"
loading="lazy">&lt;/iframe></description><author>Chris Palmer</author><guid>2022/06/01/a-bit-more-from-the-minor-pentatonic/index.html</guid><pubDate>Wed, 01 Jun 2022 00:00:00 +0000</pubDate></item><item><title>Simple And Terrible Machines</title><link>https://noncombatant.org/2022/05/22/simple-terrible-machines/index.content</link><description>&lt;h1>Simple And Terrible Machines&lt;/h1>

&lt;p>&lt;time>22 May 2022&lt;/time>&lt;/p>

&lt;p>As an artifact of industrial engineering, it is very hard to beat the &lt;a
 href="https://en.wikipedia.org/wiki/Fender_Telecaster">Fender Telecaster&lt;/a>:
 durability, repairability, usability, fitness for purpose (sound), and low cost
 are all hallmarks of its design. Take a moment to admire &lt;a
 href="https://twitter.com/colbertlateshow/status/1452799769286483980">a
 particularly fine specimen&lt;/a>.&lt;/p>

&lt;p>In a sure sign of quality, the Tele patinates well. &lt;a href="https://www.chicagofretworks.com/relic-service/">People
 try to fake
 patination&lt;/a>, which is the nadir of cringe yet the expression of a yearning to
 replicate the outward signs of timeless quality.&lt;/p>

&lt;p>The Tele is at the top of an uncanny peak: like a Dutch bicycle, it is
 possible to improve on the design, but only by incurring severe trade-offs.&lt;/p>

&lt;ul>

 &lt;li>You could use &lt;a href="https://en.wikipedia.org/wiki/Humbucker">humbucking
 pickups&lt;/a>, but you’d lose the characteristic bright sound of the bridge
 pickup.&lt;/li>

 &lt;li>You could put a humbucker in the neck pickup position only, but might have
 have an output balance problem relative to the bridge position. Compensating
 with a high-output single-coil pickup in the bridge position would also
 compromise the signature treble clarity.&lt;/li>

 &lt;li>You could add more frets — traditional Teles have 21 or 22 — but the closer
 you move the neck pickup backward toward the bridge, the more you lose its
 distinctive sound.&lt;/li>

 &lt;li>You could ease playability by shortening &lt;a
 href="https://en.wikipedia.org/wiki/Scale_length_(string_instruments)">the scale
 length&lt;/a>, but that would also reduce the overall snappy, ‘tight’ sound of the
 instrument.&lt;/li>

&lt;/ul>

&lt;p>The key, and perhaps sole, trade-off-free improvement available in the design
 is in the usability of the controls. The traditional Tele has a 3-way pickup
 selector switch, with the volume knob behind it, and the tone (treble
 attenuator) behind that. The pickup selector switch is a bit too close to the
 volume knob when it’s set all the way ‘back’ (toward the bridge). And it’s nice
 to be able to &lt;a href="https://www.youtube.com/watch?v=LCiSOEHdkFQ">adjust the
 volume with your pinkie while picking&lt;/a> — but the Tele’s volume knob is too
 far away to make that easy.&lt;/p>

&lt;p>It is easy to &lt;a href="https://www.premierguitar.com/gear/tele-control-plate-mods">improve the
 usability of the controls&lt;/a> by reversing the control plate, and many players
 do this.&lt;/p>

&lt;p>Fender resolved the switch and knob issues entirely with &lt;a
 href="https://en.wikipedia.org/wiki/Fender_Stratocaster">the Stratocaster&lt;/a>,
 and made &lt;a
 href="https://www.premierguitar.com/gear/reviews/esoterica-electrica-the-incredibly-smart-and-simple-strat">further
 reductions in the cost of manufacture and repair&lt;/a> as well. &lt;a
 href="https://www.ibanez.com/usa/products/detail/yy20_1P_01.html">The Ibanez
 Talman&lt;/a> is a Telecaster with the Stratocaster controls solution.&lt;/p>

&lt;p>The Tele is also very efficient in its use of materials (which are plentiful,
 non-endangered, and cheap: maple for the neck, and ash or alder for the body).
 Little of the wood is thrown away when sculpting the neck and the body, relative
 to the manufacturing techniques used in other instrument designs. For example,
 in &lt;a href="https://www.maegenwellsguitars.com/mwg">hand-carved archtop
 guitars&lt;/a>, the top begins life as a 1”-thick chunk of wood. By the end, no
 part of it is more than 0.15” thick. As beautiful works of art as they
 undeniably are, they are not parsimonious. Another popular guitar design calls
 for a CNC machine to sculpt a neck that is at most 1” thick, out of a 3”-thick
 block.&lt;/p>

&lt;p>Unlike almost all other musical instrument designs, the Telecaster is
 incredibly hardy. It is 0% fragile — and yet also readily repairable and
 modifiable.&lt;/p>

&lt;p>There are &lt;i>implementation&lt;/i> (not design) improvements possible in the
 Telecaster. Noiseless single-coil pickups, a tapered neck joint, chambered body,
 and locking tuners are standard for most manufacturers now (except Fender). The
 changes increase the cost a little, but increase usability a lot.&lt;/p>

&lt;p>The Tele, like Lisp and Algol, represents the very best that could have been
 done with the technology of the (roughly same) time, and remains very hard to
 improve on. For example, modern languages like Python and JavaScript are
 basically Lisp, but without the macro/DSL wonderland that Lisp’s trivial syntax
 affords. You get better everyday UX, but at a significant cost in
 functionality.&lt;/p>

&lt;p>I’m fascinated by this uncanny quality peak, in whatever type of engineering
 object, in which further improvements are few and far between. I wonder what
 peaks we could be climbing now but aren’t. Is there a better systems language
 than Rust, which we should be running on... what? RISC-V? Could we get the
 benefits of Rust, but with a more gradual learning curve? Could we get the
 performance of x64 without the cruft?&lt;/p>

&lt;p>It might be easier to get to the uncanny peak with simple machines like
 musical instruments and bicycles — there are perhaps fewer decision points and
 trade-offs and things that can break. But I’m reminded of this Twitter
 exchange:&lt;/p>

&lt;blockquote>

 &lt;p>@taber@woof.group @cakesandcourage &lt;a href="https://twitter.com/cakesandcourage/status/1461481653059129345">Nov
 18,
 2021&lt;/a>&lt;br />

 a popular myth is that people who are Very Computer have computers that work.
 nothing could be further from the truth. the Very Computer are capable of
 generating much more novel and fascinating ways to make computers not fucking
 work and exercise this capability wantonly&lt;/p>

 &lt;p>celphase @celphase &lt;a href="https://twitter.com/celphase/status/1461505813852434433">Nov 18,
 2021&lt;/a>&lt;/p>

 &lt;figure>&lt;img src="mild-proficiency.png" width="496" height="287" alt="A graph of
y = “amount of tech issues” and x = “technical proficiency” that shows “no
computer” at the origin; “poweruser” at y = 50%, x = 25%; “blessed valley of
mild proficiency” at y = 25%, x = 50%; and then a steep upward slope with
varying levels of self-inflicted Linux: “Maybe I should try Arch”, “Maybe I
should try Gentoo”, “I recompiled the Linux kernel on my smart-fridge and now my
printer no longer works on any of my devices." loading="lazy" />
 &lt;figcaption>The
 Blessed Valley Of Mild Proficiency, by @celphase.&lt;/figcaption>
 &lt;/figure>

&lt;/blockquote>

&lt;p>Maybe, for Terrible Machines like computers and programming languages, the
 Blessed Valley Of Mild Proficiency &lt;b>is&lt;/b> the uncanny peak.&lt;/p></description><author>Chris Palmer</author><guid>2022/05/22/simple-terrible-machines/index.html</guid><pubDate>Sun, 22 May 2022 00:00:00 +0000</pubDate></item><item><title>Taxonomy Of In-The-Wild Exploitation</title><link>https://noncombatant.org/2022/04/22/itw-taxonomy/index.content</link><description>&lt;h1>Taxonomy Of In-The-Wild Exploitation&lt;/h1>

&lt;p>&lt;time>16 April 2022&lt;/time>&lt;/p>

&lt;p>As too few software engineers know, &lt;a
 href="https://alexgaynor.net/2020/may/27/science-on-memory-unsafety-and-security/">about
 65% of known vulnerabilities in C/C++ codebases are due to memory unsafety&lt;/a>.
 The “65% finding”, as I’ll call it, is consistent across vendors and across
 decades. Obviously, that conclusion comes from data biased in a certain way:
 these are the vulnerabilities that attackers and defenders have been
 consistently able to find; these are the vulnerabilities that vendors are
 willing to disclose at all; these are the vulnerabilities that we choose to talk
 about.&lt;/p>

&lt;p>We know there’s more going on out there. Even so, the finding is useful and
 actionable.&lt;/p>

&lt;p>There are also several efforts to track known vulnerabilities that we know
 have actually been exploited in the wild (ITW):&lt;/p>

&lt;ul>

 &lt;li>&lt;a href="https://www.cisa.gov/known-exploited-vulnerabilities-catalog">CISA’s
 Known Exploited Vulnerabilities Catalog&lt;/a>&lt;/li>

 &lt;li>&lt;a
 href="https://docs.google.com/spreadsheets/d/1lkNJ0uQwbeC1ZTRrxdtuPLCIl7mlUreoKfSIgajnSyY/view#gid=2129022708">Project
 Zero’s 0day In The Wild spreadsheet&lt;/a>&lt;/li>

 &lt;li>&lt;a href="https://docs.google.com/spreadsheets/d/1FslzTx4b7sKZK4BR-DpO45JZNB1QZF9wuijK3OxBwr0/edit#gid=0">Tom
 Ritter’s Browser Exploit History&lt;/a>&lt;/li>

&lt;/ul>

&lt;p>(See also &lt;a href="https://github.com/divergentdave/icscert-advisories-scraper">David Cook’s
 ICS-CERT Advisories Scraper&lt;/a>, which is specific to ICS and covers more than
 just ITW bugs.)&lt;/p>

&lt;p>These datasets are also necessarily biased: these are (some of) the
 vulnerabilities attackers can find, and (some of) what they can actually field.
 But we also know that phishing and other social-engineering techniques account
 for a huge portion of real-world attacks.&lt;/p>

&lt;p>These different biases are useful: the more information we have about what’s
 possible and what attackers are really doing, the better we can respond — as
 long as we seek out a variety of datasets and remain aware of their biases. I’d
 love to see additional datasets with entirely different foci, e.g. credential
 and permission phishing, fake invoice fraud, USB drives with malware left
 sitting around... We might not be able to get data about side-channel attacks
 fielded ITW, but I can dream.&lt;/p>

&lt;p>I was curious to see if the 65% finding aligned with what we see in CISA’s
 data. &lt;a href="https://docs.google.com/spreadsheets/d/1JeN3F8EG6A_ckb7PDCHIuAocR8W-6UEu9kKoctJaF08/edit#gid=0">I
 imported their CSV into a Google sheet, and started categorizing the CVEs&lt;/a>
 according to a sketch of a taxonomy I came up with for this purpose, and by the
 implementation language of the target. (See the &lt;b>type&lt;/b> and &lt;b>language&lt;/b>
 columns.) To substantiate the classifications where the description was not
 obvious, I also added a column with details on the bug and/or its exploitation.
 This column usually contains a link to a proof of concept (PoC), an analysis, or
 other details.&lt;/p>

&lt;p>Additionally, Jack Cable mapped the CVEs to their CWEs (see new columns
 &lt;b>cwe&lt;/b> and &lt;b>cwe2&lt;/b>), and mapped those to the taxonomy described here.
 That analysis shows substantially different results, which is interesting. This
 suggests that CWEs (or any data in the CVE entry) don’t contain enough
 information to tell whether a vulnerability is memory related. For instance &lt;a
 href="https://cwe.mitre.org/data/definitions/20.html">CWE-20, improper input
 validation&lt;/a>, may or may not result in a memory-unsafety vulnerability.
&lt;/p>

&lt;h3>Limitations Of This Analysis&lt;/h3>

&lt;p>It’s not complete: we haven’t finished categorizing all the bugs for
 &lt;b>type&lt;/b> (currently 60% done) nor for &lt;b>language&lt;/b> (currently 58%
 done).
&lt;/p>

&lt;p>The way in which it’s incomplete is not random: I did a bunch of easy ones
 first, I did some searches for particular keywords and categorized those first,
 and so on. Therefore the percentages calculated at the top are not necessarily
 what we’ll see once the categorization is complete.&lt;/p>

&lt;p>My classifications might be wrong! It’d be nice to have more people go
 through and see if they agree with how I’ve categorized things — some bugs might
 have the wrong &lt;b>type&lt;/b> or &lt;b>language&lt;/b>. If you can correct an error, fill
 in an unknown, or add more detail, please add a comment on a cell. Thanks! (See
 also the “Unknown” filter view.)&lt;/p>

&lt;p>There’s more to be done. For example, with some somewhat hairy spreadsheet
 code, you can find out some fun facts about the distribution of the bugs. For
 example, in cell F2, I’ve calculated the percentage of C/C++ bugs that are
 memory unsafety (currently 55.18%):&lt;/p>

&lt;pre>
=round(
 multiply(
 100,
 divide(
 countifs(
 B10:B1000, "=memory",
 A10:A1000, "=C/C++"),
 countif(A10:A1000, "=C/C++")
 )
 ),
2)
&lt;/pre>

&lt;p>Since the time I started this lil project, CISA has added many more rows to
 their spreadsheet. And I have not done the same analysis with other datasets
 like P0’s and Ritter’s.&lt;/p>

&lt;h2>Taxonomy&lt;/h2>

&lt;p>Here is how I categorize the vulnerabilities in CISA’s dataset:&lt;/p>

&lt;table>

 &lt;tr>
 &lt;th class="bottom right">Type&lt;/th>
 &lt;th class="bottom">Sarcastic Name&lt;/th>
 &lt;th class="bottom">Description&lt;/th>
 &lt;th class="bottom">Examples (non-exhaustive)&lt;/th>
 &lt;/tr>

 &lt;tr>
 &lt;th class="right">memory&lt;/th>
 &lt;td>“C problems”&lt;/td>
 &lt;td>Spatial or temporal memory unsafety&lt;/td>
 &lt;td>Buffer overflow, use-after-free, write-what-where, double-free,
 leak or use of uninitialized memory&lt;/td>
 &lt;/tr>

 &lt;tr>
 &lt;th class="right">eval&lt;/th>
 &lt;td>“Lisp problems”&lt;/td>
 &lt;td>Treating attacker data as interpreted code&lt;/td>
 &lt;td>SQL injection, XSS, shell injection, deserializing evil objects and loading
 their evil classes&lt;/td>
 &lt;/tr>

 &lt;tr>
 &lt;th class="right">logic&lt;/th>
 &lt;td>“Brain problems”&lt;/td>
 &lt;td>Errors in application-layer logic&lt;/td>
 &lt;td>Incorrect branch condition, incomplete information in branch condition, type
 confusion, integer semantic sadness that does not result in memory unsafety&lt;/td>
 &lt;/tr>

 &lt;tr>
 &lt;th class="right">configuration&lt;/th>
 &lt;td>“Face-palm problems”&lt;/td>
 &lt;td>Errors in default or likely deployment configuration, misfeatures&lt;/td>
 &lt;td>Leaving the debug interface on in production, web shell as a ‘feature’,
 default passwords&lt;/td>
 &lt;/tr>

 &lt;tr>
 &lt;th class="right">cryptography&lt;/th>
 &lt;td>“Math problems”&lt;/td>
 &lt;td>Errors in the use of cryptography, including not using it&lt;/td>
 &lt;td>N-once reuse, low-entropy keys, confidentiality where integrity is needed
 (or vice-versa, or both), plaintext&lt;/td>
 &lt;/tr>

 &lt;tr>
 &lt;th class="right">ux&lt;/th>
 &lt;td>“Human problems”&lt;/td>
 &lt;td>Problems that arise when the UI, UX, or social context does not match human
 needs, limitations, or expectations&lt;/td>
 &lt;td>Phishable credentials, affordances favoring errors, confusing UI or
 documentation, high effort/concentration required, UI redressing&lt;/td>
 &lt;/tr>

&lt;/table>

&lt;a id="fn1_back">&lt;/a>

&lt;p>It’s difficult to create a universally-applicable taxonomy. (Ask any
 biologist.) You can see everything as a logic bug, or you can see C’s problems
 as being user experience bugs for developers (DX): affordances that favor
 errors, too hard to use consistently safely, and counter-intuitive
 semantics&lt;a href="#fn1">①&lt;/a>.&lt;/p>

&lt;p>My categories are intentionally broad, for 2 reasons.&lt;/p>

&lt;ol>

 &lt;li>The taxa in any taxonomy typically overlap, and with software bugs, they
 seem to overlap a lot. I’m trying to account for that while also making some
 rough decision.&lt;/li>

 &lt;li>I just wanted to chew through CISA’s list of 616 bugs quickly enough to get
 a first-order approximation to the central question: “Are ⅔ of the bugs
 attackers use against C/C++ programs memory unsafety bugs, or less, or more, or
 what? And what else might be going on out there?”&lt;/li>

&lt;/ol>

&lt;p>As a defender, I typically classify bugs by asking &lt;b>what went wrong in the
 design or implementation, and how are we going to fix it&lt;/b>. What would the fix
 look like, and can it be systematic or (semi-)automated? Checking bounds,
 correcting object lifetimes, fixing an &lt;code>if&lt;/code>/&lt;code>else&lt;/code>
 condition, fixing the deployment configuration? Un-shipping a misfeature? UX
 research?&lt;/p>

&lt;p>Now, sometimes we might exploit e.g. memory unsafety to achieve type
 confusion, or vice versa, or use e.g. buffer overflow to achieve command
 injection. I categorized these bugs by what I see as the earliest error (that we
 know of) in a possible chain of errors. (Although I won’t say “&lt;a
 href="https://twitter.com/amyngyn/status/1072576388518043656">root cause&lt;/a>”,
 of course.)&lt;/p>

&lt;p>In some cases, memory safety would have stopped exploitation, even if
 memory unsafety is not the first error in the chain. I typically classified
 those as logic bugs.&lt;/p>

&lt;p>Notably, I am not classifying bugs by their outcomes during exploitation,
 e.g. information disclosure, remote code execution (RCE), local privilege
 escalation (LPE), denial of service (DoS), et c.: the same bug may have many
 possible outcomes. Nor do I classify by severity: everyone has a different
 threat model, so a standardized severity system is typically hard to apply
 meaningfully.&lt;/p>

&lt;h2>Patterns I Noticed&lt;/h2>

&lt;p>To see these patterns for yourself, it helps to make heavy use of the Filter
 View feature of Sheets. You can also make a copy and add in your own
 &lt;code>=COUNTIF&lt;/code>s and so on. I bet there are patterns I missed! Please add
 comments to the sheet or email me if you see something interesting.
&lt;/p>

&lt;h3>Recurring Bug Types&lt;/h3>

&lt;p>Path traversal accounts for a large chunk of vulnerabilities (which I
 categorize as logic). &lt;a href="/2017/11/07/problems-of-urls/">As with URLs&lt;/a>,
 text strings are an alluring but not consistently workable interface for
 describing paths from root to branch in a tree. People just can’t decode,
 resolve, or compare them consistently, and those are security-critical
 operations.&lt;/p>

&lt;p>There’s lots of ‘remote shell as a feature’ going on (which I classify as
 configuration). Debug interface? Quick-and-easy way to implement some
 functionality? Lack of proper library APIs for some functionality? All of the
 above, I’d imagine.&lt;/p>

&lt;p>CISA’s data does not count UX bugs that make phishing (of various types) and
 misuse/misconfiguration more likely or easier to attack — but we know they are a
 big part of exploitation in real life. I suspect the ux category is vastly
 underrepresented. If we counted them, ux might be greater than all the other
 categories combined.&lt;/p>

&lt;p>The goat in the room is credential phishing. &lt;b>This fatal problem will
 remain rampant until we build support for WebAuthn into all important
 services.&lt;/b>&lt;/p>

&lt;h3>Big Head, Long Tail&lt;/h3>

&lt;p>Unsurprisingly, the memory category is the biggest single category (so far),
 although it’s not fully 65% of the bugs used against C/C++ targets.&lt;/p>

&lt;p>Keep in mind that the 65% finding is for codebases that are in C/C++, but
 this dataset describes systems implemented in a variety of languages — and most
 languages are memory-safe. Memory unsafety exploitation may be over-represented
 as an attack type in the dataset; i.e. perhaps attackers in the wild are
 favoring it because of the control such bugs provide, their skill sets, stealth,
 or similar kinds of reasons.&lt;/p>

&lt;p>I’d point to eval as the true second most immediately actionable category for
 fixing/exploiting (depending on your proclivities). There’s so much easy-to-find
 stuff in that category, with a variety of techniques for discovery.&lt;/p>

&lt;p>The logic category is hugely broad — almost a default — so its prominence as
 second-biggest category might not be as meaningful or actionable. (Although you
 will see patterns in that category.) It represents a long tail of scattered bug
 classes and (hopefully) one-offs.&lt;/p>

&lt;h3>The Poor State Of Information&lt;/h3>

&lt;p>We need to have a &lt;a href="https://sre.google/sre-book/postmortem-culture/">blameless postmortem&lt;/a>
 for a way of documenting vulnerabilities that is already dead.&lt;/p>

&lt;p>These are vulnerabilities that affect people’s lives, government policy, the
 economy, civil society — all the bugs in question have been exploited ITW — yet
 there’s so much noise, obscurantism, and bravado that it’s often more difficult,
 not less, for people to decide what to do.&lt;/p>

&lt;p>We need to stop writing, and accepting, vague write-ups like “execute code
 via unspecified vectors”, “allows remote attackers to cause a denial of service
 or possibly execute arbitrary code”, “the vulnerability is due to insufficient
 handling of [data]”, and so on. (These are real examples!)&lt;/p>

&lt;p>A big part of the purpose — or, potential — for public vulnerability
 announcements and reports is to teach and learn, mature the engineering culture,
 and above all to avoid repeating these problems. And for that, we need specifics
 and we need sufficient certainty. Being vague is not the most effective way to
 compensate for risk.&lt;/p>

&lt;p>The people building the infrastructure of our world, and bodies like the &lt;a
 href="https://www.cisa.gov/cyber-safety-review-board">Cyber Safety Review
 Board&lt;/a>, are most effective when they have all the facts at hand. Aviation
 safety has made huge game-changing improvements over the decades, but not
 without full access to the (sometimes embarrassing) details. We need &lt;a
 href="http://www.feynman.com/science/the-challenger-disaster/">Feynman
 explaining the Challenger explosion&lt;/a>, not handwaving. The links I’ve added in
 the &lt;b>additionalDetail&lt;/b> column are, overall, much more like the
 Feynman-grade stuff we need to get a real grip on what’s going on.&lt;/p>

&lt;h4>The Desperate Cry For True Facts&lt;/h4>

&lt;p>Working on this classification project required us to hunt for additional
 details when the official descriptions were lacking. In about 9 hours of work, I
 was able to get through about 45% of the 616 bugs. If the official descriptions
 had had enough content, I could likely have finished 100% in much less time.&lt;/p>

&lt;p>Hunting for bug detail led me to the unfortunate conclusion that a CVE number
 is little more than a search keyword. You always have to go to hacker blogs, bug
 trackers, and find and read PoCs. Very occasionally, the vendor’s announcement
 would have more detail than the CVE entry.&lt;/p>

&lt;p>Pro Tip: Don’t start by just searching for the CVE number. The top 10 hits
 are going to be just sites that copy the CVE entry. (I will file this as a
 Search quality bug when I get to work on Monday.) Instead, you have to be more
 precise (the quotes help):&lt;/p>

&lt;ul>
 &lt;li>&lt;code>"cve-abcd-efgh" "github"&lt;/code>&lt;/li>
 &lt;li>&lt;code>"cve-abcd-efgh" "blog"&lt;/code>&lt;/li>
 &lt;li>&lt;code>"cve-abcd-efgh" "project zero"&lt;/code>&lt;/li>
&lt;/ul>

&lt;p>Sometimes you can get some detail by searching Twitter, too.&lt;/p>

&lt;h2>The Future&lt;/h2>

&lt;p>Ultimately, all software bugs are logic errors — software is logic. But what
 I’m looking for are systematic ways to correct errors, and the bug
 classifications reflect that. As defenders, we shouldn’t fix individual buffer
 overflows; we must stop using C. We shouldn’t fix SQL injections; we must use
 parameterized queries. We shouldn’t fix shell injections; we must stop using
 &lt;code>system&lt;/code> and &lt;code>popen&lt;/code>, and instead build and use real APIs.
 We shouldn’t fix instances of XSS; we must use a structured templating system.
 And so on.
&lt;/p>

&lt;p>Almost all of the exploited vulnerabilities are quite mundane, and solvable
 by mundane means. They’re not sexy or weird or surprising — and that’s good
 news. So much pain and trouble can be solved with simple tools that we already
 have.&lt;/p>

&lt;p>We need to get increasingly clear about implementation quality requirements.
 This includes stopping new uses from getting into our codebases (with presubmit
 scripts or Git hooks) and systematically auditing for them and treating them as
 bugs and technical debt to prioritize paying off. Often, you can simply grep or
 &lt;a href="https://github.com/googleprojectzero/weggli">weggli&lt;/a> for these, and
 get a list. There’s also &lt;a href="https://codeql.github.com/">CodeQL&lt;/a>.
&lt;/p>

&lt;p>Our goal as software engineers should be to eventually get down to only bugs
 that are one-offs, specific to the application.&lt;/p>

&lt;h2>Acknowledgements&lt;/h2>

&lt;p>Thanks to Dev Akhawe for helping me categorize the bugs, and thanks to
 Jonathan Rudenberg and Eric Rescorla for reading early drafts and proposing
 improvements. Jack Cable mapped the CWEs to the taxonomy I use here. Any errors,
 and there are surely many, obviously remain my own.&lt;/p>

&lt;hr />

&lt;a id="fn1">&lt;/a>

&lt;p>&lt;b>&lt;a href="#fn1_back">1.&lt;/a>&lt;/b> You might even call memory unsafety a form
 of eval, if you’re feeling silly (and I always am). I propose the following
 addendum to &lt;a href="https://en.wikipedia.org/wiki/Greenspun%27s_tenth_rule">Greenspun’s 10th
 rule&lt;/a>:&lt;/p>

&lt;blockquote>

 &lt;p>Any sufficiently complicated C or Fortran program contains an ad hoc,
 informally-specified, bug-ridden, slow implementation of half of Common Lisp.
 This includes &lt;code>eval&lt;/code>.&lt;/p>

&lt;/blockquote>

&lt;p>After all, &lt;a href="http://forum.ouah.org/FormatString.PDF">what is
 &lt;code>%n&lt;/code> but a hard-to-use form of &lt;code>eval&lt;/code>&lt;/a>? 🤔 🤨&lt;/p></description><author>Chris Palmer</author><guid>2022/04/22/itw-taxonomy/index.html</guid><pubDate>Sat, 16 Apr 2022 00:00:00 +0000</pubDate></item><item><title>“Flood” By Throwing Muses</title><link>https://noncombatant.org/2022/04/04/throwing-muses-flood/index.content</link><description>&lt;h1>“Flood” By Throwing Muses&lt;/h1>

&lt;p>&lt;time>4 April 2022&lt;/time>&lt;/p>

&lt;p>Here’s another super-favorite: “Flood” by Throwing Muses, from the banger &lt;a
href="https://en.wikipedia.org/wiki/University_(album)">&lt;i>University&lt;/i>&lt;/a>.
For me, it’s the feeling of waking up in the ICU, pumped to the gills full of
fentanyl, knowing that my Bright Light is there.&lt;/p>

&lt;p>For this one, I’ve tried to approximate the vocal melody and have taken a
wild stab at the articulation and (in the verse) the harmony. It’s good practice
to try to play vocal parts on your instrument!&lt;/p>

&lt;p>The organic, ‘no rules, just feels right’ arrangement, with the odd numbers
of repeats and truncated repeats, is interesting to me. It underscores that the
accompaniment really follows the vocal — as sparse and as understated as it is,
the vocal is leading the guitars and drums around. Kristin Hersh isn’t afraid to
get a touch proggy, but she always does it in a song-y way. The nerd details
don’t seem premeditated as much as a side effect of just going where the lyric
needs to go, whenever that might happen. Not all feelings fit into 4 repeats of
a 4-bar phrase!&lt;/p>

&lt;p>The bass gives the long verse phrase movement, guiding your body through the
narrative. Especially in bar 18, it takes you through the odd end of the verse
as it lands neatly at the bridge (and a deft key change).&lt;/p>

&lt;p>I didn’t transcribe Jane Scarpantoni’s cello part, unfortunately, and I
didn’t write out all the vocal variations in the chorus. Perhaps I am a lazy
goat, but at least I got this far. I’m absolutely starving for dinner.&lt;/p>

&lt;p>I really like suspended chords in general; but especially here, the way they
leave room for the vocals to provide the thirds. The guitar is out of the
vocal’s way — but only barely! Those suspensions ambiguously lurk
throughout.&lt;/p>

&lt;iframe src="throwing-muses-flood.pdf" width="100%" height="500"
loading="lazy">&lt;/iframe></description><author>Chris Palmer</author><guid>2022/04/04/throwing-muses-flood/index.html</guid><pubDate>Mon, 04 Apr 2022 00:00:00 +0000</pubDate></item><item><title>“Red” By King Crimson</title><link>https://noncombatant.org/2022/03/11/red-king-crimson/index.content</link><description>&lt;h1>“Red” By King Crimson&lt;/h1>

&lt;p>&lt;time>11 March 2022&lt;/time>&lt;/p>

&lt;!--
https://www.quora.com/Why-do-some-riffs-that-don-t-fall-into-any-scale-or-theory-sound-good/answer/Alex-Johnston-39?ch=99&amp;oid=300467355&amp;share=0050bfea&amp;srid=hkm2R&amp;target_type=answer
-->

&lt;p>I love this tune.&lt;/p>

&lt;p>Rather than try to figure out what scale(s) the melody is in, I think of it
as movements of major chords in minor and major thirds. I’d maybe even go so far
as to suggest that the fact that the 2nd melody is almost all in the diminished
scale is just a nice coincidence. (The last note, F♯, is not in the diminished
scale but is the third of the chord, D.)&lt;/p>

&lt;p>I feel the introductory rhythm in 4/4, and treat the note groupings as
syncopated accent groups (5 + 5 + 5 + 9) rather than as meter changes. It
suggests polyrhythmic possibilities to me.&lt;/p>

&lt;p>I’ve written the opening chords as all having a ♯11. That’s the overall
harmonic vibe, although nobody actually frets a ♯11 chord. The bass plays major
triads in various inversions (and one root-fifth power chord), and the guitar
plays the chord’s third with the ♯11 as passing tones on the way to the next
chord. The ♯11 passing tritone resolves to the perfect fifth — the major third
of the next chord! (And that’s why the B diminished scale ends on an F♯: it’s
the major third of the D chord in the bass.)&lt;/p>

&lt;p>I find that beautiful: It’s not super weird, it’s super simple! And that’s
super weird!&lt;/p>

&lt;p>Moving major chords in major thirds is common in 20th century music. I think
of that chord change, I — III, as a generalization of the Harmonic Minor i — V
— i tension and resolution. If you consider A harmonic minor, Am — E — Am, then
C — E — C is just substituting the relative major of Am. But it opens up so many
possibilities! I hear it everywhere.&lt;/p>

&lt;p>I think, and hope, that the rest of the sketch of a transcription is
accurate. It disagrees here and there with other transcriptions on the
intertron, especially in the 🄸 Interlude, and my take on the bass in the verse
may not be exactly right.&lt;/p>

&lt;p>During the verse, try to do those string bends only on ③ — keep the E note on
④ as steady as you can.&lt;/p>

&lt;p>I didn’t write out the whole song, because once you’ve got these parts, the
rest is repetition with some ad lib variations here and there. The structure is
set, but within that you have some freedom to play around. At the bottom I show
what Fripp often does in the verse, as well as my favorite verse ad libs.&lt;/p>

&lt;p>If you spot any errors, please email me. 🙂&lt;/p>

&lt;iframe src="king-crimson-red.pdf" width="100%" height="500"
loading="lazy">&lt;/iframe></description><author>Chris Palmer</author><guid>2022/03/11/red-king-crimson/index.html</guid><pubDate>Fri, 11 Mar 2022 00:00:00 +0000</pubDate></item><item><title>Kill Your Email</title><link>https://noncombatant.org/2022/03/05/kill-your-email/index.content</link><description>&lt;h1>Kill Your Email&lt;/h1>

&lt;p>&lt;time>5 March 2022&lt;/time>&lt;/p>

&lt;figure>&lt;img loading="lazy" src="kill-tv.jpg" width="500" height="261" alt="The
iconic sticker saying “Kill Your Television”" />
 &lt;figcaption>The face of the enemy
 changes with the decades.&lt;/figcaption>
&lt;/figure>

&lt;p>What distinguishes email from other digital communications is that it has
 become a world-writable to-do list. A world-writable to-do list is an
 abomination that steals our time, our attention, our autonomy, and our souls. It
 stops us from doing productive work.&lt;/p>

&lt;p>We should resist email, and prefer most other form of communications. But
 until we kill the concept of email, we have to live with it. Here is how I kill
 my email before it kills me.&lt;/p>

&lt;p>My to-do list items seem to have a bimodal distribution: there are things I
 can resolve in less than 2 minutes, and things that require work. For me, there
 isn’t much in between. So, I split my inbox into 2 sections, using Gmail’s
 Multiple Inboxes feature.&lt;/p>

&lt;figure>&lt;img loading="lazy" src="multiple-inboxes.png" width="774" height="569" alt="The Multiple Inboxes settings under Inbox in Gmail
Settings" />
 &lt;figcaption>Turn on Multiple Inboxes, with 1 section set to the
 search query &lt;code>is:starred&lt;/code>.&lt;/figcaption>
&lt;/figure>

&lt;p>My main inbox is new to-dos that people have sent me. The 2nd section of my
 inbox is any email I’ve ‘starred’. I read my inbox from the bottom (oldest) up,
 either resolving them immediately or starring and archiving them if they can’t
 be resolved quickly. I then work my way up to the top, achieving 💖 Inbox Zero
 💖. I do this about twice a day.&lt;/p>

&lt;p>When burning down the inbox, I do not hesitate — I don’t put off burning down
 that thing whose subject line makes me anxious. There are only 2 possible
 outcomes, neither of which is too scary: either I’ll resolve it right then and
 there, or it goes into the starred list to be worried about later.&lt;/p>

&lt;p>Then, I work my way through the list of starred items, again from oldest to
 newest, and un-star them as I finish them. These are the tasks that constitute
 work. When chewing through these, I consider whether they represent work that
 furthers my goals, if they are properly somebody else’s job, or if they are not
 all that important. I am ruthless about this: either this task is part of my
 job, or it is not. If I don’t think it is, &lt;i>bonk&lt;/i> — unstarred. If it was
 really important for me to do, people will raise it again. If not, well, I have
 important things I need to achieve, and only 8 hours in the day.&lt;/p>

&lt;p>I also use Gmail’s keyboard shortcuts. I find they help the initial
 inbox-murder phase go faster: when you’re skimming subject lines, you can
 assassinate many mails without even opening them. I archive everything in case I
 need to look it up later. I typically only delete messages that I sent myself to
 represent tasks, after I’ve completed them.&lt;/p>

&lt;p>Needless to say, notifications are anathema and have no place in our wild and
 precious lives.&lt;/p>

&lt;figure>&lt;img loading="lazy" src="snortcuts-no-tifications.png" width="672" height="540" alt="The Keyboard Shortcuts and Notifications settings in Gmail
Settings" />
 &lt;figcaption>Turn keyboard shortcuts on. Put the No back in
 Notifications.&lt;/figcaption>
&lt;/figure>

&lt;p>I also use Chrome’s ‘Shortcut’ feature to turn a tab into its own window.
 This allows me to fully maximize that window, with no browser controls. I find
 this minimizes distraction.&lt;/p>

&lt;figure>&lt;img loading="lazy" src="create-shortcut.png" width="745" height="602"
 alt="dots menu → More Tools → Create Shortcut..." />
 &lt;figcaption>Create a shortcut
 for your email. This allows you to run it in its own window, not as a browser
 tab.&lt;/figcaption>
&lt;/figure>

&lt;p>You’ll get this dialog box:&lt;/p>

&lt;figure>&lt;img loading="lazy" src="open-as-window.png" width="457" height="195" alt="Chrome’s Create Shortcut dialog" />
 &lt;figcaption>Check the Open As Window box
 in the Create Shortcut dialog.&lt;/figcaption>
&lt;/figure>

&lt;p>I then pin this window/app to my macOS Dock.&lt;/p>

&lt;p>Go forth and kill email!&lt;/p>

&lt;figure>&lt;img loading="lazy" src="kill-kill.jpg" width="512" height="776"
 alt="The poster for the movie Faster, Pussycat! Kill! Kill!" />
 &lt;figcaption>I’ve
 never actually seen &lt;a href="https://en.wikipedia.org/wiki/Faster,_Pussycat!_Kill!_Kill!">the
 movie&lt;/a>.&lt;/figcaption>
&lt;/figure></description><author>Chris Palmer</author><guid>2022/03/05/kill-your-email/index.html</guid><pubDate>Sat, 05 Mar 2022 00:00:00 +0000</pubDate></item><item><title>More 7th Arpeggios</title><link>https://noncombatant.org/2022/02/21/more-7th-arpeggios/index.content</link><description>&lt;h1>More 7th Arpeggios&lt;/h1>

&lt;p>&lt;time>21 February 2022&lt;/time>&lt;/p>

&lt;p>&lt;a href="/2022/02/20/7th-arpeggios/">The last post&lt;/a> showed arpeggio shapes
for 4 types of 7th chords: major 7, minor 7, dominant 7, and half-diminished 7
(&lt;sup>∅&lt;/sup>7). There’s more fun to be had: here we see diminished 7, augmented
7, and minor/major 7. The Harmonic Minor scale is a chance to use them (C♯
Harmonic Minor, in this case). For extra fun, you can use either or both of the
haf-diminshed 7 and the diminished 7 in the ii° (which is D♯, in this key).&lt;/p>

&lt;p>With these shapes, the fretting can get a little hairy. Note the position
shift with the diminished shape: for the Edim7, we have to shift from VII
position to VI.&lt;/p>

&lt;p>For the Eaug7 (also sometimes written E+7), it’s really in the VIII position,
with a stretch back to the VII for the tonic. Stretch-o-rama, but it’s more
doable if you get your thumb on the back of the neck as if you were in the VIII
position. For me, that’s just behind the 9th fret.&lt;/p>

&lt;p>For the min/maj7, there’s a stretch on ①, but I find the pull-off from the
3rd finger to the 2nd, when coming back down on ③, to be the real hard part.&lt;/p>

&lt;iframe src="more-7th-arpeggios.pdf" width="100%" height="500"
loading="lazy">&lt;/iframe></description><author>Chris Palmer</author><guid>2022/02/21/more-7th-arpeggios/index.html</guid><pubDate>Mon, 21 Feb 2022 00:00:00 +0000</pubDate></item><item><title>Arpeggios Of 7th Chords</title><link>https://noncombatant.org/2022/02/20/7th-arpeggios/index.content</link><description>&lt;h1>Arpeggios Of 7th Chords&lt;/h1>

&lt;p>&lt;time>20 February 2022&lt;/time>&lt;/p>

&lt;p>I took some guitar lessons from &lt;a
href="https://twitter.com/AndeeBlackSugar">Andee Blacksugar&lt;/a> for a good long
while, and had some fun. One thing he taught me was this 2—1—2—1—2 pattern for
7th-chord arpeggios: root and 3rd on ⑤, 5th on ④, 7th and octave on ③, 3rd on ②,
and 5th and 7th on ①. I find it easier to play than other arpeggio patterns I’ve
learned.&lt;/p>

&lt;p>For fun, I decided to write out one of the warm-up exercises I wrote that
uses this pattern. It just goes up the scale and back down again in scale
degrees, but there are some amusing twists: the metric phasing, and the legato
makes the picking seem weird (but it strictly follows the “down on the beat, up
on the up-beat” pattern — it only &lt;i>seems&lt;/i> weird).&lt;/p>

&lt;p>I notated the fretting-hand fingerings I use; your mileage my vary. On the
major 7th shape, for example, you can barre or roll your 2nd finger on ③ and ②
instead of my perhaps-idiosyncratic fingering.&lt;/p>

&lt;iframe src="7th-arpeggios-exercise.pdf" width="100%" height="500"
loading="lazy">&lt;/iframe></description><author>Chris Palmer</author><guid>2022/02/20/7th-arpeggios/index.html</guid><pubDate>Sun, 20 Feb 2022 00:00:00 +0000</pubDate></item><item><title>Thoughts On Language Design Bugs</title><link>https://noncombatant.org/2021/10/23/thoughts-on-language-design-bugs/index.content</link><description>&lt;h1>Thoughts On Language Design Bugs&lt;/h1>

&lt;p>&lt;time>23 October 2021&lt;/time>&lt;/p>

&lt;p>This post is an attempt to answer some pretty reasonable questions my friends
and colleagues have asked me, on the topic of programming language security. If
you’ve read anything else I’ve written, you know I believe the 2nd-biggest
software security engineering problem is the unsafety of C and C++. What that
implies and what to do about it is not necessarily obvious. So here are some
lightly paraphrased questions, and my general thoughts.&lt;/p>

&lt;p>(The 1st-biggest problem is all about human factors: abuse, phishing, and
accessibility.)&lt;/p>

&lt;div id="toc">&lt;/div>

&lt;h2>Is JavaScript Memory-Unsafe?&lt;/h2>

&lt;blockquote>Why do you call JS and Python ‘safer’? Since (e.g.) JavaScript is
implemented in C++, doesn’t that make it just as memory-unsafe as
C/C++?&lt;/blockquote>

&lt;p>Yes — and no. The kernels of the implementations of languages like Python,
JavaScript (JS), and Java are typically in C/C++ and they certainly do exhibit
memory unsafety and other C/C++ undefined behavior (UB) bugs. (Memory unsafety
is a subclass of UB.) However, these languages intend to limit UB as part of
their interface or contract. Minimizing or eliminating memory unsafety is a
design goal.&lt;/p>

&lt;p>Thus, crucially, UB bugs in these languages are &lt;b>implementation bugs&lt;/b>.
The (e.g. Python) developers fix them once, and then everyone benefits from the
implementation getting closer to the interface semantics. The implementation can
inch closer to the ideal of the interface, and the community can adopt the
improvement at scale.&lt;/p>

&lt;p>In C/C++, by contrast, UB is considered &lt;b>a design ‘feature’, not a bug&lt;/b>.
The language design committees and compiler developers won’t fix such bugs. Even
brand new features in C++ introduce new UB — it’s not considered a historical
mistake to be corrected.&lt;/p>

&lt;p>It might seem like Python, JS, et c. are safe wrappers around unsafe code.
And they can be, and (depending on the specific implementation) more or less
are. For example, if an application implemented in Python is successfully
attacked, it’s much more likely to have been from a bug in the application logic
than from a use-after-free or a buffer overflow in a list comprehension or other
core Python feature.&lt;/p>

&lt;p>Thus, a safe language implemented in an unsafe language might be OK, to the
extent that we can scale up fixing the errors in the implementation. But that’s
highly variable, as the next question raises.&lt;/p>

&lt;h2>What’s Happening With JavaScript Security?&lt;/h2>

&lt;blockquote>What about the fairly rough time JS implementations are having? They
don’t seem to be getting incrementally closer to the interface
ideal.&lt;/blockquote>

&lt;p>Yes, this is a notable problem. I think there are a few reasons the problem
exists, and is apparent.&lt;/p>

&lt;p>JS implementations are quite complex and large. Any large body of C/C++ code
is going to have a lot of problems. By contrast, the implementations of (say)
Lua and Self are notably concise, and Python is large but not huge. (And a good
chunk of Python’s size is auto-generated code.) If we assume roughly equivalent
bug-density per line across developers — in general we have no reason to assume
otherwise — less code means fewer bugs.&lt;/p>

&lt;p>Additionally, defensive and offensive security research teams are hunting
night and day, en masse and at scale, for bugs in JS implementations
specifically. If another language suddenly grew to equivalent prominence, it
might face similar scrutiny and perhaps the known bug count would go up.&lt;/p>

&lt;p>But there is a 3rd critical issue: Many of the bugs affecting JS
implementations are not vanilla C/C++ UB implementation bugs. For Reasons, JS
happens to face fairly intense scrutiny on raw micro-performance, which
typically leads developers to cut corners on correctness. (That’s the usual
justification for C/C++’s UB, too. Such an extreme performance focus can make
sense in some circumstances, but in the vast majority of cases it’s the wrong
trade-off.)&lt;/p>

&lt;p>As part of achieving high performance, JS engines typically include several
different run-time compilers (just-in-time or JIT compilers) to transform the
code at run-time into a faster form. To build not 1 but several such systems
into your language implementation is a significant and complex undertaking
— especially when the pressure is on to go fast and save battery life on
people’s phones.&lt;/p>

&lt;p>For example, JS implementations often have JIT optimization bugs that go
something like this: “We thought we could optimize by removing this dynamic type
check, because we thought we had a solid argument that the object is guaranteed
to be of type &lt;code>T&lt;/code>. But, we were wrong.” (This kind of thing is quite
hard to get right.) And then the JIT emits memory-unsafe object code due to
erroneous assumptions during compilation. This class of bug is not due directly
or uniquely to C/C++.&lt;/p>

&lt;h2>Why Don’t We Rewrite Everything In Safer Languages?&lt;/h2>

&lt;blockquote>Given that C/C++ UB creates so many problems — causing the
implementations of languages to not live up to their designs — why aren’t the
likes of Python and other languages being rewritten in memory-safe
languages?&lt;/blockquote>

&lt;p>First, because it’s expensive to do that. There are whole teams working hard
to make it less expensive to transition large codebases from C/C++ to modern
languages, but it’s just not a cheap or easy thing to do yet. Whether it is
possible to make it cheap enough at all is an open research question. Whether or
not it succeeds, I hope that the work being done now, in several organizations,
is made public. Even negative results would be hugely useful.&lt;/p>

&lt;p>Additionally, separate from C/C++ UB, there exists a claim that developers
would just as likely make the same JIT compiler logic errors in a safer language
as they do in C/C++. In switching to a safer language, you would get rid of the
‘simple’ or direct UB and memory-unsafety problems, but JIT compilers would
still be difficult.&lt;/p>

&lt;p>I hypothesize that some such compiler and interpreter logic bugs can be
approached as type errors and state machine transition errors, and thus
automatically detected and prevented by the implementation language’s own type
semantics. (For example, consider a bug where it should never have been possible
to move from state 1 to state 2 with an object of type &lt;code>T1&lt;/code>, only
with a &lt;code>T2&lt;/code>. This is known as &lt;a
href="https://cliffle.com/blog/rust-typestate/">the typestate pattern&lt;/a>, and
it might help with certain of the problems that dynamic language run-times
face.)&lt;/p>

&lt;h3>Micro-Performance vs Correctness: An Ecosystem Problem&lt;/h3>

&lt;p>To a significant extent, though, the semantics of JS, Lua, and Python are
highly dynamic — and that means there’s an inherent tension between the run-time
cost of dynamic correctness checks vs. raw micro-performance. Dynamism is an
awesome feature, but it comes at the cost of some machine-level performance.&lt;/p>

&lt;p>I believe the right approach to this trade-off is to focus on
macro-performance, and to stop worrying about micro-performance for a while.&lt;/p>

&lt;p>(At an absolute level, the micro-performance of modern JS engines is
absolutely stunningly awesome. Part of the reason we are having these problems
is that the developers of these engines have already done the impossible 10
times over, and now they’re looking for some 11th win. And, who knows... they’re
so good at what they do, they might very well find it. JS engine developers have
effectively solved the micro-performance problem of dynamic languages. It’s
impossible to understate the excellence of that — in part because it makes safer
languages that much more applicable and deployable! So we should all thank
performance-oriented engineers for this safety.)&lt;/p>

&lt;p>What’s wrong with JS performance — why some pages or apps make your phone
warm — no longer has much to do with whether we do or don’t elide a dynamic
correctness check. It’s all about JS ecosystem problems.&lt;/p>

&lt;ul>

&lt;li>

&lt;p>Your favorite news site pulls in garbage from Outbrain or whomever. &lt;a
href="https://en.wikipedia.org/wiki/Transclusion">Transclusion&lt;/a> is a key
(beautiful) feature of the web, but page authors often transclude content
developed by maniacs who have no concern for the performance and reputation of
the transcluder.&lt;/p>

&lt;p>To address this problem, &lt;a
href="https://developers.google.com/web/updates/2020/05/heavy-ad-interventions">some
browsers do enforce limits on 3rd-party resource consumption&lt;/a>, but they are
too generous. These interventions require the browser to be able to recognize 3P
resources as such, which is not always possible. A common practice on the web is
to pull the 3rd-party content into the first party itself: what should be
&lt;code>&amp;lt;iframe src="https://ads.com/ad"&amp;gt;&amp;lt;/iframe&amp;gt;&lt;/code> becomes
&lt;code>&amp;lt;script src="https://ads.com/ad"&amp;gt;&amp;lt;/script&amp;gt;&lt;/code>. At that
point, the browser can’t reliably recognize the 3P script as 3P, and thus to
impose limits on its performance and functionality would be even more
contentious than it already is.&lt;/p>

&lt;/li>

&lt;li>

&lt;p>The JS standard library is too small, and that encourages the development of
&lt;a href="https://www.npmjs.com/">an oversized and intensely interdependent
contingent ecosystem of 3rd-party modules&lt;/a> to provide genuinely missing, but
also trivial or &lt;a
href="https://philipwalton.com/articles/loading-polyfills-only-when-needed/">unnecessary&lt;/a>,
functionality. These modules are not always implemented to the standards of
quality that we expect in a modern language’s standard library. And they’re
interdependent: if you pull in 1 module to do 1 thing, it might likely pull in
many of its own transitive dependencies.&lt;/p>

&lt;p>Many web pages include many of these modules, which increases the amount of
JS code that needs to be sent to your browser and then parsed, compiled, and
executed. &lt;a
href="https://infrequently.org/2018/09/the-developer-experience-bait-and-switch/">The
size of web pages has been growing quickly&lt;/a>, and of all bytes in a web page,
JS bytes are the most expensive.&lt;/p>

&lt;/li>

&lt;li>

&lt;p>JIT compilation is a valiant and often successful approach to improving time
efficiency, but it has trade-offs that can be significant. Transforming code to
be faster takes time. The faster you want the code to be, the more analysis the
JIT compiler has to do, and that takes more time and power. Additionally, the
JIT compiler has to store the newly-transformed code somewhere, and that takes
up precious memory. On top of that, using more memory can sometimes incur a time
penalty, too.&lt;/p>

&lt;p>So in some cases, the net effect of JIT can be negative; in other cases, it’s
worth it but expensive. If you turn off JIT compilation, you can potentially
improve correctness and security (no JIT → no JIT bugs), and you might not
notice a performance penalty. (See &lt;a
href="https://microsoftedge.github.io/edgevr/posts/Super-Duper-Secure-Mode/">turning
off JIT in Edge&lt;/a>, and &lt;a
href="https://chromeenterprise.google/policies/#DefaultJavaScriptJitSetting">in
Chrome&lt;/a>. Note that you will possibly see a compatibility penalty: pages that
use WebAssembly won’t work in JITless mode.)&lt;/p>

&lt;p>This too is an ecosystem problem. If, hypothetically, 1 JS implementation
were to unilaterally take a less aggressive approach to JIT compilation (for
example, only doing JIT compilation after observing strong signals that it is
really necessary, rather than doing it eagerly), the tech press and competing
firms would publish misleading micro-benchmarks showing that in certain
circumstances other JS implementations ran ‘faster’. Even if the total system
performance that people actually experience (including heat, battery life,
memory consumption, other applications starving for resources, et c.) improved
under the ‘gentle JIT’ policy, it might not be tenable (or, at least not easy)
to ship under existing market(ing) conditions.&lt;/p>

&lt;/li>

&lt;/ul>

&lt;h2>So What Are We Supposed To Do?&lt;/h2>

&lt;p>Given that we are drowning in the personal, ecosystem, and political
consequences of C/C++ UB bugs and vulnerabilities, but that reimplementing is
expensive and difficult, what in the actual shit are we supposed to do right now
with the systems we depend on?&lt;/p>

&lt;p>First and foremost, as a matter of professional ethics and responsibility, no
green-field development must be done in unsafe languages. The behind-the-curve
technology of the 1970s has not enabled and will not enable us to meet the
requirements of the 2020s and 2030s. We have to put a lot of work into working
around its problems, as I describe below, and we have to enter into that effort
knowing that it is all repair work and not new advancement.&lt;/p>

&lt;p>Complementarily, we must do everything we can to minimize the amount of
maintenance and development we do in unsafe languages. That means gradually
migrating old code to safer languages, developing the new features of existing
systems in safer languages, replacing or removing components implemented in
unsafe languages, and so on.&lt;/p>

&lt;p>In the limited and blocked-off area of maintenance and development in unsafe
code, there is actually a lot we can do to improve things. First, take the
micro-performance heat off by exploring solutions to the macro-performance
problems, whatever they might be. (Look for amplifiers at the application level.
Does 1 click incur 100 requests or operations?) When the micro-heat is off, you
can breathe a little and start looking into correctness and security.&lt;/p>

&lt;p>Keep testing. Incentivize testing and bug finding. More. Incentivize fixing
bugs, polish, quality. More. It must be possible to get promoted to and
compensated at a high level for measurably improving code quality, instead of
shipping new features. It does sometimes happen, but overall most software
development organizations need a significant culture change.&lt;/p>

&lt;p>Although C/C++ cannot be ‘fixed’, there is quite a bit we can do to minimize
and avoid the problems of these languages.&lt;/p>

&lt;ul>

&lt;li>

&lt;p>Ignore and replace the standard libraries. They are riddled with historical
and recent design bugs. Fortunately, alternatives exist: for example, you can &lt;a
href="https://github.com/abseil/abseil-cpp/blob/master/absl/base/options.h#L211">harden
Abseil&lt;/a>, and/or write your own replacements that prioritize your
requirements. It’s sad that we have to do this, but we do.&lt;/p>

&lt;p>On the bright side, we stand to gain a lot of efficiency &lt;b>and&lt;/b>
correctness &lt;b>and&lt;/b> ergonomics — the standard libraries leave us in the rare
position of not necessarily having to trade these things off. Take this
opportunity! Abseil did, and it’s great.&lt;/p>

&lt;p>From an ecosystem perspective, it would be much better if the correctness-
and safety-interested C++ communities rallied around a few new API designs and
new implementations: a new standard built to modern expectations.&lt;/p>

&lt;/li>

&lt;li>

&lt;p>Paper over the core language semantic problems to the extent possible. You
can do this with non-standard compiler flags: turn on bounds-checking for
arrays, turn on Undefined Behavior Sanitizer in trapping mode in production, and
turn on all compiler warnings and actually think about them. (Even the annoying
ones can point to real bugs — yes, even &lt;code>-Wpadded&lt;/code>.)&lt;/p>

&lt;p>Create new types to replace the built-in types. (Many people have made their
own integers, for example; here’s &lt;a
href="https://github.com/Google/integers">my start at a run at the integer
semantics problem&lt;/a>. I include pointers to several other designs on the idea.
I don’t claim mine is perfect, but I do think some form of integer improvement
is critical.)&lt;/p>

&lt;/li>

&lt;li>

&lt;p>Push the type system as far as you can, to assert correctness. C++ might not
have as fancy a type system as Haskell or Rust, but it is flexible, and you can
establish new patterns and helper libraries to get a more ergonomic experience.
For example, you could certainly implement the typestate pattern, or traits, or
spiffier &lt;code>enum&lt;/code>s (&lt;code>enum class&lt;/code> exists!) in C++. It might
require establishing new idioms, but, we can do that. It’s a lot cheaper than
reimplementing everything, and it might make gradual migration and
interoperability easier, too.&lt;/p>

&lt;/li>

&lt;/ul></description><author>Chris Palmer</author><guid>2021/10/23/thoughts-on-language-design-bugs/index.html</guid><pubDate>Sat, 23 Oct 2021 00:00:00 +0000</pubDate></item><item><title>A Fun Harmonic Game</title><link>https://noncombatant.org/2021/10/01/fun-harmonic-game/index.content</link><description>&lt;style>
 iframe {
 width: 100%;
 height: 40em;
 }
&lt;/style>

&lt;h1>A Fun Harmonic Game&lt;/h1>

&lt;p>&lt;time>1 October 2021&lt;/time>&lt;/p>

&lt;aside>
 &lt;p>Update: A friend, whose brother is a composer, pointed out that this
 is known as &lt;a href="https://en.wikipedia.org/wiki/Neo-Riemannian_theory">an “L”
 transformation in neo-Riemannian theory&lt;/a>. TIL! Every so often, the internet
 actually delivers on its promise. 🤓🥳&lt;/p>
&lt;/aside>

&lt;p>The other day I discovered a fun harmonic game. It’s a bit like &lt;a
 href="https://www.thejazzpianosite.com/jazz-piano-lessons/jazz-chord-progressions/line-cliches/">the
 line cliché&lt;/a>, but (I think) a bit more challenging. Here are the rules:&lt;/p>

&lt;ol>

 &lt;li>Use only the 4 basic triads (major, minor, augmented, diminished). Start
 with any triad.&lt;/li>

 &lt;li>To get the next triad, move only 1 note of the chord up or down 1 half
 step.&lt;/li>

 &lt;li>Each chord change must change its root. (For example, E major → E minor is
 not allowed. Don’t cheat by using enharmonic names! 😉)&lt;/li>

&lt;/ol>

&lt;p>That’s it! It’s simple, but the limitations are tight. I find it’s a bit hard
 to end up with a progression that works, but you can surprise yourself, and
 perhaps come up with something you would not have otherwise.&lt;/p>

&lt;p>You can make it significantly easier and generate richer changes by removing
 rule 1 or rule 3.&lt;/p>

&lt;p>Here are some ideas I like. (Note that example 🄱 breaks rule 3.)&lt;/p>

&lt;iframe src="2021-09-30 Study.pdf" loading="lazy">&lt;/iframe></description><author>Chris Palmer</author><guid>2021/10/01/fun-harmonic-game/index.html</guid><pubDate>Fri, 01 Oct 2021 00:00:00 +0000</pubDate></item><item><title>Improving Software ‘Numbers’</title><link>https://noncombatant.org/2021/09/26/improving-software-numbers/index.content</link><description>&lt;h1>Improving Software ‘Numbers’&lt;/h1>

&lt;p>&lt;time>26 September 2021&lt;/time>&lt;/p>

&lt;aside>
 &lt;p>Update: Thanks again to Saleem Rashid, this time for pointing me at &lt;a
 href="https://stdrs.dev/nightly/x86_64-unknown-linux-gnu/core/num/struct.Saturating.html">&lt;code>Saturating&lt;/code>
 in Rust Nightly&lt;/a>.&lt;/p>
&lt;/aside>

&lt;p>Programming languages should expose a flexible variety of explicit types and
 operators for handling arithmetic overflow and related problems. As language
 design problems go, this might be relatively less difficult to achieve. Rust is
 closest to where programming languages need to be, but not all the way there
 yet.&lt;/p>

&lt;p>I believe that software should be able to reliably compute arithmetic
 expressions. You may say I’m a dreamer, but I’m not the only one.&lt;/p>

&lt;p>To represent an infinite set in finite space is problematic. This is not news
 to most software engineers. We always need a coherent policy for how to deal
 with our inability to represent some elements of infinite sets, or expressions
 that would evaluate to representable elements if only we had space.&lt;/p>

&lt;p>We can consistently apply some policy (whatever it may be) using the
 language’s type system: by encoding policy in the set’s type, and operators on
 and functions of it, we can get (if nothing else) consistent representation of
 and behavior in error states. (I’ll call them &lt;i>representation errors&lt;/i>
 generically.)&lt;/p>

&lt;p>Surely, we can all agree that this is the minimum necessary for
 program correctness.&lt;/p>

&lt;p>Surely, we can all agree that correctness is the minimum necessary for
 program safety.&lt;/p>

&lt;p>Surely, we can all agree that providing people correct and safe software is
 our duty as engineers.&lt;/p>

&lt;p>Even the most fundamental objects of computation, the reals and the integers
 and arithmetic on them, require some policy for unrepresentable values — even if
 it is simply to crash when no more memory is available to an arbitrary-precision
 arithemtic library (for example).&lt;/p>

&lt;p>Machine words are more limited still, and have far less range to represent
 the reals and integers than do arbitrary-precision types. Even so, for practical
 efficiency, we typically use machine words to represent elements of these sets.
 For many circumstances, this is not a problem.&lt;/p>

&lt;p>The machines we typically use implement reasonable error policies, at least
 for the integer types. For example, ARM’s and Intel’s policy is to make
 arithmetic modular, and to indicate carry, borrow, and overflow in a status
 register. (See e.g. &lt;a href="https://developer.arm.com/documentation/dui0801/g/Condition-Codes/Carry-flag">carry
 flag&lt;/a>, &lt;a href="https://developer.arm.com/documentation/dui0801/g/Condition-Codes/Overflow-flag">overflow
 flag&lt;/a>, and &lt;a
 href="https://developer.arm.com/documentation/dui0068/b/ARM-Instruction-Reference/Conditional-execution">conditional
 execution&lt;/a>.)&lt;/p>

&lt;p>Unfortunately, most of the programming languages that aim for machine-level
 efficiency — e.g. C, C++, and Rust — do not provide a standard way to access the
 machine status register directly, or otherwise indicate representation errors.
 (Rust does provide indirect access, however; see below.) Programmers must switch
 to machine language, or must use non-standard, implementation-specific features
 such as &lt;a href="https://clang.llvm.org/docs/LanguageExtensions.html">&lt;code>__builtin_add_overflow&lt;/code>&lt;/a>.&lt;/p>

&lt;p>It would be helpful if these languages’ developers defined standardized
 syntax and semantics for accessing the error state that the machine provides.
 (If the programmer uses such a mechanism, but compiles for a machine that
 doesn’t signal representation errors, the compiler could emulate such a signal,
 otherwise attempt to accommodate the programmer, or raise a compilation
 error.)&lt;/p>

&lt;p>However, some languages often violate and obscure the clear and simple policy
 that most machines define.&lt;/p>

&lt;style>
 table {
 border-collapse: collapse;
 }

 th,
 td {
 text-align: left;
 vertical-align: bottom;
 padding: 0.5em;
 }

 tr:nth-child(even) {
 background-color: #eee;
 }
&lt;/style>

&lt;table>

 &lt;tr>
 &lt;th>Language&lt;/th>
 &lt;th>Unrepresentable Signed Integer Behavior&lt;/th>
 &lt;th>Unrepresentable Unsigned Integer Behavior&lt;/th>
 &lt;/tr>

 &lt;tr>
 &lt;td>C, C++&lt;/td>
 &lt;td>Undefined behavior&lt;/td>
 &lt;td>Modular arithmetic&lt;/td>
 &lt;/tr>

 &lt;tr>
 &lt;td>Rust&lt;br />(default Release configuration)&lt;/td>
 &lt;td>Modular arithmetic&lt;/td>
 &lt;td>Modular arithmetic&lt;/td>
 &lt;/tr>

 &lt;tr>
 &lt;td>Rust&lt;br />(default Debug configuration)&lt;/td>
 &lt;td>Machine trap&lt;/td>
 &lt;td>Machine trap&lt;/td>
 &lt;/tr>

 &lt;tr>
 &lt;td>Java, Go&lt;/td>
 &lt;td>Modular arithmetic&lt;/td>
 &lt;td>Modular arithmetic&lt;/td>
 &lt;/tr>

&lt;/table>

&lt;p>There are a number of problems with this state of affairs:&lt;/p>

&lt;ul>

 &lt;li>
 &lt;p>&lt;b>Undefined behavior is hard or impossible to test for, and leads to increased
 cognitive load for the programmer.&lt;/b> The programmer has to divine the behavior
 that the compiler will choose to generate, including in different build
 configurations and at different optimization levels.&lt;/p>

 &lt;p>This can lead to situations where what programmers test (e.g. debug builds)
 is not the same as the code that runs in production, and the production behavior
 differs from what was tested.&lt;/p>

 &lt;p>Needless to say, when the ultimate behavior of the program is not predicted,
 intended, or tested by the programmer, bugs inevitably ensue — sometimes
 including exploitable vulnerabilities.&lt;/p>
 &lt;/li>

 &lt;li>
 &lt;p>&lt;b>Having different policies for signed and unsigned integer types
 exposes the quirks of obsolete and special-use machines, and increases cognitive
 load on the programmer.&lt;/b> In fact, many programmers are unaware of the policy
 difference. It is necessary and good to expose machine-specific behavior in
 machine languages, but it’s undesirable in higher-level languages.&lt;/p>
 &lt;/li>

 &lt;li>
 &lt;p>&lt;b>Trapping is a rather rigid policy&lt;/b>, and programmers may not expect
 it as the default, at least at first. It has the benefit of exposing the
 representation problem early in the development process, though. In a language
 that offers many policy choices, trapping might be the best default.&lt;/p>
 &lt;/li>

 &lt;li>
 &lt;p>&lt;b>Rust has the problem that the tested behavior is not the production
 behavior&lt;/b>, unless the programmer takes the somewhat unusual step of changing
 the default build configurations. This might be an unwelcome surprise after
 trapping behavior during testing.&lt;/p>

 &lt;p>I suppose the theory is that the trapping behavior will shake out all the
 bugs, but it can definitely be the case that program inputs seen during testing
 differ from those seen in production — especially in the case where the program
 must handle intentionally hostile input.&lt;/p>

 &lt;p>People often say that since Rust provides array bounds checking (in all
 builds), not trapping on integer overflow in production is OK. That is true as
 far as it goes, but invalid array access is not the only possible consequence of
 integer overflow.&lt;/p>
 &lt;/li>

 &lt;li>
 &lt;p>&lt;b>The set of policy options is incomplete, and insufficient for the full
 range of program requirements.&lt;/b> For all languages, it would be useful to have
 a suite of standardized policies available, including at least wrapping, trapping,
 clamping/saturation, undefined behavior, and promotion to &lt;code>BigInt&lt;/code> or
 other arbitrary precision type.&lt;/p>
 &lt;/li>

 &lt;li>
 &lt;p>&lt;b>Only Rust programmers have easy access to choice.&lt;/b> If the
 language’s policy is not right for the program requirements, the programmer must
 go to &lt;a href="https://source.chromium.org/chromium/chromium/src/+/main:base/numerics/">extraordinary
 lengths&lt;/a> to implement the right policy — typically without any help from
 standard mechanisms to observe the machine’s error state.&lt;/p>

 &lt;p>Rust is closest to where we need to be. If a program requires a different
 policy, Rust provides &lt;a href="https://doc.rust-lang.org/std/num/struct.Wrapping.html">a
 &lt;code>Wrapping&lt;/code> type&lt;/a> and operators like &lt;a
 href="https://doc.rust-lang.org/std/primitive.i32.html#method.wrapping_add">&lt;code>wrapping_add&lt;/code>&lt;/a>,
 &lt;a
 href="https://doc.rust-lang.org/std/primitive.i32.html#method.overflowing_add">&lt;code>overflowing_add&lt;/code>&lt;/a>,
 &lt;a href="https://doc.rust-lang.org/std/primitive.i32.html#method.saturating_add">&lt;code>saturating_add&lt;/code>&lt;/a>,
 &lt;a href="https://doc.rust-lang.org/std/primitive.i32.html#method.checked_add">&lt;code>checked_add&lt;/code>&lt;/a>,
 and &lt;a
 href="https://doc.rust-lang.org/std/primitive.i32.html#method.unchecked_add">&lt;code>unchecked_add&lt;/code>&lt;/a>.
 &lt;/p>
 &lt;/li>

&lt;/ul>

&lt;p>The usual reason given for the use of undefined behavior is that it can
 enable certain micro-optimizations. This is potentially useful and a legitimate
 policy option. (Language designers hesitate to pay the micro-cost of overflow
 checking &lt;a href="https://github.com/rust-lang/rfcs/pull/2635">even in special
 cases&lt;/a>. But to me it seems like &lt;code>unchecked_add&lt;/code> is available for
 the few people whose application is unacceptably affected by a check.)&lt;/p>

&lt;p>In any case, and in any language, “potentially (but untestably) fast, hard to
 predict, possibly wrong, and possibly unsafe”, even if occasionally desirable,
 should not be the default policy, as it is for signed arithmetic in C and
 C++.&lt;/p>

&lt;p>Fortunately, all of the languages in mainstream use have active standards
 committees and change processes. They could define ways to access the machine
 state, and could define standard types and operators implementing a wide range
 of reasonable representation error policies. (In addition to the suite of
 special policy operators that Rust provides, it’d help to have types whose
 default operators implement each of those policies, as well — not just
 &lt;code>Wrapping&lt;/code>.)
&lt;/p>

&lt;p>In some cases, it may even be possible to change the default policies. I
 think language designers and standardizers should do so.
&lt;/p>

&lt;p>(Perhaps something similar could be done for the error modes of
 floating-point arithmetic, too.)&lt;/p>

&lt;aside>
 &lt;p>Thanks to Saleem Rashid for pointing out some gaps, and to Alex Gaynor
 for pointing out an inaccuracy!&lt;/p>
&lt;/aside></description><author>Chris Palmer</author><guid>2021/09/26/improving-software-numbers/index.html</guid><pubDate>Sun, 26 Sep 2021 00:00:00 +0000</pubDate></item><item><title>A Thought On ‘End-to-End’ Security</title><link>https://noncombatant.org/2021/09/01/end-to-end/index.content</link><description>&lt;h1>A Thought On ‘End-to-End’ Security&lt;/h1>

&lt;p>&lt;time>1 September 2021&lt;/time>&lt;/p>

&lt;p>There’s a good deal of hullabaloo about Apple’s CSAM detection system(s) for
 the iPhone, iMessage, and iCloud. There are a lot of complex trade-offs in play,
 and I am not qualified to say if it’s net-good or net-bad.&lt;/p>

&lt;p>Everyone is getting their yell in, pro- or con-, and that is good. To me, the
 clearest discussion of why Apple’s plan is so hard to love comes from Deirdre
 Connolly and Matthew Green on the &lt;a
 href="https://securitycryptographywhatever.buzzsprout.com/1822302/9099774-apple-s-csam-detection-feat-matthew-green">Security.
 Cryptography. Whatever. podcast&lt;/a>.&lt;/p>

&lt;p>In &lt;a href="https://www.lawfareblog.com/normalizing-surveillance">“Normalizing
 Surveillance”&lt;/a> (in Lawfare, of all places) Susan Landau raises a key
 question: What does ‘end-to-end’ security actually mean? Is Apple violating the
 spirit of the principle? (Has there ever been a clear letter of the
 principle?)&lt;/p>

&lt;blockquote>Apple’s solution for its messaging app works through a redefinition
 of end-to-end encryption (E2E) with a new meaning that a communication is
 end-to-end encrypted until it reaches the recipient’s phone. Previously an
 iPhone (or iPad) user could use the Messages app to send a message to another
 iPhone or iPad user and it would be E2E encrypted via iMessage, Apple’s E2E
 encrypted messaging app. But Apple’s new definition of E2E encrypted means that
 Apple tools could have access to any decrypted contents.&lt;/blockquote>

&lt;p>The original ‘letter’ of the principle comes from &lt;a
 href="https://web.mit.edu/Saltzer/www/publications/endtoend/endtoend.pdf">Saltzer,
 Reed, and Clark’s paper “End-To-End Arguments In System Design”&lt;/a> (&lt;a href="saltzer-end-to-end.pdf">local
 copy&lt;/a>). They argue that reliability must
 come primarily from the application layer, and they use a file transfer
 application protocol as their example. They don’t find it sufficient to rely on
 the lower-layer protocols, or their providers, to provide application-semantic
 reliability (in this case, file integrity). They note the possibility that lower
 layers might help, or improve efficiency, but lower layers and providers cannot
 be solely relied upon to provide such reliability.&lt;/p>

&lt;p>Saltzer et al. mention encryption only in passing, and don’t really dig into
 the idea of the lower layer providers as intentional threat actors. The
 end-to-end argument does readily lend itself to that approach to security, but
 the original paper does not give us a clear definition of E2E security. It’s
 about reliability in a world of accidents, mishaps, and misunderstandings.&lt;/p>

&lt;p>The spirit of the E2E argument as a security model, though, is surely clear:
 the application layer must not trust other software, protocols, or
 communications providers; instead, it must treat them as not only unreliable but
 as potential threat actors.&lt;/p>

&lt;p>But does it make sense to treat the author(s) of the trusted computing base
 (TCB) — your hardware, firmware, operating system, and core application
 frameworks — as untrusted? As threat actors?&lt;/p>

&lt;p>Landau considers it a “redefinition” of the principle of E2E security to
 trust the TCB. Essentially, she wishes — we all would wish! — for the “ends” to
 be the application software instances alone, defending themselves against an
 &lt;b>un&lt;/b>trusted and potentially hostile computing base:
&lt;/p>

&lt;figure>&lt;img src="we-wish.svg" alt="A graphic showing Alice, Bob, Alice’s
device, and Bob’s device, with messaging apps talking to each other and treating
the device OSs as potentially hostile." title="We wish the device OS were
untrusted, because it might be hostile." loading="lazy" width="500" height="289" />
 &lt;figcaption>We wish the device OS were untrusted, because it might be
 hostile.&lt;/figcaption>
&lt;/figure>

&lt;p>Unfortunately, the reality has always been, and must necessarily be, more
 like this:&lt;/p>

&lt;figure>&lt;img src="reality.svg" alt="A graphic showing Alice, Bob, Alice’s
device, and Bob’s device, with messaging apps talking to each other and treating
the device OSs as potenitally hostile but necessarily trusted." title="In fact,
the device OS is trusted, even though it might be hostile. Bummer, but that’s
life." loading="lazy" width="500" height="289" />
 &lt;figcaption>In fact, the device OS
 is trusted, even though it might be hostile. Bummer, but that’s
 life.&lt;/figcaption>
&lt;/figure>

&lt;p>Every TCB, from every vendor, has at least the power — hopefully unused, or
 at least ‘benignly’ — to inspect, modify, tootle with, and otherwise perturb any
 application it hosts. None of Apple, iOS, iMessage are unique in this way. You
 have to trust Ubuntu not to frobulate your Signal Desktop. You have to trust
 Android not to discrombulize your WhatsApp.&lt;/p>

&lt;p>Whether the trust&lt;b>ed&lt;/b> computing base is trust&lt;b>worthy&lt;/b> is an
 entirely separate question.&lt;/p>

&lt;p>Another separate question: Does it make sense to treat the application itself
 as a threat actor, other than by simply rejecting it? Part of Apple’s system(s)
 for CSAM involves, presumably, integration between iOS, iMessage, and iCloud
 — presumably, the system(s) are implemented partially inside iMessage and
 partially with API hooks between the OS, app, and iCloud. Apple is the author of
 all that software, and runs the services.&lt;/p>

&lt;p>In theory, at least, any TCB could reach into any application it hosts to do
 the same thing. I’m not saying I think Apple or any other OS vendor will go so
 far as to do their CSAM scanning in apps they didn’t author.&lt;/p>

&lt;p>(That said, substantial content inspection, code injection into applications
 and into the kernel, and reporting to the mothership has long been common in the
 anti-virus (AV) industry. If you install such software, be aware that you are
 usually placing total trust in it. If you don’t like Apple’s private set
 intersection stuff, you’re really not going to like what you find out about
 AV.)&lt;/p>

&lt;p>So, I don’t think it’s a redefinition of the letter (such as it is) or spirit
 of the E2E principle to treat the TCB as trusted. (It’s right there in the
 name.) A given TCB, or app, might be untrustworthy for your needs, and that can
 be a problem. But it’s not a problem Apple introduced.&lt;/p></description><author>Chris Palmer</author><guid>2021/09/01/end-to-end/index.html</guid><pubDate>Wed, 01 Sep 2021 00:00:00 +0000</pubDate></item><item><title>Fun Lil Hacks</title><link>https://noncombatant.org/2021/08/30/fun-lil-hacks/index.content</link><description>&lt;h1>Fun Lil Hacks&lt;/h1>

&lt;p>&lt;time>30 August 2021&lt;/time>&lt;/p>

&lt;p>Here are some fun hacks I’ve been working on lately.&lt;/p>

&lt;h2>Run Python&lt;/h2>

&lt;p>&lt;a href="https://github.com/noncombatant/run-python">Published on
 GitHub&lt;/a>.&lt;/p>

&lt;p>This little snippet of Python and a macOS Automator workflow allow me to run
 Python code in almost any text input widget of almost any application on my Mac.
 (Gmail’s message compose window is not a regular text input, sadly. Everything
 else works, though, including vim in Terminal.&lt;/p>

&lt;p>I’ve bound it to the global hotkey ⌘-\. I just select any text, hit that
 hotkey, and the selection is replaced with the result of evaluating the text as
 Python 3 code. I have it run a Python imterpreter that has a lot of extra
 modules imported so that I have easy access to common functionality.&lt;/p>

&lt;p>You take this:&lt;/p>

&lt;figure>&lt;img src="run-python-01.png" width="556" height="155" alt="A screen shot
of the text “Hey Bob, what’s up. When the nurse said my body temperature was
u.Quantity(98.6, u.degF).to(degC), I just about frrrreaked out. But it turns
out that’s normal.” in a message compose window in Slack." loading="lazy" />
 &lt;figcaption>Python code in any text area.&lt;/figcaption>
&lt;/figure>

&lt;p>Select the Python expression, hit ⌘-\, and get this:&lt;/p>

&lt;figure>&lt;img src="run-python-02.png" width="557" height="159" alt="A screen shot
of the text “Hey Bob, what’s up. When the nurse said my body temperature was
&lt;Quantity(37.0, degree_Celsius)>, I just about frrrreaked out. But it turns
out that’s normal.”" loading="lazy" />
 &lt;figcaption>Evaluating
 Python.&lt;/figcaption>
&lt;/figure>

&lt;h2>HTTP Nowhere&lt;/h2>

&lt;p>&lt;a
 href="https://chrome.google.com/webstore/detail/http-nowhere/bjaonomdmphjeieijhhjpcdekcdahlpl/related?hl=en&amp;authuser=0">Published
 in the Chrome Web Store&lt;/a> and &lt;a href="https://github.com/noncombatant/http-nowhere">on GitHub&lt;/a>.&lt;/p>

&lt;p>This browser extension upgrades all HTTP and WS requests to HTTPS and WSS,
 respectively. It then blocks HTTP and WS. Ideally, with this extension, no
 plaintext web requests will ever hit the wire. You can (and should) verify this
 with &lt;a href="https://www.wireshark.org/download.html">Wireshark&lt;/a>.&lt;/p>

&lt;p>HTTP Nowhere cannot turn on DNS-over-HTTPS for you, however, because there is
 currently no extension API to do that. You’ll have to enable secure DNS
 manually, in Settings (chrome://settings/security) Definitely turn this on!&lt;/p>

&lt;p>This extension might soon be obviated or partially obviated by the coming
 HTTPS First mode. (HTTPS First is currently available in Chrome Canary behind a
 flag: chrome://flags/#https-only-mode-setting.)&lt;/p>

&lt;h2>Uncover UI&lt;/h2>

&lt;p>&lt;a href="https://chrome.google.com/webstore/detail/uncover-ui/gjjmcgdmihdajcgogajilcpollahpkgf?hl=en&amp;authuser=0">Published
 in the Chrome Web Store&lt;/a> and &lt;a href="https://github.com/noncombatant/uncover-ui">on GitHub&lt;/a>.&lt;/p>

&lt;p>This browser extension removes unnecessary UI elements that cover up
 necessary UI elements. For some reason I do not understand, UI designers seem to
 really like covering up their own UI with other UI.&lt;/p>

&lt;p>Uncover UI currently only works in Gmail and Google Docs. I am thinking about
 extending it to remove all those pop-up screens that news and shopping sites
 like to use to stop you from reading their content and buying their
 products.&lt;/p></description><author>Chris Palmer</author><guid>2021/08/30/fun-lil-hacks/index.html</guid><pubDate>Mon, 30 Aug 2021 00:00:00 +0000</pubDate></item><item><title>Long Live Sandboxing!</title><link>https://noncombatant.org/2021/04/11/long-live-sandboxing/index.content</link><description>&lt;h1>Long Live Sandboxing!&lt;/h1>

&lt;p>&lt;time>11 April 2021&lt;/time>&lt;/p>

&lt;p>Apparently, there is some confusion about whether sandboxing is necessary,
 sufficient, and/or affordable. (&lt;a
 href="https://www.securityweek.com/cost-sandboxing-prompts-shift-memory-safe-languages-little-too-late">Here
 is an example from Security Week&lt;/a>, although this is not the only
 instance.)&lt;/p>

&lt;p>As the lead of Chrome’s sandboxing team and as co-lead of Chrome’s memory
 safety efforts, perhaps I can clarify a little.&lt;/p>

&lt;p>As I said in &lt;a href="https://www.usenix.org/conference/enigma2021/presentation/palmer">my
 Enigma presentation&lt;/a> (&lt;a
 href="https://www.usenix.org/sites/default/files/conference/protected-files/enigma2021_slides_palmer.pdf">slide
 7&lt;/a>), “good sandboxing is table stakes.” I reiterated this point in &lt;a
 href="/2021/04/09/prioritizing-memory-safety-migrations/">my previous post&lt;/a>
 (“if [...] your application is not making use of process sandboxing, consider
 exploring that first before starting a rewrite effort”).&lt;/p>

&lt;p>Contrary to what the Security Week article and some Twitter discourse
 suggest, &lt;b>sandboxing and memory safety are complementary techniques&lt;/b>, and
 both are necessary.&lt;/p>

&lt;dl>

 &lt;dt>&lt;b>Sandboxing reduces the severity of bugs.&lt;/b>&lt;/dt>

 &lt;dd>

 &lt;p>Sandboxing isolates code away from system resources and application
 resources, reducing the damage that compromise can do. (Sandboxing also has
 certain efficiency advantages, as well as disadvantages, too.)&lt;/p>

 &lt;p>However, a certain amount of attack surface will always be available from
 within a sandbox, and memory unsafety (and other bugs) can enable an attacker to
 get at it.&lt;/p>

 &lt;p>So you still need to get rid of as many bugs inside the sandbox as
 possible.&lt;/p>

 &lt;/dd>

 &lt;dt>&lt;b>Memory safety reduces the number of bugs.&lt;/b>&lt;/dt>

 &lt;dd>

 &lt;p>As discussed at Enigma and in my previous post, very many bugs, including an
 overwhelming majority of the vulnerabilities we know about right now, are due to
 memory unsafety. It helps to get rid of as many of those as possible.&lt;/p>

 &lt;p>However, memory safety can’t constrain access to system resources, including
 the file system, system calls, et c.&lt;/p>

 &lt;p>So you still need sandboxing.&lt;/p>

 &lt;/dd>

&lt;/dl>

&lt;p>There are 2 key ways that Chromium (specifically) is nearing the limits of
 how much sandboxing we can do right now:&lt;/p>

&lt;ul>

 &lt;li>Our unit of isolation, the process, is expensive in time and space on some
 (not all) platforms.&lt;/li>

 &lt;li>Some operating systems do not provide sufficiently fine-grained mechanisms
 to allow us to maximally constrain sandboxed processes. Things are improving,
 but it’s an unavoidably slow process.&lt;/li>

&lt;/ul>

&lt;p>I tried also to raise awareness that not all the applications that need
 sandboxing are making use of it. I know of at least 1 organization that was
 compromised because their server application did not sandbox a file format
 parser (written in C), and allowed anyone on the internet to send input to it.
 So, more developers need to do more sandboxing — &lt;b>as an industry, we are nowhere
 near the limits yet&lt;/b>.&lt;/p>

&lt;p>We are still pursuing additional sandboxing in Chromium. It’s just that we
 can see a limit to what’s possible &lt;b>at the moment&lt;/b>. If OS developers give
 us more of the primitives we want, we’ll jump right on them — as we always
 have.&lt;/p>

&lt;p>Finally, nobody knowledgeable, that I know of, has claimed or would claim
 that eliminating 100% of memory unsafety bugs would also get rid of all
 vulnerabilities. The claim — &lt;a
 href="https://alexgaynor.net/2020/may/27/science-on-memory-unsafety-and-security/">based
 on repeated real-world experience and evidence&lt;/a> — is that memory unsafety
 accounts for a large majority of vulnerabilities. There will still be bugs. Our
 goal is to marginalize memory unsafety bugs, because they are currently our
 worst observed problem.&lt;/p></description><author>Chris Palmer</author><guid>2021/04/11/long-live-sandboxing/index.html</guid><pubDate>Sun, 11 Apr 2021 00:00:00 +0000</pubDate></item><item><title>Prioritizing Memory Safety Migrations</title><link>https://noncombatant.org/2021/04/09/prioritizing-memory-safety-migrations/index.content</link><description>&lt;style>
 img {
 border: 0px;
 }
&lt;/style>

&lt;h1>Prioritizing Memory Safety Migrations&lt;/h1>

&lt;p>&lt;time>9 April 2021&lt;/time>&lt;/p>

&lt;aside>
 &lt;p>Update 11 April: Please also see &lt;a href="/2021/04/11/long-live-sandboxing/">Long Live Sandboxing!&lt;/a>. Sandboxing
 is not dead, despite what you might have heard.&lt;/p>
&lt;/aside>

&lt;p>With all the talk of using Rust to reduce memory unsafety bugs, &lt;a
 href="https://security.googleblog.com/2021/04/rust-in-android-platform.html">such
 as Android using Rust in the Android Open Source Project&lt;/a>, there’s a lot of
 extremely reasonable concern about the high cost of “rewriting it all in Rust”
 (or any other safer language), as it’s often phrased. Operating systems, web
 browsers, complex online services, and so on can be implemented with tens of
 millions of lines of C/C++ code. (&lt;a
 href="https://www.technologyreview.com/2012/12/03/181350/many-cars-have-a-hundred-million-lines-of-code/">Sometimes
 more&lt;/a>.) Rewriting all that seems prohibitively expensive, and exacerbates &lt;a
 href="https://www.usenix.org/conference/enigma2021/presentation/gaynor">what
 Alex Gaynor aptly calls grief&lt;/a> — people stay in the denial stage longer when
 struck by the enormity of the memory unsafety problem.&lt;/p>

&lt;p>Thankfully, &lt;a href="https://wiki.mozilla.org/Oxidation">replacing C/C++ with
 code in a safer language&lt;/a> is not an all-or-nothing task. We can do it
 gradually; some parts we might never need to replace. Most safer languages can
 link in the same address space as C and/or C++, and call into and be called by
 C/C++. You can also normalize data structures such that the safe code handles
 arbitrary inputs, and the C/C++ code can focus on a single, simpler grammar. For
 example:&lt;/p>

&lt;figure>
&lt;svg width="242pt" height="260pt" role="img" aria-label="a directed graph
showing internet → { PNG, JPEG, GIF, TIFF, ... } → SkBitmap"
 viewBox="0.00 0.00 242.00 260.00" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
&lt;g id="graph0" class="graph" transform="scale(1 1) rotate(0) translate(4 256)">
&lt;!-- internet -->
&lt;g id="node1" class="node">
&lt;title>internet&lt;/title>
&lt;path fill="none" stroke="var(--fg)" d="M42,-144C42,-144 12,-144 12,-144 6,-144 0,-138 0,-132 0,-132 0,-120 0,-120 0,-114 6,-108 12,-108 12,-108 42,-108 42,-108 48,-108 54,-114 54,-120 54,-120 54,-132 54,-132 54,-138 48,-144 42,-144"/>
&lt;text text-anchor="middle" x="27" y="-123.8" font-family="Roboto" font-size="9.00">internet&lt;/text>
&lt;/g>
&lt;!-- PNG -->
&lt;g id="node2" class="node">
&lt;title>PNG&lt;/title>
&lt;path fill="none" stroke="var(--fg)" d="M132,-252C132,-252 102,-252 102,-252 96,-252 90,-246 90,-240 90,-240 90,-228 90,-228 90,-222 96,-216 102,-216 102,-216 132,-216 132,-216 138,-216 144,-222 144,-228 144,-228 144,-240 144,-240 144,-246 138,-252 132,-252"/>
&lt;text text-anchor="middle" x="117" y="-231.8" font-family="Roboto" font-size="9.00">PNG&lt;/text>
&lt;/g>
&lt;!-- internet&amp;#45;&amp;gt;PNG -->
&lt;g id="edge1" class="edge">
&lt;title>internet&amp;#45;&amp;gt;PNG&lt;/title>
&lt;path fill="none" stroke="var(--fg)" d="M42.07,-144.38C60.36,-168.28 90,-207 90,-207 90,-207 90.54,-207.56 91.45,-208.51"/>
&lt;polygon fill="var(--fg)" stroke="var(--fg)" points="89.06,-211.07 98.51,-215.84 94.1,-206.21 89.06,-211.07"/>
&lt;/g>
&lt;!-- JPEG -->
&lt;g id="node3" class="node">
&lt;title>JPEG&lt;/title>
&lt;path fill="none" stroke="var(--fg)" d="M132,-198C132,-198 102,-198 102,-198 96,-198 90,-192 90,-186 90,-186 90,-174 90,-174 90,-168 96,-162 102,-162 102,-162 132,-162 132,-162 138,-162 144,-168 144,-174 144,-174 144,-186 144,-186 144,-192 138,-198 132,-198"/>
&lt;text text-anchor="middle" x="117" y="-177.8" font-family="Roboto" font-size="9.00">JPEG&lt;/text>
&lt;/g>
&lt;!-- internet&amp;#45;&amp;gt;JPEG -->
&lt;g id="edge2" class="edge">
&lt;title>internet&amp;#45;&amp;gt;JPEG&lt;/title>
&lt;path fill="none" stroke="var(--fg)" d="M54.4,-142.2C62.83,-147.37 72.29,-153.18 81.22,-158.66"/>
&lt;polygon fill="var(--fg)" stroke="var(--fg)" points="79.57,-161.75 89.92,-164 83.23,-155.78 79.57,-161.75"/>
&lt;/g>
&lt;!-- GIF -->
&lt;g id="node4" class="node">
&lt;title>GIF&lt;/title>
&lt;path fill="none" stroke="var(--fg)" d="M132,-144C132,-144 102,-144 102,-144 96,-144 90,-138 90,-132 90,-132 90,-120 90,-120 90,-114 96,-108 102,-108 102,-108 132,-108 132,-108 138,-108 144,-114 144,-120 144,-120 144,-132 144,-132 144,-138 138,-144 132,-144"/>
&lt;text text-anchor="middle" x="117" y="-123.8" font-family="Roboto" font-size="9.00">GIF&lt;/text>
&lt;/g>
&lt;!-- internet&amp;#45;&amp;gt;GIF -->
&lt;g id="edge3" class="edge">
&lt;title>internet&amp;#45;&amp;gt;GIF&lt;/title>
&lt;path fill="none" stroke="var(--fg)" d="M54.4,-126C62.39,-126 71.31,-126 79.82,-126"/>
&lt;polygon fill="var(--fg)" stroke="var(--fg)" points="79.92,-129.5 89.92,-126 79.92,-122.5 79.92,-129.5"/>
&lt;/g>
&lt;!-- TIFF -->
&lt;g id="node5" class="node">
&lt;title>TIFF&lt;/title>
&lt;path fill="none" stroke="var(--fg)" d="M132,-90C132,-90 102,-90 102,-90 96,-90 90,-84 90,-78 90,-78 90,-66 90,-66 90,-60 96,-54 102,-54 102,-54 132,-54 132,-54 138,-54 144,-60 144,-66 144,-66 144,-78 144,-78 144,-84 138,-90 132,-90"/>
&lt;text text-anchor="middle" x="117" y="-69.8" font-family="Roboto" font-size="9.00">TIFF&lt;/text>
&lt;/g>
&lt;!-- internet&amp;#45;&amp;gt;TIFF -->
&lt;g id="edge4" class="edge">
&lt;title>internet&amp;#45;&amp;gt;TIFF&lt;/title>
&lt;path fill="none" stroke="var(--fg)" d="M54.4,-109.8C62.83,-104.63 72.29,-98.82 81.22,-93.34"/>
&lt;polygon fill="var(--fg)" stroke="var(--fg)" points="83.23,-96.22 89.92,-88 79.57,-90.25 83.23,-96.22"/>
&lt;/g>
&lt;!-- ... -->
&lt;g id="node6" class="node">
&lt;title>...&lt;/title>
&lt;path fill="none" stroke="var(--fg)" d="M132,-36C132,-36 102,-36 102,-36 96,-36 90,-30 90,-24 90,-24 90,-12 90,-12 90,-6 96,0 102,0 102,0 132,0 132,0 138,0 144,-6 144,-12 144,-12 144,-24 144,-24 144,-30 138,-36 132,-36"/>
&lt;text text-anchor="middle" x="117" y="-15.8" font-family="Roboto" font-size="9.00">...&lt;/text>
&lt;/g>
&lt;!-- internet&amp;#45;&amp;gt;... -->
&lt;g id="edge5" class="edge">
&lt;title>internet&amp;#45;&amp;gt;...&lt;/title>
&lt;path fill="none" stroke="var(--fg)" d="M42.07,-107.62C60.36,-83.72 90,-45 90,-45 90,-45 90.54,-44.44 91.45,-43.49"/>
&lt;polygon fill="var(--fg)" stroke="var(--fg)" points="94.1,-45.79 98.51,-36.16 89.06,-40.93 94.1,-45.79"/>
&lt;/g>
&lt;!-- SkBitmap -->
&lt;g id="node7" class="node">
&lt;title>SkBitmap&lt;/title>
&lt;path fill="none" stroke="var(--fg)" d="M222,-144C222,-144 192,-144 192,-144 186,-144 180,-138 180,-132 180,-132 180,-120 180,-120 180,-114 186,-108 192,-108 192,-108 222,-108 222,-108 228,-108 234,-114 234,-120 234,-120 234,-132 234,-132 234,-138 228,-144 222,-144"/>
&lt;text text-anchor="middle" x="207" y="-123.8" font-family="Roboto" font-size="9.00">SkBitmap&lt;/text>
&lt;/g>
&lt;!-- PNG&amp;#45;&amp;gt;SkBitmap -->
&lt;g id="edge6" class="edge">
&lt;title>PNG&amp;#45;&amp;gt;SkBitmap&lt;/title>
&lt;path fill="none" stroke="var(--fg)" d="M135.49,-215.84C140.19,-210.96 144,-207 144,-207 144,-207 167.72,-176.02 185.81,-152.37"/>
&lt;polygon fill="var(--fg)" stroke="var(--fg)" points="188.63,-154.45 191.93,-144.38 183.07,-150.19 188.63,-154.45"/>
&lt;/g>
&lt;!-- JPEG&amp;#45;&amp;gt;SkBitmap -->
&lt;g id="edge7" class="edge">
&lt;title>JPEG&amp;#45;&amp;gt;SkBitmap&lt;/title>
&lt;path fill="none" stroke="var(--fg)" d="M144.4,-163.8C152.83,-158.63 162.29,-152.82 171.22,-147.34"/>
&lt;polygon fill="var(--fg)" stroke="var(--fg)" points="173.23,-150.22 179.92,-142 169.57,-144.25 173.23,-150.22"/>
&lt;/g>
&lt;!-- GIF&amp;#45;&amp;gt;SkBitmap -->
&lt;g id="edge8" class="edge">
&lt;title>GIF&amp;#45;&amp;gt;SkBitmap&lt;/title>
&lt;path fill="none" stroke="var(--fg)" d="M144.4,-126C152.39,-126 161.31,-126 169.82,-126"/>
&lt;polygon fill="var(--fg)" stroke="var(--fg)" points="169.92,-129.5 179.92,-126 169.92,-122.5 169.92,-129.5"/>
&lt;/g>
&lt;!-- TIFF&amp;#45;&amp;gt;SkBitmap -->
&lt;g id="edge9" class="edge">
&lt;title>TIFF&amp;#45;&amp;gt;SkBitmap&lt;/title>
&lt;path fill="none" stroke="var(--fg)" d="M144.4,-88.2C152.83,-93.37 162.29,-99.18 171.22,-104.66"/>
&lt;polygon fill="var(--fg)" stroke="var(--fg)" points="169.57,-107.75 179.92,-110 173.23,-101.78 169.57,-107.75"/>
&lt;/g>
&lt;!-- ...&amp;#45;&amp;gt;SkBitmap -->
&lt;g id="edge10" class="edge">
&lt;title>...&amp;#45;&amp;gt;SkBitmap&lt;/title>
&lt;path fill="none" stroke="var(--fg)" d="M135.49,-36.16C140.19,-41.04 144,-45 144,-45 144,-45 167.72,-75.98 185.81,-99.63"/>
&lt;polygon fill="var(--fg)" stroke="var(--fg)" points="183.07,-101.81 191.93,-107.62 188.63,-97.55 183.07,-101.81"/>
&lt;/g>
&lt;/g>
&lt;/svg>
 &lt;figcaption>You can accept
 arbitrary image (e.g.) formats from the internet, use a safer language to
 normalize them into Skia’s simple &lt;code>SkBitmap&lt;/code> format, and then handle
 the bitmaps in Skia in C++. This simplifies the C++ code (reducing its attack
 surface), and provides a simple cross-language interface.&lt;/figcaption>
&lt;/figure>

&lt;p>But how do you tell where to start replacing C/C++ with safer code, and where
 to stop?&lt;/p>

&lt;p>Although security is certainly not the only benefit of a safe language — the
 Android team’s post starts out stressing correctness — my perspective is
 security. And from that starting point, we can use what I think is a pretty
 clear method to prioritize our efforts.&lt;/p>

&lt;p>Even if you have, say, 20 million lines of C++ code, not all of it is
 directly or indirectly exposed to attackers. You can start hardening the most
 exposed code first, and you can rank exposure by how long the path to the code
 is. Consider &lt;a href="https://googleprojectzero.blogspot.com/2020/12/an-ios-zero-click-radio-proximity.html">Ian
 Beer’s epic radio pyrotechnics&lt;/a>, in which he compromised iPhones by sending
 them mean-spirited packets by radio. We can model the attack surface exposure
 something like this:&lt;/p>

&lt;figure>
&lt;svg width="259pt" height="44pt" role="img" aria-label="a directed graph showing attacker → radio chip → kernel"
 viewBox="0.00 0.00 259.00 44.00" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
&lt;g id="graph0" class="graph" transform="scale(1 1) rotate(0) translate(4 40)">
&lt;!-- attacker -->
&lt;g id="node1" class="node">
&lt;title>attacker&lt;/title>
&lt;path fill="none" stroke="var(--fg)" d="M42,-36C42,-36 12,-36 12,-36 6,-36 0,-30 0,-24 0,-24 0,-12 0,-12 0,-6 6,0 12,0 12,0 42,0 42,0 48,0 54,-6 54,-12 54,-12 54,-24 54,-24 54,-30 48,-36 42,-36"/>
&lt;text text-anchor="middle" x="27" y="-15.8" font-family="Roboto" font-size="9.00">attacker&lt;/text>
&lt;/g>
&lt;!-- radio -->
&lt;g id="node2" class="node">
&lt;title>radio&lt;/title>
&lt;path fill="none" stroke="var(--fg)" d="M134,-36C134,-36 102,-36 102,-36 96,-36 90,-30 90,-24 90,-24 90,-12 90,-12 90,-6 96,0 102,0 102,0 134,0 134,0 140,0 146,-6 146,-12 146,-12 146,-24 146,-24 146,-30 140,-36 134,-36"/>
&lt;text text-anchor="middle" x="118" y="-15.8" font-family="Roboto" font-size="9.00">radio chip&lt;/text>
&lt;/g>
&lt;!-- attacker&amp;#45;&amp;gt;radio -->
&lt;g id="edge1" class="edge">
&lt;title>attacker&amp;#45;&amp;gt;radio&lt;/title>
&lt;path fill="none" stroke="var(--fg)" d="M54.22,-18C62.17,-18 71.06,-18 79.59,-18"/>
&lt;polygon fill="var(--fg)" stroke="var(--fg)" points="79.73,-21.5 89.73,-18 79.73,-14.5 79.73,-21.5"/>
&lt;/g>
&lt;!-- kernel -->
&lt;g id="node3" class="node">
&lt;title>kernel&lt;/title>
&lt;path fill="none" stroke="var(--fg)" d="M239,-36C239,-36 194,-36 194,-36 188,-36 182,-30 182,-24 182,-24 182,-12 182,-12 182,-6 188,0 194,0 194,0 239,0 239,0 245,0 251,-6 251,-12 251,-12 251,-24 251,-24 251,-30 245,-36 239,-36"/>
&lt;text text-anchor="middle" x="216.5" y="-15.8" font-family="Roboto" font-size="9.00">device driver&lt;/text>
&lt;/g>
&lt;!-- radio&amp;#45;&amp;gt;kernel -->
&lt;g id="edge2" class="edge">
&lt;title>radio&amp;#45;&amp;gt;kernel&lt;/title>
&lt;path fill="none" stroke="var(--fg)" d="M146.14,-18C154.07,-18 162.95,-18 171.64,-18"/>
&lt;polygon fill="var(--fg)" stroke="var(--fg)" points="171.69,-21.5 181.69,-18 171.69,-14.5 171.69,-21.5"/>
&lt;/g>
&lt;/g>
&lt;/svg>
 &lt;figcaption>An attack pathway from the internet
 to the kernel.&lt;/figcaption>
&lt;/figure>

&lt;p>That’s a bit of an oversimplification, but it lets us see that the attacker’s
 call graph is not very deep — that is, that driver is pretty exposed.&lt;/p>

&lt;p>Additionally, as the title of Ian’s post points out, the attacker’s cost to
 traverse the first few edges is 0. We can model that by assigning ‘weight’ or
 ‘cost’ to the edges in the graph. The higher the cost, the less likely it is
 that the attacker will succeed. Assuming the radio is fairly simple and does
 little normalization or filtering before passing what it got to the kernel, we
 might draw something like this:&lt;/p>

&lt;figure>
&lt;svg width="300pt" height="46pt" role="img" aria-label="a directed graph showing
attacker → (0) radio chip → (low or medium) kernel"
 viewBox="0.00 0.00 300.00 46.00" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
&lt;g id="graph0" class="graph" transform="scale(1 1) rotate(0) translate(4 42)">
&lt;!-- attacker -->
&lt;g id="node1" class="node">
&lt;title>attacker&lt;/title>
&lt;path fill="none" stroke="var(--fg)" d="M42,-36C42,-36 12,-36 12,-36 6,-36 0,-30 0,-24 0,-24 0,-12 0,-12 0,-6 6,0 12,0 12,0 42,0 42,0 48,0 54,-6 54,-12 54,-12 54,-24 54,-24 54,-30 48,-36 42,-36"/>
&lt;text text-anchor="middle" x="27" y="-15.8" font-family="Roboto" font-size="9.00">attacker&lt;/text>
&lt;/g>
&lt;!-- radio -->
&lt;g id="node2" class="node">
&lt;title>radio&lt;/title>
&lt;path fill="none" stroke="var(--fg)" d="M140,-36C140,-36 108,-36 108,-36 102,-36 96,-30 96,-24 96,-24 96,-12 96,-12 96,-6 102,0 108,0 108,0 140,0 140,0 146,0 152,-6 152,-12 152,-12 152,-24 152,-24 152,-30 146,-36 140,-36"/>
&lt;text text-anchor="middle" x="124" y="-15.8" font-family="Roboto" font-size="9.00">radio chip&lt;/text>
&lt;/g>
&lt;!-- attacker&amp;#45;&amp;gt;radio -->
&lt;g id="edge1" class="edge">
&lt;title>attacker&amp;#45;&amp;gt;radio&lt;/title>
&lt;path fill="none" stroke="var(--fg)" d="M54.21,-18C63.93,-18 75.15,-18 85.67,-18"/>
&lt;polygon fill="var(--fg)" stroke="var(--fg)" points="85.88,-21.5 95.88,-18 85.88,-14.5 85.88,-21.5"/>
&lt;text text-anchor="middle" x="75" y="-20.8" font-family="Roboto" font-size="9.00">0&lt;/text>
&lt;/g>
&lt;!-- kernel -->
&lt;g id="node3" class="node">
&lt;title>kernel&lt;/title>
&lt;path fill="none" stroke="var(--fg)" d="M280,-36C280,-36 235,-36 235,-36 229,-36 223,-30 223,-24 223,-24 223,-12 223,-12 223,-6 229,0 235,0 235,0 280,0 280,0 286,0 292,-6 292,-12 292,-12 292,-24 292,-24 292,-30 286,-36 280,-36"/>
&lt;text text-anchor="middle" x="257.5" y="-15.8" font-family="Roboto" font-size="9.00">device driver&lt;/text>
&lt;/g>
&lt;!-- radio&amp;#45;&amp;gt;kernel -->
&lt;g id="edge2" class="edge">
&lt;title>radio&amp;#45;&amp;gt;kernel&lt;/title>
&lt;path fill="none" stroke="var(--fg)" d="M152.25,-18C169.67,-18 192.67,-18 212.63,-18"/>
&lt;polygon fill="var(--fg)" stroke="var(--fg)" points="212.74,-21.5 222.74,-18 212.74,-14.5 212.74,-21.5"/>
&lt;text text-anchor="middle" x="187.5" y="-30.8" font-family="Roboto" font-size="9.00">low or&lt;/text>
&lt;text text-anchor="middle" x="187.5" y="-20.8" font-family="Roboto" font-size="9.00">medium&lt;/text>
&lt;/g>
&lt;/g>
&lt;/svg>
 &lt;figcaption>An attack
 pathway from the internet to the kernel, with estimated costs for each edge
 traversal.&lt;/figcaption>
&lt;/figure>

&lt;p>On a scale from 0 &amp;lt; low &amp;lt; medium &amp;lt; high, we might generously
 estimate the cost to exploit the vulnerable driver to be maybe medium. If the
 defender is lucky, maybe ASLR is working, or something.&lt;/p>

&lt;p>Ian explains everything in full detail in his post, but in general we should
 not think of C/C++ code as defensible. If an attacker is able to get at C/C++
 attack surface, we must assume they can win with an exploit based on memory
 unsafety.&lt;/p>

&lt;p>As an additional example, consider your web server’s or browser’s TLS
 implementation. Should we consider it exposed? We can model it something like
 this:&lt;/p>

&lt;figure>
&lt;svg width="536pt" height="46pt" role="img" aria-label="a directed graph showing attacker → (0, low, or medium) net interface → (passthru) kernel → (passthru) TCP → (low or
medium) TLS"
 viewBox="0.00 0.00 536.00 46.00" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
&lt;g id="graph0" class="graph" transform="scale(1 1) rotate(0) translate(4 42)">
&lt;!-- attacker -->
&lt;g id="node1" class="node">
&lt;title>attacker&lt;/title>
&lt;path fill="none" stroke="var(--fg)" d="M42,-36C42,-36 12,-36 12,-36 6,-36 0,-30 0,-24 0,-24 0,-12 0,-12 0,-6 6,0 12,0 12,0 42,0 42,0 48,0 54,-6 54,-12 54,-12 54,-24 54,-24 54,-30 48,-36 42,-36"/>
&lt;text text-anchor="middle" x="27" y="-15.8" font-family="Roboto" font-size="9.00">attacker&lt;/text>
&lt;/g>
&lt;!-- NIC -->
&lt;g id="node2" class="node">
&lt;title>NIC&lt;/title>
&lt;path fill="none" stroke="var(--fg)" d="M184,-36C184,-36 140,-36 140,-36 134,-36 128,-30 128,-24 128,-24 128,-12 128,-12 128,-6 134,0 140,0 140,0 184,0 184,0 190,0 196,-6 196,-12 196,-12 196,-24 196,-24 196,-30 190,-36 184,-36"/>
&lt;text text-anchor="middle" x="162" y="-15.8" font-family="Roboto" font-size="9.00">net interface&lt;/text>
&lt;/g>
&lt;!-- attacker&amp;#45;&amp;gt;NIC -->
&lt;g id="edge1" class="edge">
&lt;title>attacker&amp;#45;&amp;gt;NIC&lt;/title>
&lt;path fill="none" stroke="var(--fg)" d="M54.28,-18C72.28,-18 96.58,-18 117.45,-18"/>
&lt;polygon fill="var(--fg)" stroke="var(--fg)" points="117.69,-21.5 127.69,-18 117.69,-14.5 117.69,-21.5"/>
&lt;text text-anchor="middle" x="91" y="-30.8" font-family="Roboto" font-size="9.00">0, low, or&lt;/text>
&lt;text text-anchor="middle" x="91" y="-20.8" font-family="Roboto" font-size="9.00">medium&lt;/text>
&lt;/g>
&lt;!-- kernel -->
&lt;g id="node3" class="node">
&lt;title>kernel&lt;/title>
&lt;path fill="none" stroke="var(--fg)" d="M295,-36C295,-36 250,-36 250,-36 244,-36 238,-30 238,-24 238,-24 238,-12 238,-12 238,-6 244,0 250,0 250,0 295,0 295,0 301,0 307,-6 307,-12 307,-12 307,-24 307,-24 307,-30 301,-36 295,-36"/>
&lt;text text-anchor="middle" x="272.5" y="-15.8" font-family="Roboto" font-size="9.00">device driver&lt;/text>
&lt;/g>
&lt;!-- NIC&amp;#45;&amp;gt;kernel -->
&lt;g id="edge2" class="edge">
&lt;title>NIC&amp;#45;&amp;gt;kernel&lt;/title>
&lt;path fill="none" stroke="var(--fg)" d="M196.14,-18C206.05,-18 217.07,-18 227.56,-18"/>
&lt;polygon fill="var(--fg)" stroke="var(--fg)" points="227.81,-21.5 237.81,-18 227.81,-14.5 227.81,-21.5"/>
&lt;text text-anchor="middle" x="217" y="-20.8" font-family="Roboto" font-size="9.00">0&lt;/text>
&lt;/g>
&lt;!-- TCP -->
&lt;g id="node4" class="node">
&lt;title>TCP&lt;/title>
&lt;path fill="none" stroke="var(--fg)" d="M391,-36C391,-36 361,-36 361,-36 355,-36 349,-30 349,-24 349,-24 349,-12 349,-12 349,-6 355,0 361,0 361,0 391,0 391,0 397,0 403,-6 403,-12 403,-12 403,-24 403,-24 403,-30 397,-36 391,-36"/>
&lt;text text-anchor="middle" x="376" y="-15.8" font-family="Roboto" font-size="9.00">TCP&lt;/text>
&lt;/g>
&lt;!-- kernel&amp;#45;&amp;gt;TCP -->
&lt;g id="edge3" class="edge">
&lt;title>kernel&amp;#45;&amp;gt;TCP&lt;/title>
&lt;path fill="none" stroke="var(--fg)" d="M307.02,-18C317.24,-18 328.52,-18 338.9,-18"/>
&lt;polygon fill="var(--fg)" stroke="var(--fg)" points="338.91,-21.5 348.91,-18 338.91,-14.5 338.91,-21.5"/>
&lt;text text-anchor="middle" x="328" y="-20.8" font-family="Roboto" font-size="9.00">0&lt;/text>
&lt;/g>
&lt;!-- TLS -->
&lt;g id="node5" class="node">
&lt;title>TLS&lt;/title>
&lt;path fill="none" stroke="var(--fg)" d="M516,-36C516,-36 486,-36 486,-36 480,-36 474,-30 474,-24 474,-24 474,-12 474,-12 474,-6 480,0 486,0 486,0 516,0 516,0 522,0 528,-6 528,-12 528,-12 528,-24 528,-24 528,-30 522,-36 516,-36"/>
&lt;text text-anchor="middle" x="501" y="-15.8" font-family="Roboto" font-size="9.00">TLS&lt;/text>
&lt;/g>
&lt;!-- TCP&amp;#45;&amp;gt;TLS -->
&lt;g id="edge4" class="edge">
&lt;title>TCP&amp;#45;&amp;gt;TLS&lt;/title>
&lt;path fill="none" stroke="var(--fg)" d="M403.09,-18C420.78,-18 444.4,-18 463.9,-18"/>
&lt;polygon fill="var(--fg)" stroke="var(--fg)" points="463.95,-21.5 473.95,-18 463.95,-14.5 463.95,-21.5"/>
&lt;text text-anchor="middle" x="438.5" y="-30.8" font-family="Roboto" font-size="9.00">low or&lt;/text>
&lt;text text-anchor="middle" x="438.5" y="-20.8" font-family="Roboto" font-size="9.00">medium&lt;/text>
&lt;/g>
&lt;/g>
&lt;/svg>
 &lt;figcaption>An attack pathway from the internet to
 the application’s TLS implementation.&lt;/figcaption>
&lt;/figure>

&lt;p>In this case, the attacker is interested only in the application’s TLS
 implementation, and is just using the kernel as a way to get there — they are
 not attacking the device driver or the TCP implementation. (Although those are
 also exposed attack surfaces, of course.) The kernel typically does not do
 anything with the application layer traffic, passing it verbatim to the userland
 application. So the kernel is not creating a security boundary in this case.&lt;/p>

&lt;p>The attacker has a pretty straight shot to your application’s TLS
 implementation; the only attack precondition is whether the attacker can send
 malicious TLS traffic to the application. Obviously, servers listen to the
 internet and process whatever they get; that’s 0 cost. If attacking a client, an
 attacker may have to get the target to contact their server or may have to be on
 the same network as the target. We might say that is up to medium cost.&lt;/p>

&lt;p>So, things like device drivers and HTTP, TCP, and TLS implementations are all
 fine candidates for (re)implementing in a safer language. They’re unavoidably
 exposed.&lt;/p>

&lt;p>Consider an example where the C/C++ attack surface is not as directly
 exposed.&lt;/p>

&lt;figure>
&lt;svg width="425pt" height="44pt" role="img" aria-label="a directed graph showing attacker → ... → HTTP → parse CSP → evaluate CSP"
 viewBox="0.00 0.00 425.00 44.00" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
&lt;g id="graph0" class="graph" transform="scale(1 1) rotate(0) translate(4 40)">
&lt;!-- attacker -->
&lt;g id="node1" class="node">
&lt;title>attacker&lt;/title>
&lt;path fill="none" stroke="var(--fg)" d="M42,-36C42,-36 12,-36 12,-36 6,-36 0,-30 0,-24 0,-24 0,-12 0,-12 0,-6 6,0 12,0 12,0 42,0 42,0 48,0 54,-6 54,-12 54,-12 54,-24 54,-24 54,-30 48,-36 42,-36"/>
&lt;text text-anchor="middle" x="27" y="-15.8" font-family="Roboto" font-size="9.00">attacker&lt;/text>
&lt;/g>
&lt;!-- stuff -->
&lt;g id="node2" class="node">
&lt;title>stuff&lt;/title>
&lt;path fill="none" stroke="var(--fg)" d="M132,-36C132,-36 102,-36 102,-36 96,-36 90,-30 90,-24 90,-24 90,-12 90,-12 90,-6 96,0 102,0 102,0 132,0 132,0 138,0 144,-6 144,-12 144,-12 144,-24 144,-24 144,-30 138,-36 132,-36"/>
&lt;text text-anchor="middle" x="117" y="-15.8" font-family="Roboto" font-size="9.00">...&lt;/text>
&lt;/g>
&lt;!-- attacker&amp;#45;&amp;gt;stuff -->
&lt;g id="edge1" class="edge">
&lt;title>attacker&amp;#45;&amp;gt;stuff&lt;/title>
&lt;path fill="none" stroke="var(--fg)" d="M54.4,-18C62.39,-18 71.31,-18 79.82,-18"/>
&lt;polygon fill="var(--fg)" stroke="var(--fg)" points="79.92,-21.5 89.92,-18 79.92,-14.5 79.92,-21.5"/>
&lt;/g>
&lt;!-- HTTP -->
&lt;g id="node3" class="node">
&lt;title>HTTP&lt;/title>
&lt;path fill="none" stroke="var(--fg)" d="M222,-36C222,-36 192,-36 192,-36 186,-36 180,-30 180,-24 180,-24 180,-12 180,-12 180,-6 186,0 192,0 192,0 222,0 222,0 228,0 234,-6 234,-12 234,-12 234,-24 234,-24 234,-30 228,-36 222,-36"/>
&lt;text text-anchor="middle" x="207" y="-15.8" font-family="Roboto" font-size="9.00">HTTP&lt;/text>
&lt;/g>
&lt;!-- stuff&amp;#45;&amp;gt;HTTP -->
&lt;g id="edge2" class="edge">
&lt;title>stuff&amp;#45;&amp;gt;HTTP&lt;/title>
&lt;path fill="none" stroke="var(--fg)" d="M144.4,-18C152.39,-18 161.31,-18 169.82,-18"/>
&lt;polygon fill="var(--fg)" stroke="var(--fg)" points="169.92,-21.5 179.92,-18 169.92,-14.5 169.92,-21.5"/>
&lt;/g>
&lt;!-- parse_CSP -->
&lt;g id="node4" class="node">
&lt;title>parse_CSP&lt;/title>
&lt;path fill="none" stroke="var(--fg)" d="M315,-36C315,-36 282,-36 282,-36 276,-36 270,-30 270,-24 270,-24 270,-12 270,-12 270,-6 276,0 282,0 282,0 315,0 315,0 321,0 327,-6 327,-12 327,-12 327,-24 327,-24 327,-30 321,-36 315,-36"/>
&lt;text text-anchor="middle" x="298.5" y="-15.8" font-family="Roboto" font-size="9.00">parse CSP&lt;/text>
&lt;/g>
&lt;!-- HTTP&amp;#45;&amp;gt;parse_CSP -->
&lt;g id="edge3" class="edge">
&lt;title>HTTP&amp;#45;&amp;gt;parse_CSP&lt;/title>
&lt;path fill="none" stroke="var(--fg)" d="M234.37,-18C242.29,-18 251.13,-18 259.64,-18"/>
&lt;polygon fill="var(--fg)" stroke="var(--fg)" points="259.76,-21.5 269.76,-18 259.76,-14.5 259.76,-21.5"/>
&lt;/g>
&lt;!-- eval_CSP -->
&lt;g id="node5" class="node">
&lt;title>eval_CSP&lt;/title>
&lt;path fill="none" stroke="var(--fg)" d="M405,-36C405,-36 375,-36 375,-36 369,-36 363,-30 363,-24 363,-24 363,-12 363,-12 363,-6 369,0 375,0 375,0 405,0 405,0 411,0 417,-6 417,-12 417,-12 417,-24 417,-24 417,-30 411,-36 405,-36"/>
&lt;text text-anchor="middle" x="390" y="-15.8" font-family="Roboto" font-size="9.00">eval CSP&lt;/text>
&lt;/g>
&lt;!-- parse_CSP&amp;#45;&amp;gt;eval_CSP -->
&lt;g id="edge4" class="edge">
&lt;title>parse_CSP&amp;#45;&amp;gt;eval_CSP&lt;/title>
&lt;path fill="none" stroke="var(--fg)" d="M327.33,-18C335.35,-18 344.23,-18 352.69,-18"/>
&lt;polygon fill="var(--fg)" stroke="var(--fg)" points="352.72,-21.5 362.72,-18 352.72,-14.5 352.72,-21.5"/>
&lt;/g>
&lt;/g>
&lt;/svg>
 &lt;figcaption>An attack pathway
 from the internet to a client’s CSP evaluator.&lt;/figcaption>
&lt;/figure>

&lt;p>In this example, we have an HTTP client that is going to parse and evaluate a
 &lt;a href="https://en.wikipedia.org/wiki/Content_Security_Policy">Content Security
 Policy&lt;/a> (CSP) header. Each of the network interface, device driver, TCP
 implementation, TLS client implementation, HTTP client implementation, and CSP
 parser are fairly exposed attack surface. For example, if the attacker wants to
 exploit some bug in the CSP parser, they can likely rely on all of the previous
 components to pass the header value through verbatim to the CSP parser. Thus,
 they probably do not create a security boundary.
&lt;/p>

&lt;p>But if the attacker wants to exploit a likely bug class, mis-evaluation of
 CSP policy, they must first get past the CSP parser. Although it is vulnerable
 attack surface, it does also provide some security boundary: the policy must be
 well-formed according to the grammar the parser accepts. Another bug class is
 that the parser’s grammar is not necessarily the same as the grammar in the
 spec.&lt;/p>

&lt;p>Thus, we’d be speaking of logic bugs in the CSP parser and/or evaluator. This
 is the kind of code that can be buggy in any language; this is not memory
 unsafety that can be resolved at scale with a safer language.&lt;/p>

&lt;p>These examples suggest that you have to get fairly deep into the call graph
 before memory unsafety becomes less of a concern. That’s consistent with &lt;a
 href="https://alexgaynor.net/2020/may/27/science-on-memory-unsafety-and-security/">the
 findings that memory unsafety accounts for anywhere from ⅔ to ¾ of
 vulnerabilities&lt;/a>. The problem is that bad.&lt;/p>

&lt;p>Models like those above can be step 1 in a process of repair triage. You
 might order a set of constraints when filtering through what code to rewrite,
 apply mitigations or testing to, or even get rid of first:&lt;/p>

&lt;ol>
 &lt;li>Select the most exposed code&lt;/li>
 &lt;li>...of that code, start with the highest-privilege code&lt;/li>
 &lt;li>...of that code, start with the code that has the highest observed bug count&lt;/li>
&lt;/ol>

&lt;p>Or you might triage differently, depending on your situation:&lt;/p>

&lt;ol>
 &lt;li>Select the most exposed code&lt;/li>
 &lt;li>...of that code, start with the code that has the highest observed bug count&lt;/li>
 &lt;li>...of that code, start with the highest-privilege code&lt;/li>
&lt;/ol>

&lt;p>Or even:&lt;/p>

&lt;ol>
 &lt;li>Select the code that has the highest observed bug count&lt;/li>
 &lt;li>...of that code, start with the most exposed code&lt;/li>
 &lt;li>...of that code, start with the highest-privilege code&lt;/li>
&lt;/ol>

&lt;p>Which approach is appropriate depends on your system. For example, if you are
 working entirely in the kernel, all your code runs at the same level of
 privilege so you can’t use that as a filter. Or if you are in userland, but your
 application is not making use of process sandboxing, consider exploring that
 first before starting a rewrite effort.&lt;/p>

&lt;p>In any case, we don’t have to “rewrite everything in Rust” to significantly
 improve memory safety, and we are not lost in a sea of undifferentiated attack
 surface. There are ways we can prioritize in a somewhat systematic way — we
 don’t have to fix random things ad hoc.&lt;/p>

&lt;p>&lt;i>Thanks to Jacob Hoffman-Andrews, Andrew Dunham, and Dev Akhawe for reading
 drafts of this post and suggesting helpful improvements!&lt;/i>&lt;/p></description><author>Chris Palmer</author><guid>2021/04/09/prioritizing-memory-safety-migrations/index.html</guid><pubDate>Fri, 09 Apr 2021 00:00:00 +0000</pubDate></item><item><title>Vaccine Day</title><link>https://noncombatant.org/2021/03/15/vaccine-day/index.content</link><description>&lt;h1>Vaccine Day&lt;/h1>

&lt;p>&lt;time>15 March 2021&lt;/time>&lt;/p>

&lt;p>Today was the first day I became &lt;a
href="https://sf.gov/information/other-conditions-eligible-covid-19-vaccine">eligible
for the Covid-19 vaccine&lt;/a>. I’m at high risk and in group 1c for a pile of
reasons. I had been checking and re-checking the various vaccine appointment
sign-up web sites all weekend, to no avail.&lt;/p>

&lt;p>I’m a hardened survivor; but, you know, that doesn’t mean I want to test fate
on purpose. So I’ve been sheltering in place for over a year, with yet another
round of medical adventures last Summer, venturing outside as rarely as possible
and coming into contact only with my immediate SF family (who have observed the
same precautions).&lt;/p>

&lt;p>By chance, yesterday evening, a friend who has been volunteering at &lt;a
href="https://sf.gov/location/moscone-center-south-covid-19-vaccine-site">the
Moscone Center mass vaccination site&lt;/a> pointed me to the web site and said I
could get an appointment just then. So I mashed the buttons real fast and indeed
I got an appointment for today!&lt;/p>

&lt;p>The whole thing was run incredibly smoothly. Even though the place was full
(within the limits of safe distancing) and the lines were long, everything moved
as quickly as possible and the whole process took not much longer than it takes
to walk in. I walked right up to the moving line, got to the door, in the
building, signed in, down the escalators to the convention floor (where there
were speakers set up and &lt;a
href="https://www.youtube.com/watch?v=LPFgBCUBMYk">blasting Janelle&lt;/a>!!), to a
big ol’ hall with well-spaced chairs and some high-energy volunteers cheering
and directing traffic. Everyone was pretty happy, because fuckin’ science,
right?! I sat for about 5 minutes before it was my turn, and then I was gently
but unceremoniously jabbed. Then everyone has to sit for 15 minutes in case they
have an allergic reaction or other side-effect. (Nobody had any trouble that I
could see while I was there.)&lt;/p>

&lt;p>More Janelle on the way out. Then I just went home as if it were a normal
day.&lt;/p>

&lt;p>But it was absolutely not a normal day. It was a triumph of science, and just
as importantly it is a triumph of civic pride and care for fellow people. We can
solve collective action problems, and provide public goods like public health —
if we want to. It took a crisis to shake us awake, and we have to work against
the simultaneous crisis of an ideology dedicated to &lt;i>not&lt;/i> solving
collective action problems and &lt;i>not&lt;/i> providing public goods.&lt;/p>

&lt;p>But it’s really happening. This is the first time in a year that I have
really felt, at a gut level, that we might someday get through this.&lt;/p>

&lt;p>Once I’ve got my second dose (already scheduled!) and am feeling safe, I’m &lt;a
href="https://sfdhr.org/emergency-healthcare-volunteers">going to volunteer
too&lt;/a>. I’m feeling grateful, once again, for my incredible medical luck. It’s
a happy duty to help some other people get their luck.&lt;/p></description><author>Chris Palmer</author><guid>2021/03/15/vaccine-day/index.html</guid><pubDate>Mon, 15 Mar 2021 00:00:00 +0000</pubDate></item><item><title>Maybe We Can Have Nice Things</title><link>https://noncombatant.org/2021/02/16/maybe-we-can-have-nice-things/index.content</link><description>&lt;h1>Maybe We Can Have Nice Things&lt;/h1>

&lt;p>&lt;time>16 February 2021&lt;/time>&lt;/p>

&lt;p>&lt;aside>18 February: See below for some nice updates!&lt;/aside>&lt;/p>

&lt;p>Programming languages advance by introducing new constraints. A key reason we
don’t use assembly language for everything is that the lack of constraints make
it too hard to use for everyday programming. Before &lt;a
href="https://www.cs.utexas.edu/users/EWD/ewd02xx/EWD215.PDF">&lt;code>goto&lt;/code>
was considered harmful&lt;/a>, people wrote machine code that jumped all over the
place, and programmers had to maintain a mental model of the complete machine
state and the full implications of each jump — a recipe for bugs.&lt;/p>

&lt;p>Then, &lt;a
href="https://en.wikipedia.org/wiki/Structured_programming">structured
programming&lt;/a> was introduced: structured languages still compiled down to
&lt;code>goto&lt;/code>s (or arbitrary jumps), but the programmer could think in terms
of more limited jumps: &lt;code>if&lt;/code>, &lt;code>switch&lt;/code>/&lt;code>case&lt;/code>,
&lt;code>call&lt;/code>, &lt;code>return&lt;/code>, &lt;code>for&lt;/code>. These constrained
jumps are much easier to understand; for example, when you’re reading code, you
can know that &lt;code>return&lt;/code> doesn’t return just anywhere. It returns only
to the caller, as identified by a pointer on the stack. Later, language
designers added additional constrained jumps like
&lt;code>throw&lt;/code>/&lt;code>catch&lt;/code>, and virtual function calls.&lt;/p>

&lt;p>(&lt;code>throw&lt;/code> is a little bit too &lt;code>goto&lt;/code>-y for my taste,
since you can’t tell locally where the relevant &lt;code>catch&lt;/code> block is. But
that’s a story for another time.)&lt;/p>

&lt;p>A key innovation of C++ was to introduce &lt;a
href="https://en.wikipedia.org/wiki/Resource_acquisition_is_initialization">RAII&lt;/a>,
which essentially ‘piggybacks’ on the value of the stack and enriches it with a
lot more power. (The additional complexity is usually manageable, and worth it.)
It allows you extend the automatic memory management that the stack provides,
initializing and cleaning up complex resources instead of just primitive values
like integers and floats. You can automatically close open files, release
dynamic storage, and so on. And it’s deterministic.&lt;/p>

&lt;p>But there was still the problem of the heap: a free-fire zone with no
constraints, riddled with memory leaks (heap resources allocated but never
released) and use-after-free bugs (heap resources re-used even after having been
released).&lt;/p>

&lt;p>A key innovation of Rust has been to &lt;a
href="https://doc.rust-lang.org/1.8.0/book/references-and-borrowing.html">statically
constrain the lifetimes of heap resources&lt;/a>, enabling us to more completely
solve the worst remaining memory unsafety problem. (Previous solutions to the
heap lifetime problem were &lt;a
href="https://en.wikipedia.org/wiki/Garbage_collection_(computer_science)">dynamic&lt;/a>,
not static, and hence expensive in space and time — as well as being
non-deterministic. These limitations reduce the applicability of
dynamically-managed languages to applications and environments where these costs
are affordable.)&lt;/p>

&lt;p>And, of course, taming object lifetimes greatly eases the problem of safe,
efficient concurrency. Concurrency is the key to improving performance in modern
systems.&lt;/p>

&lt;p>Beyond memory safety, Rust makes more use of typefulness than I typically see
in other mainstream languages in its niche. For example, Rust’s rich
&lt;code>enum&lt;/code>s and pattern matching make it easier to write state machines,
&lt;a href="https://doc.rust-lang.org/rust-by-example/generics/new_types.html">the
new type idiom&lt;/a> makes it easier to get additional type safety (and improves
the interface-as-documentation factor), and so on. You can work to get similar
benefits in other languages, but Rust’s syntactic mechanisms and idiomatic usage
create affordances for these easier patterns.&lt;/p>

&lt;p>Another freeing constraint Rust has introduced has been to systematize and
automate dependency management: the Cargo package management system. Good
dependency management is a &lt;a href="https://research.swtch.com/deps">monstrously
hard problem&lt;/a>. Any dependency management system, including manual or ad hoc
management, poses a variety of problems:&lt;/p>

&lt;ul>

&lt;li>&lt;b>Version conflicts:&lt;/b> Inevitably, the latest version of the foo package
has changed its API in such a way that it can’t interoperate with the bar
package. Now resolve these conflicts all up and down the dependency tree.
Fun!&lt;/li>

&lt;li>&lt;b>Supply-chain security:&lt;/b> When you pull in a dependency, you must trust
the transitive closure of all the authors who have committed to that dependency
sub-tree. This includes not just the code and the programs you can build with
it, but build scripts themselves.&lt;/li>

&lt;li>&lt;b>Micro- and even pico-dependencies:&lt;/b> The tendency to multiply the
previous 2 problems by creating &lt;a
href="https://www.npmjs.com/package/is-odd">extremely tiny&lt;/a>, &lt;a
href="https://www.npmjs.com/package/is-even">single-use packages&lt;/a>.&lt;/li>

&lt;li>&lt;b>Proliferation:&lt;/b> The tendency to multiply the previous 3 problems by
creating several packages that serve the same basic need, leading to a situation
in which effort solving the same problem is fragmented — including
documentation, training, code reviewer/auditor hours, and so on. (I call this
the “Occam’s Razor now has &lt;a
href="https://www.theonion.com/fuck-everything-were-doing-five-blades-1819584036">5
blades&lt;/a>” problem.)&lt;/li>

&lt;/ul>

&lt;p>The NPM ecosystem provides the clearest modern illustration of these
problems. (See page 11 of &lt;a
href="https://octoverse.github.com/static/github-octoverse-2020-security-report.pdf">GitHub’s
report on security&lt;/a>, for example.)&lt;/p>

&lt;p>However, for all of NPM’s problems, &lt;b>at least it is a package management
system at all&lt;/b>! It’s easy to pick on NPM (or predecessors like &lt;a
href="https://www.cpan.org/">CPAN&lt;/a>, or &lt;a href="https://ctan.org/">CTAN&lt;/a>,
or...), but even at its worst it’s a &lt;b>huge improvement&lt;/b> over manually
managing dependencies (such as by manually vendoring them into your source tree,
or just telling the user to install such-and-such libraries before attempting to
compile).&lt;/p>

&lt;p>Life is better with NPM, and with Rust’s Cargo, Go’s &lt;code>go get&lt;/code>, and
so on. Even when they aren’t perfect yet, they provide a framework for
improvement, by constraining where dependencies come from and how we maintain
them.&lt;/p>

&lt;p>But a lot of work is still necessary. As an example of a Nice Thing Indeed,
Cargo has this add-on package called &lt;a
href="https://github.com/rust-secure-code/cargo-supply-chain">supply-chain&lt;/a>,
which will show you all the packages a given package depends on. It will also
estimate how many individual publishers author those dependencies. Here is what
happens when you run supply-chain on itself:&lt;/p>

&lt;pre>
~/src/rust/cargo-supply-chain % &lt;b>cargo supply-chain publishers&lt;/b>

The following crates will be ignored because they come from a local directory:
 - cargo-supply-chain

The `crates.io` cache was not found or it is invalid.
 Run `cargo supply-chain update` to generate it.

Fetching publisher info from crates.io
This will take roughly 2 seconds per crate due to API rate limits
Fetching data for "adler" (0/79)
[&lt;i>77 items, including some surprising ones, elided...&lt;/i>]
Fetching data for "xattr" (78/79)

The following individuals can publish updates for your dependencies:

 1. alexcrichton via crates: flate2, wasm-bindgen-backend, wasi, bitflags, proc-macro2, wasm-bindgen-macro, wasm-bindgen, openssl-probe, unicode-xid, wasm-bindgen-macro-support, filetime, semver, tar, unicode-normalization, libc, js-sys, bumpalo, log, wasm-bindgen-shared, cfg-if, cc, web-sys
 [&lt;i>55 authors elided...&lt;/i>]
 57. zesterer via crates: spin

Note: there may be outstanding publisher invitations. crates.io provides no way to list them.
Invitations are also impossible to revoke, and they never expire.
See https://github.com/rust-lang/crates.io/issues/2868 for more info.

All members of the following teams can publish updates for your dependencies:

 1. "github:rustwasm:core" (https://github.com/rustwasm) via crates: web-sys, js-sys, wasm-bindgen-macro, wasm-bindgen-macro-support, wasm-bindgen-backend, wasm-bindgen, wasm-bindgen-shared
 2. "github:servo:cargo-publish" (https://github.com/servo) via crates: core-foundation-sys, percent-encoding, form_urlencoded, unicode-bidi, core-foundation, idna, url
 3. "github:servo:rust-url" (https://github.com/servo) via crates: percent-encoding, form_urlencoded, idna, url
 4. "github:rust-bus:maintainers" (https://github.com/rust-bus) via crates: security-framework-sys, security-framework, tinyvec
 5. "github:rust-lang-nursery:libs" (https://github.com/rust-lang-nursery) via crates: bitflags, log, lazy_static
 6. "github:serde-rs:owners" (https://github.com/serde-rs) via crates: serde_derive, serde, serde_json
 7. "github:rust-lang:libs" (https://github.com/rust-lang) via crates: libc, cfg-if
 8. "github:rust-lang-nursery:log-owners" (https://github.com/rust-lang-nursery) via crates: log
 9. "github:rust-random:maintainers" (https://github.com/rust-random) via crates: getrandom

Github teams are black boxes. It's impossible to get the member list without explicit permission.

~/src/rust/cargo-supply-chain % &lt;b>cargo supply-chain update&lt;/b>
Note: this will download large amounts of data (approximately 250Mb).
On a slow network this will take a while.
&lt;/pre>

&lt;p>Now, that’s a lot of dependencies by a lot of publishers whom I don’t know.
(Although it’s not automated, if you dig around you’ll find that many of those
authors are well-established members of the Rust development team, so trusting
them is an easier sell.) Another bummer is that, when I built supply-chain, my
default &lt;code>$CFLAGS&lt;/code> broke the build (&lt;b>Update 18 Feb:&lt;/b> with an
almost certainly spurious and not security-relevant warning,
&lt;code>-Wunused-macros&lt;/code>). (My flags are quite persnickety:
&lt;code>-Weverything -Werror -std=c11&lt;/code>. Very little code builds with these
flags. 😇) Apparently, some of supply-chain’s own dependencies depend on C code.
Alas.&lt;/p>

&lt;p>But that’s OK! Cargo provides a framework for working on these problems. Over
time, I’d like to see things move along these lines:&lt;/p>

&lt;ul>

&lt;li>Replace C/C++ dependencies with Rust, and reduce the use of
&lt;code>unsafe&lt;/code>. This has been happening, and will continue to, over time.
(See &lt;a href="https://github.com/rust-secure-code/safety-dance">the Safety Dance
project&lt;/a>, which is a focused on reducing the use of
&lt;code>unsafe&lt;/code>.)&lt;/li>

&lt;li>Coalesce the most common dependencies into a (semi-)official ‘extended
&lt;code>std&lt;/code>’, so that they can appear as a single dependency with a single
publishing team. This is controversial in some communities, but I think it would
go a long way toward reducing the problems.&lt;/li>

&lt;li>Obviate some of the micro-dependencies by folding them into larger, more
general packages including the language itself, &lt;code>std&lt;/code>, and ‘extended
&lt;code>std&lt;/code>’ (where and if appropriate). This is also sometimes
controversial, but again I think it would help.&lt;/li>

&lt;li>Perhaps supply-chain, check, clippy, or a new tool could provide some
indication of a package’s reputation or something like what the Perl community
jokingly calls &lt;a href="https://metacpan.org/pod/Test::Kwalitee">kwalitee&lt;/a>:
Not quality, but overall ‘smells’. Good test coverage? Is the package version
greater than 1.0? Actively maintained? Frequently used? Maintained by the same
people for a long time? A low proportion of lines of code in &lt;code>unsafe&lt;/code>
blocks, or in C/C++/assembly? Some of these things can be more or less
automatically determined, and tooling could flag packages that stand out.

&lt;aside>Fun update: Such a thing exists, and is called &lt;a
href="https://github.com/crev-dev/cargo-crev/">crev&lt;/a>. Awesome!&lt;/aside>&lt;/li>

&lt;/ul>

&lt;p>Another good thing about Rust is its friendly community. Not all systems
programming communities are as welcoming as Rust’s is. Rust, and some other
communities, have taken &lt;a
href="https://www.rust-lang.org/policies/code-of-conduct">proactive steps to
maintain a healthy community&lt;/a>. I think it’s fair to say the Rust community is
doing relatively well, especially in the systems programming niche.&lt;/p>

&lt;p>Like all language communities, whether of natural languages or artificial
languages, the community and the body of literature and the oral tradition are
what matter. In its niche, Rust looks like the option with the most momentum
around a more positive, healthier community. The community and the language are
probably not perfect — nothing is, if perfect is even a thing — but Rust looks
like the community most open to solving its problems, and most capable of
solving systems programming problems.&lt;/p>

&lt;aside>

&lt;p>Thanks to Adrian Taylor for reminding me to mention typefulness, concurrency,
and Safety Dance.&lt;/p>

&lt;p>Thanks to Sergey Davidoff, supply-chain maintainer, for pointing me at crev
and noting that Safety Dance is more about reducing &lt;code>unsafe&lt;/code> than
C.&lt;/p>

&lt;/aside></description><author>Chris Palmer</author><guid>2021/02/16/maybe-we-can-have-nice-things/index.html</guid><pubDate>Tue, 16 Feb 2021 00:00:00 +0000</pubDate></item><item><title>Enigma 2021</title><link>https://noncombatant.org/2021/02/06/enigma-2021/index.content</link><description>&lt;h1>Enigma 2021&lt;/h1>

&lt;p>&lt;time>6 February 2021&lt;/time>&lt;/p>

&lt;p>Every year, the Enigma conference is enjoyable and interesting. I’m a huge
fan of the wide-ranging scope and single-track structure. I hope we all get
vaccinated in time to have the conference in person again next year. The
conference organizers did a great job making the virtual conference work as well
as possible, and the Slack was fun, but you know… nothing beats in-person
hooting in the hallway track.&lt;/p>

&lt;p>I was super fortunate to have my talk proposal accepted. I spoke about &lt;a
href="https://www.usenix.org/conference/enigma2021/presentation/palmer">The
Limits Of Sandboxing, And Next Steps&lt;/a>, which is about my work on the Chrome
Platform Security Team the past few years. (If you want to read the slides, &lt;a
href="https://docs.google.com/presentation/d/1U60ycn3iW5MOB_xJUc09fsS1KXY2i68m9eVJoG4loWk/edit#slide=id.gb726919370_0_12">the
original Google presentation&lt;/a> has all the speaker notes and working links to
citations. Spoiler Alert: the “next steps” are to adopt memory-safe
languages.&lt;/p>

&lt;p>Alex Gaynor and I sort of collaborated to make the same point from 2
different perspectives. His presentation, &lt;a
href="https://www.usenix.org/conference/enigma2021/presentation/gaynor">Quantifying
Memory Unsafety And Reactions To It&lt;/a>, is a great synthesis of empirical data
and emotional realness. Likely the biggest difficulty we face in migrating away
from memory-unsafe languages is people’s emotional attachments to the status
quo. Change is hard.&lt;/p>

&lt;p>As always, there were a whole bunch of high-quality talks this year. Some
stand-outs (in no particular order):&lt;/p>

&lt;ul>

&lt;li>&lt;a
href="https://www.usenix.org/conference/enigma2021/presentation/starbird">Online
Rumors, Misinformation And Disinformation: The Perfect Storm Of Covid-19 And
Election2020&lt;/a>, by Kate Starbird&lt;/li>

&lt;li>&lt;a
href="https://www.usenix.org/conference/enigma2021/presentation/mou">Building
E2EE And User Identity&lt;/a>, by Merry Ember Mou&lt;/li>

&lt;li>&lt;a
href="https://www.usenix.org/conference/enigma2021/presentation/stone">The State
Of 0-Day In-The-Wild Exploitation&lt;/a>, by Maddie Stone&lt;/li>

&lt;li>&lt;a href="https://www.usenix.org/conference/enigma2021/presentation/negus">No
Data, No Problem—Giving Nuclear Inspectors Better Tools Without Revealing State
Secrets&lt;/a>, by Mitch Negus&lt;/li>

&lt;/ul></description><author>Chris Palmer</author><guid>2021/02/06/enigma-2021/index.html</guid><pubDate>Sat, 06 Feb 2021 00:00:00 +0000</pubDate></item><item><title>A Sweet Chorus-y Echo</title><link>https://noncombatant.org/2020/04/18/capistan/index.content</link><description>&lt;h1>A Sweet Chorus-y Echo&lt;/h1>

&lt;p>&lt;time>18 April 2020&lt;/time>&lt;/p>

&lt;p>I’m really into continuous effects lately. (As opposed to discrete:
 clean/DISTORTION!!, normal/PHASER!!, et c.) I want to &lt;a href="/pedal-ideas/">smoothly swoop&lt;/a> through a sound’s
 range as I play.&lt;/p>

&lt;p>&lt;a href="/2014/02/09/a-favorite-pedal-strymon-el-capistan/">I’ve always loved
 the Strymon El Capistan&lt;/a>, but I’ve been treating it as kind of a special
 effect, for a special occasion, rather than a go-to echo for regular use. But
 today I hit upon a magical setting that gives me what I want and can use all the
 time: a combination chorus and chorus-y delay. Here are the settings:&lt;/p>

&lt;figure>&lt;img src="chorus-capistan.jpg" width="800" height="800" alt="Settings
for the El Capistan as a chorus-y echo" loading="lazy" />
 &lt;figcaption>Settings for
 the El Capistan as a chorus-y echo&lt;/figcaption>
&lt;/figure>

&lt;table class="small">

 &lt;tr>
 &lt;th class="right">&lt;b>Time&lt;/b>&lt;/th>
 &lt;td>7:00&lt;/td>
 &lt;/tr>

 &lt;tr>
 &lt;th class="right">&lt;b>Tape Head&lt;/b>&lt;/th>
 &lt;td>Single&lt;/td>
 &lt;/tr>

 &lt;tr>
 &lt;th class="right">&lt;b>Mode&lt;/b>&lt;/th>
 &lt;td>A&lt;/td>
 &lt;/tr>

 &lt;tr>
 &lt;th class="right">&lt;b>Mix&lt;/b>&lt;/th>
 &lt;td>somewhere shy of 12:00&lt;/td>
 &lt;/tr>

 &lt;tr>
 &lt;th class="right">&lt;b>Tape Age&lt;/b>&lt;/th>
 &lt;td>7:00&lt;/td>
 &lt;/tr>

 &lt;tr>
 &lt;th class="right">&lt;b>Repeats&lt;/b>&lt;/th>
 &lt;td>somewhere shy of 12:00&lt;/td>
 &lt;/tr>

 &lt;tr>
 &lt;th class="right">&lt;b>Wow &amp;amp; Flutter&lt;/b>&lt;/th>
 &lt;td>3:00 or beyond!&lt;/td>
 &lt;/tr>

&lt;/table>

&lt;p>Crucial to this setup is the expression pedal, set to control the &lt;b>Time&lt;/b>
 parameter. (I use a Roland EV-5.) With the expression pedal all the way down,
 &lt;b>Time&lt;/b> is minimized and you get a thick chorus. (You can reduce the &lt;b>Wow
 &amp;amp; Flutter&lt;/b> and/or the &lt;b>Mix&lt;/b> to make it less thick.) Use the
 &lt;b>Tap&lt;/b> button to set the tempo or ease forward on the expression pedal, and
 it gradually becomes a wow-and-flutter-y echo.
&lt;/p>

&lt;p>Here’s an audio sample. I first play the part dry, then again with El
 Capistan doin’ its full-on warble. Then I increase the &lt;b>Time&lt;/b> and turn it
 into an echo. Note space-cadet pitch shifting, too. (If you hear a little
 distortion, that’s because I have my MXR Sugar Drive on all the time, set to
 barely distort when my volume pedal is on max. Continuous sounds!)&lt;/p>

&lt;audio controls>
 &lt;source src="warble.m4a" />
&lt;/audio></description><author>Chris Palmer</author><guid>2020/04/18/capistan/index.html</guid><pubDate>Sat, 18 Apr 2020 00:00:00 +0000</pubDate></item><item><title>The What The Fuck Factor</title><link>https://noncombatant.org/2020/02/26/wtff/index.content</link><description>&lt;h1>The What The Fuck Factor&lt;/h1>

&lt;p>&lt;time>26 February 2020&lt;/time>&lt;/p>

&lt;p>In an interview with Jesse Gress, musician &lt;a
href="https://books.google.com/books?id=XtxJJLYqlUIC&amp;pg=PA97&amp;lpg=PA97&amp;dq=vernon+reid+what+the+fuck+factor&amp;source=bl&amp;ots=Hvh0UUPX6p&amp;sig=ACfU3U0QLeqjMEqhS0YYJr-2E_OiFAEw1w&amp;hl=en&amp;ppis=_c&amp;sa=X&amp;ved=2ahUKEwicuIGC-NbnAhVSvZ4KHT9gD5oQ6AEwAHoECAoQAQ#v=onepage&amp;q=vernon%20reid%20what%20the%20fuck%20factor&amp;f=false">Vernon
Reid described what he calls the What The Fuck Factor&lt;/a>:&lt;/p>

&lt;blockquote>

&lt;p>Maybe the WTFF springs from a magic combination of innovation, intuition, and
passion. “I’m always attracted to ‘feel’ sorts of things,” muses Reid, “but when
I hear a player who’s really accomplished technically &lt;i>and&lt;/i> who moves me
emotionally, that’s the greatest: Pat Martino, Allan Holdsworth, George Benson.
Or &lt;a
href="https://www.guitarplayer.com/technique/joe-diorios-intervallic-designs">Joe
Diorio — his book &lt;i>Intervallic Designs&lt;/i>&lt;/a> changed my life. They’re all
very angular, mathematically precise players, but there’s something there for me
that’s very warm. I don’t know what it is exactly; maybe a real sense of moral
commitment and love. After all, love has angles.”&lt;/p>

&lt;/blockquote></description><author>Chris Palmer</author><guid>2020/02/26/wtff/index.html</guid><pubDate>Wed, 26 Feb 2020 00:00:00 +0000</pubDate></item><item><title>Recoverability</title><link>https://noncombatant.org/2019/08/24/recoverability/index.content</link><description>&lt;h1>Recoverability&lt;/h1>

&lt;p>&lt;time>24 August 2019&lt;/time>&lt;/p>

&lt;aside>
 &lt;p>Update 25 Aug: Removed 2 paragraphs that made more sense in an older
 draft than in the post as finally published.&lt;/p>
&lt;/aside>

&lt;div id="toc">&lt;/div>

&lt;p>&lt;i>Recoverability&lt;/i> is my word for a desirable computer safety property:
 The ability to fully assert ownership and control over the machine and all its
 operations. (This includes the ability to fully &lt;i>relinquish&lt;/i> control of the
 machine, too.)&lt;/p>

&lt;p>Recoverability is crucial in many everyday situations:&lt;/p>

&lt;ul>

 &lt;li>When the machine changes ownership (new and used purchases, gifts, loaner
 machines from the help desk, et c.).&lt;/li>

 &lt;li>When decommissioning the machine, you want to ensure that the machine is
 entirely clean of your data — including sensitive documents and files, but also
 access tokens and credentials.&lt;/li>

 &lt;li>When borrowing the computer (from a friend, at the copy shop, at the public
 library, et c.).&lt;/li>

 &lt;li>After an attacker has compromised the machine.&lt;/li>

 &lt;li>When people (e.g. family members, roommates) share a computer or phone.
 (This scenario can involve hostility, e.g. intimate partner surveillance and
 abuse. We have to adopt and work to solve for this threat model!)&lt;/li>

&lt;/ul>

&lt;p>You can see that recoverability really is an everyday problem, for everyone,
 when you consider how many kinds of devices require recoverability. A
 sampling:&lt;/p>

&lt;ul>

 &lt;li>traditional computers: servers, desktops, laptops&lt;/li>

 &lt;li>phones&lt;/li>

 &lt;li>kiosk and point-of-sale computers&lt;/li>

 &lt;li>printers, scanners, fax machines&lt;/li>

 &lt;li>cars (&lt;a
 href="https://www.usatoday.com/story/money/cars/2018/01/30/car-renters-beware-bluetooth-use-can-reveal-your-private-data/1080225001/">ever
 found someone else’s contacts in your rental?&lt;/a>)&lt;/li>

 &lt;li>Alexas, Google Homes, Apple HomePods, et c.&lt;/li>

 &lt;li>most kinds of data storage devices (USB drives, SSDs, spinning disks, et
 c.)&lt;/li>

&lt;/ul>

&lt;p>Recoverability is mostly about code integrity, but maintaining data
 confidentiality (usually by ensuring it’s destroyed) is also important.&lt;/p>

&lt;h2>Our Goal&lt;/h2>

&lt;p>Our goal should be to make recoverability and relinquishment first-class,
 well-supported, documented, discoverable &lt;a href="https://eprint.iacr.org/2007/399.pdf">ceremonies&lt;/a> that people
 can
 easily and regularly use. For example, &lt;a href="https://support.apple.com/en-us/HT208244">resetting a digital
 assistant&lt;/a> really should delete all user data storage, and should
 affirmatively reset all system software (including all peripheral firmware!) to
 a known-good state.&lt;/p>

&lt;p>Of course, that’s harder than it sounds. If your SSD’s firmware is
 compromised, it’s probably lying to you about updating the operating system and
 the firmware itself.&lt;/p>

&lt;h2>The Problem&lt;/h2>

&lt;p>In most computing devices, there are tons of places where no-longer-wanted
 data and code can remain, thwarting our ability to recover the device. &lt;a
 href="https://www.malwaretech.com/2015/06/hard-disk-firmware-rootkit-surviving.html">Malware
 might hide in the firmware&lt;/a>. (Many peripherals, including &lt;a
 href="https://mobile.twitter.com/Foone/status/1161421430178766853">keyboards&lt;/a>,
 network interfaces, storage devices, cameras, &lt;a
 href="https://www.theverge.com/2016/10/28/13454052/apple-macbook-pro-touch-bar-apple-watch-features">the
 Mac Touchbar&lt;/a>, and more have updatable firmware.) &lt;a
 href="https://securitywatch.pcmag.com/privacy/320343-how-to-securely-dispose-of-a-printer">Many
 printers and scanners keep a copy of what they’ve printed and scanned&lt;/a> — how
 do you wipe your tax records off your printer before selling it on Craigslist?
 And so on.&lt;/p>

&lt;h2>‘Easy’ Solutions&lt;/h2>

&lt;p>It might seem that we could ease recoverability by designing the system such
 that it is essentially &lt;a href="https://en.wikipedia.org/wiki/W%5EX">W^X&lt;/a>
 — writable data can never become executable code. However, it is very close to
 impossible to achieve this for a variety of reasons. Among others:&lt;/p>

&lt;ul>

 &lt;li>The system might &lt;a href="https://en.wikipedia.org/wiki/Interpreted_language">interpret data as
 code&lt;/a> (this includes configuration files). This is so useful that system
 designers can’t help themselves, or even don’t realize they’re doing it.&lt;/li>

 &lt;li>It means giving up updatability. Is that even worse for safety than poor
 recoverability?&lt;/li>

&lt;/ul>

&lt;p>Perhaps the only real way to achieve W^X is on a pure-ROM system: no writes.
 &lt;a href="https://en.wikipedia.org/wiki/Nintendo_Entertainment_System">As great
 as the NES was&lt;/a>, a system designed on that principle has very limited
 utility. (But more than none! And maybe sufficient for some of the use-cases?)
 Although &lt;a href="https://www.dkoldies.com/blog/-complete-list-of-nintendo-nes-games-with-save-batteries/">NES
 Game Paks eventually got writable RAM&lt;/a>, it was &lt;a
 href="https://en.wikipedia.org/wiki/Volatile_memory">volatile&lt;/a> and hence
 recoverable.
&lt;/p>

&lt;p>That suggests another option: volatile installation. Even if the code is
 writable, as long as the memory is exclusively volatile, the device is
 recoverable. For example, &lt;a href="https://panic.com/blog/the-lightning-digital-av-adapter-surprise/">Apple
 Lightning cables work this way&lt;/a>. (More fun from &lt;a
 href="https://twitter.com/nyan_satan/status/1155148789977636864">Lisa
 Braun&lt;/a>.) &lt;a href="https://wiki.archlinux.org/index.php/Microcode">CPU
 microcode updates can work the same way&lt;/a>.&lt;/p>

&lt;p>We can also achieve a certain degree of recoverability if there are code
 updates, including in non-volatile memory, but all updates are authenticated
 (such as by cryptographic code and keys from ROM or a TPM). This gives us a good
 degree of recoverability until the non-updatable &lt;a
 href="https://www.macrumors.com/2013/06/24/apples-ios-7-lightning-connector-authentication-check-permanently-cracked/">crypto
 is cracked&lt;/a>. (See also &lt;a
 href="https://www.usb.org/sites/default/files/2019-01/USB-IF_USB%20Type-C%20Authentication%20Program%20Press%20Release_FINAL_20181227.pdf">USB-C
 authentication&lt;/a>.)&lt;/p>

&lt;p>For data confidentiality — mainly, rendering data unusable upon
 relinquishment — the only real way is to always write only ciphertext into
 non-volatile memory, then to destroy the key when relinquishing. Modern storage
 technology does not give us a way to be sure that data is deleted. (See e.g. &lt;a
 href="https://www.ontrack.com/blog/2016/10/25/wear-leveling/">wear-leveling&lt;/a>.)
 We can only hope to make it indecipherable.&lt;/p>

&lt;figure>&lt;img src="ios-security-effaceable.png" width="436" height="290" alt="Screenshot of Apple iOS Security Guide: “The Erase All Content and Settings
option in Settings obliterates all of the keys in Effaceable Storage, rendering
all user data on the device cryptographically inaccessible. Therefore, it’s an
ideal way to be sure all personal information is removed from a device before
giving it to somebody else or returning it for service.”" loading="lazy" />
 &lt;figcaption>Effaceable memory for keys, described in the &lt;a
 href="https://www.apple.com/business/docs/site/iOS_Security_Guide.pdf">iOS
 Security Guide&lt;/a> as a recoverability mechanism.&lt;/figcaption>
&lt;/figure>

&lt;p>But all these ‘easy’ mechanisms leave us with a question: do we have to trade
 off updatability for recoverability? Even volatile installation depends on the
 integrity of the installation source (usually your primary operating
 system).&lt;/p>

&lt;h2>The Hardest Case: Compromise&lt;/h2>

&lt;p>What are you actually, really supposed to do to recover your computer after
 it has been compromised?&lt;/p>

&lt;p>Recovering and re-verifying the integrity of all your data and network
 accounts could be the topic of several books. For this post, I just mean the
 computer itself. After a successful attack, is your computer merely &lt;a
 href="https://en.wikipedia.org/wiki/Electronic_waste#Amount_of_electronic_waste_worldwide">e-waste&lt;/a>?&lt;/p>

&lt;!--

This doesn’t really contribute to the narrative; is a bit of a tangent.

&lt;p>If we’re being serious, a skilled attacker can remotely compromise &lt;a
href="https://chromereleases.googleblog.com/2019/07/stable-channel-update-for-desktop.html">a
browser renderer process&lt;/a>, &lt;a
href="https://www.cvedetails.com/vulnerability-list/vendor_id-26/product_id-529/Microsoft-Word.html">a
word processor&lt;/a>, &lt;a href="https://en.wikipedia.org/wiki/Stagefright_(bug)">a
multi-media messaging app&lt;/a>. From there, the attacker can elevate using any
number of local privilege escalation vulnerabilities.&lt;/p>

&lt;p>The older your software is, the more likely it is that the attack tools
necessary to exploit its vulnerabilities will have been commoditized. Over time,
the level of skill necessary to succeed goes down, until finally it’s a
plug-and-play module for &lt;a href="https://www.metasploit.com/">one of many
widely-available ‘testing’ frameworks&lt;/a>.&lt;/p>

-->

&lt;p>Unfortunately, &lt;b>all&lt;/b> your software and forgotten firmware is potentially
 relevant attack surface but also a potential persistence mechanism — breaking
 recoverability. We have to assume the worst in case of actual compromise. But
 depending on the hardware and firmware design, we may not have a way to recover
 all the firmwares. This includes those in the storage devices, which can break
 our ability even to recover the primary OS.&lt;/p>

&lt;p>Thus recoverability is an unsolved privacy, usability, economic, and even
 environmental problem. It’s a fun and important problem for these reasons and
 (especially to me) because solving it requires a holistic, general view of
 computer systems. It’ll never be enough to ‘just’ design a good update protocol,
 or kernel, or UX, or memory subsystem. All those pieces (and more) must fit
 together in a coherent narrative and ceremony that people can observe, believe,
 and rely on every day.&lt;/p>

&lt;hr />

&lt;aside>

 &lt;p>Mara Tam reminded me in conversation that the shared device use case
 demonstrates a particularly acute need for recoverability and relinquishment.
 Any other errors or omissions are mine, of course.&lt;/p>

 &lt;p>Someday I’d like to write at greater length about this use case. My
 colleagues and I have spent significant time chewing on it, and although it’s
 not easy it’s crucial that all platform developers handle it. Not only is it
 possible to do more than nothing, there may be some relatively straightforward
 improvements to be made.&lt;/p>

&lt;/aside></description><author>Chris Palmer</author><guid>2019/08/24/recoverability/index.html</guid><pubDate>Sat, 24 Aug 2019 00:00:00 +0000</pubDate></item><item><title>The State Of Software Security In 2019</title><link>https://noncombatant.org/2019/01/06/state-of-security-2019/index.content</link><description>&lt;h1>The State Of Software Security In 2019&lt;/h1>

&lt;p>&lt;strong>...And What To Do About It&lt;/strong>&lt;/p>

&lt;p>&lt;time>6 January 2019&lt;/time>&lt;/p>

&lt;div id="toc">&lt;/div>

&lt;p>My goal in this post is to skim my observations on the state of software
design and development over the past year, and to try to find a meaningful way
forward for myself for 2019. My perspective is limited by the fact that I have
worked exclusively in client-side software security for the past 7.5 years.
Still, I think there are broad trends visible even to me, and some clear signs
about where we need to go as an industry.&lt;/p>

&lt;p>I hope that this post is useful to a variety of security people: not just
engineers, but also UX designers and researchers, project/product/program
managers, people and business managers, and operations. In any case, all paths
to success require the help of all those kinds of people. This post is even more
of a link-fest than usual; I hope that’s useful.&lt;/p>

&lt;p>The high-order bit in much of the below is complexity. Hardware, software,
platforms, and ecosystems are often way too complex, and a whole lot of our
security, privacy, and abuse problems stem from that.&lt;/p>

&lt;h2>The Good&lt;/h2>

&lt;p>&lt;a href="https://twitter.com/__apf__/status/1072199572628299776">Encrypting
the web is going swimmingly&lt;/a>! Also, &lt;a
href="https://blog.chromium.org/2018/05/evolving-chromes-security-indicators.html">marking
non-secure web origins as non-secure, and marking secure origins as neutral&lt;/a>,
is moving right along. It’s amazing and wonderful that we’ve improved so much so
quickly, and it gives me hope for other huge efforts (see below). Thanks as
always to &lt;a href="https://letsencrypt.org/donate/">Let’s Encrypt&lt;/a>, and to
the other browsers who are moving in a similar direction!&lt;/p>

&lt;p>Although &lt;a href="https://en.wikipedia.org/wiki/Memory_corruption">memory
corruption&lt;/a> vulnerabilities remain prevalent, iOS, Chrome OS, and Chrome are
existence proofs that, with good effort in design (privilege reduction) and
unreasonably high effort in implementation (actually making privilege reduction
work, &lt;a
href="https://github.com/google/oss-fuzz/blob/master/docs/clusterfuzz.md">bug
hunting&lt;/a>, bug fixing, and rapid deployment of bug fixes), it is &lt;strong>just
barely&lt;/strong> possible to significantly raise the cost of exploiting memory
corruption vulnerabilities for projects implemented in unsafe languages. Against
modern targets, exploiting memory corruption is nowhere near as easy as it was
in the 1990s or the 2000s.&lt;/p>

&lt;p>&lt;a href="https://9to5mac.com/2018/01/19/ios-11-adoption-65-percent/">iOS
continues to have excellent update adoption&lt;/a> (&lt;a
href="https://david-smith.org/iosversionstats/">see also&lt;/a>), even though it’s
voluntary — a sign that people perceive the value of the updates. It’s unlikely
people are making their choice on the basis of security per se, of course. But
&lt;a href="https://twitter.com/mattblaze/status/1081384425416470528">security and
privacy are key parts of iOS’ value proposition&lt;/a>, and I do think at least
some customers perceive them.&lt;/p>

&lt;p>&lt;a
href="https://blog.github.com/2018-11-15-state-of-the-octoverse-top-programming-languages/">Memory-safe
programming languages dominate the landscape&lt;/a>. Additionally, the
fastest-growing languages are memory-safe. Some popular languages are even
type-safe. (Some might consider type safety a mere bonus, but to me, &lt;a
href="http://lucacardelli.name/Papers/TypefulProg.pdf">typefulness&lt;/a> is a
crucial building block for reliable and safe software.) There is even good news
in systems software, previously the unchallenged and most undeserved domain of
unsafety: Go is big there, and Rust is boopin’ right along (see e.g. &lt;a
href="https://servo.org/">Servo&lt;/a>, &lt;a
href="https://chromium.googlesource.com/chromiumos/platform/crosvm/">CrOS
VM&lt;/a>, &lt;a href="https://github.com/xi-editor/xi-editor">the Xi editor&lt;/a>, &lt;a
href="https://fuchsia.googlesource.com/docs/+/d4f9b980f18fc6722b06abb693240b29abbbc9fc/rust_quickstart.md">parts
of Fuchsia&lt;/a>). Although we mourn &lt;a
href="https://en.wikipedia.org/wiki/Midori_(operating_system)">Midori&lt;/a>, it
can still teach us &lt;a
href="http://joeduffyblog.com/2015/11/03/blogging-about-midori/">broadly
applicable, deep lessons&lt;/a>. (See especially &lt;a
href="http://joeduffyblog.com/2015/11/03/a-tale-of-three-safeties/">A Tale Of
Three Safeties&lt;/a> and &lt;a
href="http://joeduffyblog.com/2016/02/07/the-error-model/">The Error
Model&lt;/a>.)&lt;/p>

&lt;p>Memory tagging, a new (and &lt;a
href="https://en.wikipedia.org/wiki/Tagged_architecture">old&lt;/a>) feature of
hardware, can help with memory safety problems. &lt;a
href="https://llvm.org/devmtg/2018-10/slides/Serebryany-Stepanov-Tsyrklevich-Memory-Tagging-Slides-LLVM-2018.pdf">People
are working on making it happen on modern systems&lt;/a> (&lt;a
href="https://arxiv.org/pdf/1802.09517.pdf">paper&lt;/a>). I don’t think it’s a
replacement for fixing bugs in as systemic a way as possible (ideally, in the
source language), but it has great potential to increase safety.&lt;/p>

&lt;p>Static checkers — compilers — and dynamic checkers (e.g. &lt;a
href="https://clang.llvm.org/docs/AddressSanitizer.html">Address Sanitizer&lt;/a>
and the rest of the LLVM sanitizers) have advanced very far in the past 20
years. What was once bleeding-edge research now comes for free with
off-the-shelf compilers. This is fantastic! (Start with &lt;code>-Wall
-Werror&lt;/code> in Clang or GCC, but I like to use &lt;code>-Weverything
-Werror&lt;/code>, with a few exceptions like &lt;code>-Wno-padded&lt;/code>.
Really.)&lt;/p>

&lt;p>&lt;a
href="https://blog.chromium.org/2018/10/trustworthy-chrome-extensions-by-default.html">Chrome
is making some structural improvements to the extensions platform&lt;/a>, which
should reduce &lt;a
href="https://www.wired.com/story/chrome-extension-malware/">some of the worst
abuses we see in that ecosystem&lt;/a>.&lt;/p>

&lt;p>Parts of the software industry are having &lt;a
href="https://www.amazon.com/World-Technology-Massey-Lectures-Revised/dp/088784636X">an
ethical and moral awakening&lt;/a>:&lt;/p>

&lt;ul>

&lt;li>&lt;a href="https://www.bbc.com/news/technology-46054202">Google
Walkout&lt;/a>&lt;/li>

&lt;li>&lt;a
href="https://static01.nyt.com/files/2018/technology/googleletter.pdf">Cancel
Maven&lt;/a> (&lt;a href="https://www.armscontrol.org/pressroom/2018-acpoy-winner">see
also&lt;/a>)&lt;/li>

&lt;li>&lt;a
href="https://medium.com/s/powertrip/im-an-amazon-employee-my-company-shouldn-t-sell-facial-recognition-tech-to-police-36b5fde934ac">Against
Amazon Rekognition&lt;/a>&lt;/li>

&lt;li>&lt;a
href="https://www.telegraph.co.uk/technology/2018/10/13/microsoft-workers-protest-bid-build-pentagons-10bn-ai-warfare/">Microsoft
workers protest AI warfare&lt;/a>&lt;/li>

&lt;li>&lt;a href="http://humanetech.com/">Time Well Spent&lt;/a>&lt;/li>

&lt;li>&lt;a
href="https://medium.com/@googlersagainstdragonfly/we-are-google-employees-google-must-drop-dragonfly-4c8a30c5e5eb">Google
Must Drop Dragonfly&lt;/a>&lt;/li>

&lt;/ul>

&lt;p>You don’t have to agree with all those positions to find it good news that
our generation of engineers is growing beyond the “I could build it, so I did;
what are consequences?” mentality. &lt;a
href="https://en.wikipedia.org/wiki/Computer_Professionals_for_Social_Responsibility">Previous
generations had to make very similar choices&lt;/a>.&lt;/p>

&lt;p>(I do happen to agree with all those positions, and I will not work on
machines designed for war or police, nor on Big Brotherly, censored search
engines. And I support the efforts for equality and fair treatment for everyone.
The Walkout was a good day, but it was just a beginning. There’s a long way to
go.)&lt;/p>

&lt;p>The increasing awareness and adoption of &lt;a
href="https://en.wikipedia.org/wiki/Universal_2nd_Factor">Universal 2nd Factor
authentication&lt;/a> is great news. (U2F has been standardized as &lt;a
href="https://www.w3.org/TR/webauthn/">WebAuthn&lt;/a>, which is considerably more
complex than most security people would like. Expect bugs to come of that...)
The high degree of phishing resistance it offers is at least as important as the
protections HTTPS provides. Phishing and account take-over have consistently
been 1 of our biggest problems, and WebAuthn can put a big dent in them. You can
use it now with Google, Facebook, Twitter, Dropbox, login.gov, and others.&lt;/p>

&lt;h2>The Bad&lt;/h2>

&lt;p>C++ continues to be untenably complex and wildly unsafe:&lt;/p>

&lt;ul>

&lt;li>&lt;a href="http://www.stroustrup.com/P0977-remember-the-vasa.pdf">C++’s
creator finds himself on the other side of the community&lt;/a> on the issue of
C++’s growing complexity. Stroustrup correctly identifies C++’s growing
complexity as a potentially fatal risk for the language.&lt;/li>

&lt;li>&lt;a href="https://bugs.llvm.org/show_bug.cgi?id=34729">The new, safe APIs are
not safe&lt;/a>. (“WONTFIX”.)&lt;/li>

&lt;li>&lt;a href="https://blog.regehr.org/archives/213">C and C++ compilers continue
to exploit undefined behavior&lt;/a> — something that should not exist — for the
dubious goal of micro-optimizations. (John Regehr: “A compiler that is very
smart at recognizing and silently destroying Type 3 functions becomes
effectively evil, from the developer’s point of view.”)&lt;/li>

&lt;li>C++ is so complicated that &lt;a
href="https://groups.google.com/a/chromium.org/forum/#!topic/cxx/2UTgWpM5N0c">expert
programmers cannot find a universal way to find the size of a static array&lt;/a>,
other than the classic vanilla C macro. Maybe simple is good, after all? 🤔&lt;/li>

&lt;/ul>

&lt;p>I can’t possibly select and link to a list of the infinite bug reports whose
root causes are memory unsafety. A fun exercise is to skim through a good source
of vulnerability write-ups (&lt;a
href="https://googleprojectzero.blogspot.com/">the Project Zero blog&lt;/a> is one
of my favorites), and count how many of the bugs are even in the application
domain at all.&lt;/p>

&lt;p>(Of course, if you find that there are more memory safety bugs than
application-domain bugs or other bugs, that could just as well be due to the
researchers’ biases. But I think we can all agree that memory corruption bugs
simply should not exist at all, yet are numerous and often exploitable.)&lt;/p>

&lt;p>Designing a language that achieves all of memory safety, high performance,
and good usability remains very hard. The Rust compiler notices and rejects
safety bugs that C and C++ compilers don’t notice/can’t notice/purposefully
accept. 🤪🔨 That is to Rust’s credit, but &lt;a
href="https://rcoh.me/posts/rust-linked-list-basically-impossible/">this
discipline can be extremely difficult to learn&lt;/a>.&lt;/p>

&lt;p>Among the programming language research community’s goals is proving programs
safe. Gradually and increasingly, that work trickles down into real languages
that people can really use to ship real software. &lt;a
href="https://www.imperialviolet.org/2014/09/07/provers.html">The difficulty of
using academic tools&lt;/a> is partly a natural consequence of their small
audience, but some of the difficulty is unavoidable: proof of safety means
&lt;strong>proof&lt;/strong>, that difficult thing that people get PhDs for.
Ultimately, the software engineering community is going to have to commit to
meeting this standard, gradually and increasingly.&lt;/p>

&lt;p>Obviously, 2018 was the year everyone became aware of &lt;a
href="https://meltdownattack.com/">Spectre &amp; Meltdown&lt;/a>, &lt;a
href="https://foreshadowattack.eu/">Foreshadow&lt;/a>, &lt;a
href="https://www.intel.com/content/www/us/en/architecture-and-technology/l1tf.html">L1TF&lt;/a>,
and the idea of micro-architectural &lt;a
href="https://pdfs.semanticscholar.org/2209/42809262c17b6631c0f6536c91aaf7756857.pdf">side-channels
generally&lt;/a>. Shared resources abound, unfortunately. Of course, other
show-stopper security problems (typically due to &lt;a
href="https://people.kth.se/~maguire/DEGREE-PROJECT-REPORTS/100402-Vassilios_Ververis-with-cover.pdf">monstrous
complexity&lt;/a>) have been known for a long time (&lt;a
href="https://www.ssi.gouv.fr/archive/fr/sciences/fichiers/lti/cansecwest2006-duflot.pdf">see
also&lt;/a>, &lt;a
href="https://en.wikipedia.org/wiki/System_Management_Mode#Problems">see
also&lt;/a>). Although those links refer mostly to Intel Architecture systems,
there’s no reason to think that (e.g.) ARM is inherently safer. In particular,
the micro-architectural side-channel problems are the natural result of
designing for maximum performance — which almost every chip designer is trying
to do, because that’s what almost every customer wants.&lt;/p>

&lt;h2>The Ugly&lt;/h2>

&lt;p>Abuse (the malicious use of legitimate functionality) affects more people’s
lives in more ways than does the exploitation of bugs. Although hacking can have
a surprising influence, such as in the form of political fallout or mass data
breaches, the reasons your friends and family are sad are much more prosaic
— and harder to solve:&lt;/p>

&lt;ul>

&lt;li>Phone scams; &lt;a
href="https://en.wikipedia.org/wiki/Technical_support_scam">tech-support
scams&lt;/a>; &lt;a
href="https://medium.com/@nancynakamoto_11949/the-princess-bride-and-the-mystery-of-the-tether-business-model-d76a08c94734">cryptocurrency
scams&lt;/a> and &lt;a
href="https://www.howtogeek.com/359129/don%E2%80%99t-fall-for-the-new-cryptoblackmail-scam-here%E2%80%99s-how-to-protect-yourself/">extortion&lt;/a>.&lt;/li>

&lt;li>Malware, crapware, or ‘unwanted software’ that people purposefully install.
(These are often listed in legitimate stores, shipped with the device drivers of
hardware, or bundled with marginalware.)&lt;/li>

&lt;li>The scourge of &lt;a
href="https://motherboard.vice.com/en_us/article/53vm7n/inside-stalkerware-surveillance-market-flexispy-retina-x">spouseware
and stalkerware&lt;/a>.&lt;/li>

&lt;/ul>

&lt;p>&lt;a
href="https://www.theguardian.com/technology/2018/nov/05/energy-cost-of-mining-bitcoin-more-than-twice-that-of-copper-or-gold">Proof-of-work
continues not to work&lt;/a> 😵, &lt;a
href="https://www.cl.cam.ac.uk/~rnc1/proofwork.pdf">as foretold by prophecy&lt;/a>
😑. The coming decades are going to bring increasing climate, uh, ‘challenges’,
and all computing systems are going to have to prove their worth relative to the
sum of &lt;strong>all&lt;/strong> their costs — including carbon and e-waste. We won’t
be able to laugh those off as externalities any longer. Proof-of-work systems
will continue to be unable to show sufficient value for the cost, and may even
be the wedge for regulation (if they don’t starve themselves or crash
first).&lt;/p>

&lt;p>&lt;a
href="https://infrequently.org/2018/09/the-developer-experience-bait-and-switch/">The
web performance crisis&lt;/a> (see also &lt;a
href="https://idlewords.com/talks/website_obesity.htm">a hotter take&lt;/a> 🥵) is a
similar situation: hugely wasteful, but not (yet...?) self-limiting. In the past
I’ve had to argue that &lt;a
href="https://conferences.oreilly.com/web2expo/webexsf2009/public/schedule/speaker/1016">security
is affordable&lt;/a> even given performance constraints. It was possible to get
both performance and security then, by reducing obvious bloat and enabling
less-obvious optimizations, and it’s possible now. The root cause then was the
same as it is now: too many developers don’t use the same client systems as
their userbase does, and they don’t know what network, memory, and CPU costs
they are incurring. Previously, those costs were hard to see. Now, they are
definitely not: every browser has a very good Dev Tools console, and there is no
excuse for not using it.&lt;/p>

&lt;p>Dependency slurping systems like NPM, CPAN, &lt;code>go get&lt;/code>, and so on
continue to freak me out. They might potentially be more dangerous than manual
dependency management, despite the huge risks of that practice, precisely
because they make it ‘easy’ to grow your project’s dependency graph — and hence
the number of individuals and organizations that you implicitly trust. (And &lt;a
href="https://www.theregister.co.uk/2018/11/26/npm_repo_bitcoin_stealer/">their
trustworthiness can suddenly change for the worse&lt;/a>.) When there are
significant gaps in a language’s standard library, third-party developers will
eagerly fill those gaps with new dependencies for you to (not always knowingly)
inherit. There is &lt;a
href="https://github.com/tc39/proposal-javascript-standard-library/issues/19">an
effort underway to fill gaps in JavaScript’s standard library&lt;/a>, which I
strongly support for this reason.&lt;/p>

&lt;p>Social media continues to amplify the worst in people, and &lt;a
href="https://www.nytimes.com/2018/11/29/technology/george-soros-facebook-sheryl-sandberg.html">some
executives of social media companies continue to be part of the problem&lt;/a>.
Dealing with the toxicity and abuse of social media is a long-term,
multi-pronged effort, but 1 thing that we can immediately do as engineers, PMs,
designers, and managers is to push back on ‘engagement’ as the primary or only
metric for ‘success’. It’s game-able and heavily gamed, and does not remotely
capture the real experiences of real people on social media. People’s
experiences are often &lt;a
href="http://seriouspony.com/trouble-at-the-koolaid-point/">profoundly
awful&lt;/a>, and we as software developers are responsible for dealing with the
consequences of what we’ve built. Are we empowering people to learn and grow, or
are we amplifying the fuckery of Nazis and Chekists? Clinging to &lt;a
href="https://www.eff.org/deeplinks/2018/04/platform-censorship-wont-fix-internet">a
simplistic view of free speech&lt;/a> is not going to get us out of having to
answer that question.&lt;/p>

&lt;h2>The Future&lt;/h2>

&lt;p>Unfortunately for me, I want to work on all of these problems. I had a good
fun time in 2018 working on defense at a low-level (&lt;a
href="/2018/07/19/application-principals/">just one of many adventures&lt;/a>), and
there’s still plenty of work to be done there. (There’s lots of ambient
privilege still crying out to be reduced!) It has been rewarding to play my
small part in helping get HTTPS where it needs to be.&lt;/p>

&lt;p>And unfortunately, the problems that I find the most vexing — the abuse
category generally — are not in my area of greatest expertise. My heart is
really in the language problem: meaningful interfaces, ergonomic and safe
libraries, memory safety, and type safety. But it’s the abuse that makes my
heart sick.&lt;/p>

&lt;p>Still, I see people really shipping software improvements that seemed
impossible 20 or 10 or 5 years ago. We really are making progress. Here’s what I
want to see in 2019:&lt;/p>

&lt;ul>

&lt;li>Throwing away the idea of using ‘engagement’ as the sole or primary
metric.&lt;/li>

&lt;li>Socializing policy thinking in the engineering community. It’s time to put
on our grown-up clothes. The stuff we do matters (otherwise we wouldn’t do it,
right?), and that means we need to think about and deal with the
consequences.&lt;/li>

&lt;li>Affordances to improve web performance across the board: a larger JavaScript
standard library; performance improvements in frameworks; improvements in
tooling; client-side interventions and budgets.&lt;/li>

&lt;li>Eroding the idea that memory-unsafety is acceptable, and shipping more
software in safe languages that would previously have been written in an unsafe
language. This includes not so much straight-up rewrites of existing
applications (&lt;a
href="https://www.joelonsoftware.com/2000/04/06/things-you-should-never-do-part-i/">which
Joel says is bad&lt;/a>); mostly, I see piecemeal, in-place rewrites of components
(like Servo), and also new applications in well-established categories (like Xi
and CrosVM). New applications also give us a chance to re-think old designs, as
Xi notably does (with its cross-platform, client/server, multiple-front-end
design).&lt;/li>

&lt;li>Socializing the value of simplicity, and throwing away complexity, at all
levels: UX, languages, libraries, frameworks. In particular, nobody should start
a new project in C++.&lt;/li>

&lt;/ul>

&lt;p>Smart people are already hard at work on all these things! We can get the
industry closer to where it needs to be, and serve people better. Tomorrow is
Monday...&lt;/p>

&lt;aside>&lt;p>Thanks to Alex Gaynor, Emily Schechter, Emily Stark, Eric Mill, Kate
Conger, Stephan Somogyi, and Tom Ptacek for feedback and encouragement. Errors,
omissions, and confusions are still mine, of course. You might also like &lt;a
href="https://alexgaynor.net/2019/jan/06/security-wish-list-2019/">Alex’
security wishlist for 2019&lt;/a>.&lt;/p>&lt;/aside></description><author>Chris Palmer</author><guid>2019/01/06/state-of-security-2019/index.html</guid><pubDate>Sun, 06 Jan 2019 00:00:00 +0000</pubDate></item><item><title>Pictures From Paris And Amsterdam</title><link>https://noncombatant.org/2018/08/13/paris-2018-07/index.content</link><description>&lt;h1>Pictures From Paris And Amsterdam&lt;/h1>

&lt;p>&lt;time>13 August 2018&lt;/time>&lt;/p>

&lt;p>This July I went to Paris and Amsterdam for a bit of work and a bit of
vacation. In Amsterdam, I presented at &lt;a
href="/2018/07/19/application-principals/">a workshop for security engineers and
academics&lt;/a>, and in Paris my manager and I met up with friendly Chrome people
there who do work adjacent to ours.&lt;/p>

&lt;p>I didn’t do anything but the workshop/conference in Amsterdam, unfortunately.
I’ve loved Amsterdam in the past and should have scheduled more time there. It’s
a chill town.&lt;/p>

&lt;p>In Paris, I mostly walked around and ate food in neighborhoods I hadn’t
visited in previous trips. Here are some pictures!&lt;/p>

&lt;p>(You can get full-size versions of each picture by clicking on the
picture.)&lt;/p>

&lt;figure>&lt;a href="original/3033.jpg">&lt;img width="400" height="300" src="3033.jpg"
alt="Outbound airplane food #1" loading="lazy"/>&lt;/a>&lt;figcaption>I was very
fortunate, and got to fly business class. Entrée: raw salmon with herbs, some
kind of pâté, bread, salad, wine.&lt;/figcaption>&lt;/figure>

&lt;figure>&lt;a href="original/3035.jpg">&lt;img width="400" height="300" src="3035.jpg"
alt="Outbound airplane food #2" loading="lazy"/>&lt;/a>&lt;figcaption>Main plate:
chicken, mashed potatoes, cheese.&lt;/figcaption>&lt;/figure>

&lt;figure>&lt;a href="original/3036.jpg">&lt;img width="400" height="400" src="3036.jpg"
alt="Outbound airplane foor #3" loading="lazy"/>&lt;/a>&lt;figcaption>Dessert:
confection squares, mint tea.&lt;/figcaption>&lt;/figure>

&lt;figure>&lt;a href="original/3039.jpg">&lt;img width="400" height="300" src="3039.jpg"
alt="Outbound airplne food #4" loading="lazy"/>&lt;/a>&lt;figcaption>Breakfast:
omelette, bacon, potatoes, coffee, yogurt, fruit.&lt;/figcaption>&lt;/figure>

&lt;figure>&lt;a href="original/3047.jpg">&lt;img width="400" height="400" src="3047.jpg"
alt="Address plate: “I’m Feeling Lucky”" loading="lazy"/>&lt;/a>&lt;figcaption>The
Google Paris office entrance.&lt;/figcaption>&lt;/figure>

&lt;figure>&lt;a href="original/3049.jpg">&lt;img width="400" height="399" src="3049.jpg"
alt="An overpacked brasserie" loading="lazy"/>&lt;/a>&lt;figcaption>I arrived on the
Sunday that France won the World Cup. Every brasserie, bistro, bar, and coffee
shop was over-full of people eyeing the TV.&lt;/figcaption>&lt;/figure>

&lt;figure>&lt;a href="original/3050.jpg">&lt;img width="400" height="400" src="3050.jpg"
alt="Belgian waffle pop-up store" loading="lazy"/>&lt;/a>&lt;figcaption>Down the
street from my hotel. I swore I’d get one, but literally
forgot!&lt;/figcaption>&lt;/figure>

&lt;figure>&lt;a href="original/3051.jpg">&lt;img width="400" height="400" src="3051.jpg"
alt="View of a bistro" loading="lazy"/>&lt;/a>&lt;figcaption>While I was eating dinner
a relatively less-animated pizza place, the post-World Cup celebration was
heating up. And the weather was incredibly hot. Not pictured: people laying on
the hood of a taxi while it drove backwards down this 1-way street; person
dancing on top of a dumpster.&lt;/figcaption>&lt;/figure>

&lt;figure>&lt;a href="original/3053.jpg">&lt;img width="400" height="400" src="3053.jpg"
alt="Hotel breakfast" loading="lazy"/>&lt;/a>&lt;figcaption>The hotel breakfast was
the same every day, and very bad. The texture of the scrambled eggs was unholy,
and the beans were always cold. Good bread though.&lt;/figcaption>&lt;/figure>

&lt;figure>&lt;a href="original/3054.jpg">&lt;img width="400" height="400" src="3054.jpg"
alt="Pâtisserie" loading="lazy"/>&lt;/a>&lt;figcaption>Down the street from my hotel,
this fantastic pâtisserie. I got at least 1 thing here every day, until they
closed for vacation.&lt;/figcaption>&lt;/figure>

&lt;figure>&lt;a href="original/3055.jpg">&lt;img width="400" height="300" src="3055.jpg"
alt="The Google campus courtyard" loading="lazy"/>&lt;/a>&lt;figcaption>Many doors on
Paris streets open into courtyards and building complexes like this. The Google
office ‘campus’.&lt;/figcaption>&lt;/figure>

&lt;figure>&lt;a href="original/3059.jpg">&lt;img width="400" height="400" src="3059.jpg"
alt="An ourdoor pathway" loading="lazy"/>&lt;/a>&lt;figcaption>The entrance to my
hotel.&lt;/figcaption>&lt;/figure>

&lt;figure>&lt;a href="original/3060.jpg">&lt;img width="400" height="400" src="3060.jpg"
alt="Philosophy and psychoanalysis books in a bookstore window"
loading="lazy"/>&lt;/a>&lt;figcaption>Interesting-looking bookstore, but closed for
vacation.&lt;/figcaption>&lt;/figure>

&lt;figure>&lt;a href="original/3061.jpg">&lt;img width="400" height="300" src="3061.jpg"
alt="Evening traffic in a traffic circle" loading="lazy"/>&lt;/a>&lt;figcaption>A nice
vibe in the evening.&lt;/figcaption>&lt;/figure>

&lt;figure>&lt;a href="original/3062.jpg">&lt;img width="400" height="400" src="3062.jpg"
alt="A sign on a door saying « Défense d’uriner »"
loading="lazy"/>&lt;/a>&lt;figcaption>At Gare du Nord, this sign (“No urinating”) has
been ignored.&lt;/figcaption>&lt;/figure>

&lt;figure>&lt;a href="original/3067.jpg">&lt;img width="400" height="400" src="3067.jpg"
alt="Inside Gare du Nord" loading="lazy"/>&lt;/a>&lt;figcaption>Inside Gare du Nord,
waiting for my train to Amsterdam.&lt;/figcaption>&lt;/figure>

&lt;figure>&lt;a href="original/3069.jpg">&lt;img width="400" height="400" src="3069.jpg"
alt="Outside Amsterdam Centraal station" loading="lazy"/>&lt;/a>&lt;figcaption>Arrived
at Amsterdam Centraal station, going in circles trying to find the tram to my
hotel. It was marginally less burningly hot in Amsterdam.&lt;/figcaption>&lt;/figure>

&lt;figure>&lt;a href="original/3070.jpg">&lt;img width="400" height="300" src="3070.jpg"
alt="View of a highway and a river" loading="lazy"/>&lt;/a>&lt;figcaption>View from my
hotel room in Amsterdam.&lt;/figcaption>&lt;/figure>

&lt;figure>&lt;a href="original/3073.jpg">&lt;img width="400" height="300" src="3073.jpg"
alt="Bimhuis and Muziekgebouw" loading="lazy"/>&lt;/a>&lt;figcaption>View from outside
my hotel.&lt;/figcaption>&lt;/figure>

&lt;figure>&lt;a href="original/3075.jpg">&lt;img width="400" height="400" src="3075.jpg"
alt="Picture of a traffic light Walk button"
loading="lazy"/>&lt;/a>&lt;figcaption>Instructions on how to push the Walk button in
Amsterdam.&lt;/figcaption>&lt;/figure>

&lt;figure>&lt;a href="original/3081.jpg">&lt;img width="400" height="400" src="3081.jpg"
alt="Classic-style « Métropolitain » sign at a Métro station entrance"
loading="lazy"/>&lt;/a>&lt;figcaption>Back in Paris, riding on the
Métroooooo.&lt;/figcaption>&lt;/figure>

&lt;figure>&lt;a href="original/3084.jpg">&lt;img width="400" height="300" src="3084.jpg"
alt="More Paris traffic" loading="lazy"/>&lt;/a>&lt;figcaption>More Paris
traffic.&lt;/figcaption>&lt;/figure>

&lt;figure>&lt;a href="original/3085.jpg">&lt;img width="400" height="400" src="3085.jpg"
alt="2 lutherie shops at street level, below apartments"
loading="lazy"/>&lt;/a>&lt;figcaption>Every building in this neighborhood had at least
1 lutherie shop, piano store, or sheet music store.&lt;/figcaption>&lt;/figure>

&lt;figure>&lt;a href="original/3086.jpg">&lt;img width="400" height="400" src="3086.jpg"
alt="Restaurant: O’Crêpe" loading="lazy"/>&lt;/a>&lt;figcaption>...they’re
closed.&lt;/figcaption>&lt;/figure>

&lt;figure>&lt;a href="original/3087.jpg">&lt;img width="400" height="400" src="3087.jpg"
alt="A community library cubby" loading="lazy"/>&lt;/a>&lt;figcaption>Nice to see they
have community libraries in Paris, too!&lt;/figcaption>&lt;/figure>

&lt;figure>&lt;a href="original/3088.jpg">&lt;img width="400" height="400" src="3088.jpg"
alt="Le Moulin Rouge theater" loading="lazy"/>&lt;/a>&lt;figcaption>Le Moulin
Rouge.&lt;/figcaption>&lt;/figure>

&lt;figure>&lt;a href="original/3089.jpg">&lt;img width="400" height="400" src="3089.jpg"
alt="A breakfast of hot chocolate, orange juice, and a croissant"
loading="lazy"/>&lt;/a>&lt;figcaption>A proper breakfast snack.&lt;/figcaption>&lt;/figure>

&lt;figure>&lt;a href="original/3090.jpg">&lt;img width="400" height="400" src="3090.jpg"
alt="A graffiti sticker: « C’est le bon endroit et c’est le bon moment »"
loading="lazy"/>&lt;/a>&lt;figcaption>“This is the right place, and the right time.”
But they don’t say for what. 🤔&lt;/figcaption>&lt;/figure>

&lt;figure>&lt;a href="original/3092.jpg">&lt;img width="400" height="400" src="3092.jpg"
alt="Brasserie lunch" loading="lazy"/>&lt;/a>&lt;figcaption>Fantastic ham sandwich on
perfect toast, with perfect fries.&lt;/figcaption>&lt;/figure>

&lt;figure>&lt;a href="original/3094.jpg">&lt;img width="400" height="400" src="3094.jpg"
alt="Sign alerting pâtisserie customers that they are closing for vacation"
loading="lazy"/>&lt;/a>&lt;figcaption>When the pâtisserie closed for vacation, it was
a sad day.&lt;/figcaption>&lt;/figure>

&lt;figure>&lt;a href="original/3096.jpg">&lt;img width="400" height="400" src="3096.jpg"
alt="A logo on the wall of a building: sp ligature"
loading="lazy"/>&lt;/a>&lt;figcaption>I just like this shape.&lt;/figcaption>&lt;/figure>

&lt;figure>&lt;a href="original/3097.jpg">&lt;img width="400" height="400" src="3097.jpg"
alt="Street sign: P, with a bicycle. Graffiti makes it say « Paix »"
loading="lazy"/>&lt;/a>&lt;figcaption>Peace through bicycles.&lt;/figcaption>&lt;/figure>

&lt;figure>&lt;a href="original/3099.jpg">&lt;img width="400" height="400" src="3099.jpg"
alt="Coffee shop named Braun Notes" loading="lazy"/>&lt;/a>&lt;figcaption>A coffee
shop. 🤨&lt;/figcaption>&lt;/figure>

&lt;figure>&lt;a href="original/3101.jpg">&lt;img width="400" height="400" src="3101.jpg"
alt="Café Jules: « Le hot dog à la français ! »"
loading="lazy"/>&lt;/a>&lt;figcaption>I did not try French hot
dogs.&lt;/figcaption>&lt;/figure>

&lt;figure>&lt;a href="original/3102.jpg">&lt;img width="400" height="300" src="3102.jpg"
alt="View of the Seine" loading="lazy"/>&lt;/a>&lt;figcaption>The river
Seine.&lt;/figcaption>&lt;/figure>

&lt;figure>&lt;a href="original/3103.jpg">&lt;img width="400" height="400" src="3103.jpg"
alt="Dense buildings" loading="lazy"/>&lt;/a>&lt;figcaption>On the bank of the
Seine.&lt;/figcaption>&lt;/figure>

&lt;figure>&lt;a href="original/3106.jpg">&lt;img width="400" height="400" src="3106.jpg"
alt="Placard: « 1643 : Demeure de Philippe de Champaigne, Peintre et valet de
chambre de la Reine Mère »" loading="lazy"/>&lt;/a>&lt;figcaption>Placard on the front
of one of the entrances.&lt;/figcaption>&lt;/figure>

&lt;figure>&lt;a href="original/3107.jpg">&lt;img width="400" height="400" src="3107.jpg"
alt="Cappuccino and croissant" loading="lazy"/>&lt;/a>&lt;figcaption>Fantastic coffee
on the other side of the Seine.&lt;/figcaption>&lt;/figure>

&lt;figure>&lt;a href="original/3108.jpg">&lt;img width="400" height="400" src="3108.jpg"
alt="Croque monsieur" loading="lazy"/>&lt;/a>&lt;figcaption>More pastry
pictures.&lt;/figcaption>&lt;/figure>

&lt;figure>&lt;a href="original/3109.jpg">&lt;img width="400" height="400" src="3109.jpg"
alt="Street art of a protester wearing a helmet and other gear"
loading="lazy"/>&lt;/a>&lt;figcaption>Street art near the jazz venue that I literally
could not find, presumably nestled in among roughly 9,246 tiny
restaurants.&lt;/figcaption>&lt;/figure>

&lt;figure>&lt;a href="original/3110.jpg">&lt;img width="400" height="400" src="3110.jpg"
alt="Hamburger and fries" loading="lazy"/>&lt;/a>&lt;figcaption>Extremely well-crafted
yet completely incorrect hamburger. Strangely tall and
steak-like.&lt;/figcaption>&lt;/figure>

&lt;figure>&lt;a href="original/3114.jpg">&lt;img width="400" height="400" src="3114.jpg"
alt="Storefront: « Les Productions du GOLEM »" loading="lazy"/>&lt;/a>&lt;figcaption>I
was not able to see the golem, or its productions. Alas.&lt;/figcaption>&lt;/figure>

&lt;figure>&lt;a href="original/3115.jpg">&lt;img width="400" height="400" src="3115.jpg"
alt="Storefront: « Plus de Bruit »" loading="lazy"/>&lt;/a>&lt;figcaption>“More
Noise”, buying and selling records, CDs, and comic books.&lt;/figcaption>&lt;/figure>

&lt;figure>&lt;a href="original/3116.jpg">&lt;img width="400" height="400" src="3116.jpg"
alt="Salted caramel ice cream" loading="lazy"/>&lt;/a>&lt;figcaption>Ice cream in
Montmartre. A suggestion from one of our colleagues. This place also had great
beer, which we chugged as appropriate in that heat.&lt;/figcaption>&lt;/figure>

&lt;figure>&lt;a href="original/3117.jpg">&lt;img width="400" height="400" src="3117.jpg"
alt="Sunset" loading="lazy"/>&lt;/a>&lt;figcaption>Sunset in
Montmartre.&lt;/figcaption>&lt;/figure>

&lt;figure>&lt;a href="original/3120.jpg">&lt;img width="400" height="400" src="3120.jpg"
alt="Restaurant « Blabla »"
loading="lazy"/>&lt;/a>&lt;figcaption>Blabla!&lt;/figcaption>&lt;/figure>

&lt;figure>&lt;a href="original/3122.jpg">&lt;img width="400" height="400" src="3122.jpg"
alt="Restaurant: Banh Mi &amp; You" loading="lazy"/>&lt;/a>&lt;figcaption>I
mean...&lt;/figcaption>&lt;/figure>

&lt;figure>&lt;a href="original/3124.jpg">&lt;img width="400" height="400" src="3124.jpg"
alt="Electric motor scooter, chrome" loading="lazy"/>&lt;/a>&lt;figcaption>This
electric scooter was right outside a shop selling more in different
colors.&lt;/figcaption>&lt;/figure>

&lt;figure>&lt;a href="original/3126.jpg">&lt;img width="400" height="400" src="3126.jpg"
alt="Pasta lunch with prosciutto" loading="lazy"/>&lt;/a>&lt;figcaption>The sauce on
this pasta (underneath the prosciutto) was perfect.&lt;/figcaption>&lt;/figure>

&lt;figure>&lt;a href="original/3127.jpg">&lt;img width="400" height="400" src="3127.jpg"
alt="A large caffè latte" loading="lazy"/>&lt;/a>&lt;figcaption>This is what I got
when I ordered a cappuccino. It was good though.&lt;/figcaption>&lt;/figure>

&lt;figure>&lt;a href="original/3130.jpg">&lt;img width="400" height="400" src="3130.jpg"
alt="Chicken in a pocket bread" loading="lazy"/>&lt;/a>&lt;figcaption>Chicken,
excellent fries, and soda.&lt;/figcaption>&lt;/figure>

&lt;figure>&lt;a href="original/3132.jpg">&lt;img width="400" height="400" src="3132.jpg"
alt="Statue of Athena" loading="lazy"/>&lt;/a>&lt;figcaption>Athena doing a victory
dance.&lt;/figcaption>&lt;/figure>

&lt;figure>&lt;a href="original/3133.jpg">&lt;img width="400" height="400" src="3133.jpg"
alt="The Eiffel Tower, from afar" loading="lazy"/>&lt;/a>&lt;figcaption>The Eiffel
Tower, on an unreasonably hot and humid day.&lt;/figcaption>&lt;/figure>

&lt;figure>&lt;a href="original/3135.jpg">&lt;img width="400" height="400" src="3135.jpg"
alt="Inside the Musée d’Orsay" loading="lazy"/>&lt;/a>&lt;figcaption>Inside the Musée
d’Orsay, a museum built inside a former train station.&lt;/figcaption>&lt;/figure>

&lt;figure>&lt;a href="original/3136.jpg">&lt;img width="400" height="400" src="3136.jpg"
alt="An impressionist painting by Paul Signac, « Femmes au puits »"
loading="lazy"/>&lt;/a>&lt;figcaption>These paintings were lit to glow, but I think
they would have even without the light treatment.&lt;/figcaption>&lt;/figure>

&lt;figure>&lt;a href="original/3137.jpg">&lt;img width="400" height="400" src="3137.jpg"
alt="« Pierrot Pornographe »" loading="lazy"/>&lt;/a>&lt;figcaption>A program from the
Black Cat Theater.&lt;/figcaption>&lt;/figure>

&lt;figure>&lt;a href="original/3138.jpg">&lt;img width="400" height="400" src="3138.jpg"
alt="Cover of a program" loading="lazy"/>&lt;/a>&lt;figcaption>Another program
cover.&lt;/figcaption>&lt;/figure>

&lt;figure>&lt;a href="original/3141.jpg">&lt;img width="400" height="400" src="3141.jpg"
alt="A long shot of the interior of the Musée d’Orsay"
loading="lazy"/>&lt;/a>&lt;figcaption>Sculptures in the Musée
d’Orsay.&lt;/figcaption>&lt;/figure>

&lt;figure>&lt;a href="original/3145.jpg">&lt;img width="400" height="400" src="3145.jpg"
alt="Restaurant: « L’Epée de blé »" loading="lazy"/>&lt;/a>&lt;figcaption>Good bread
is a big deal.&lt;/figcaption>&lt;/figure>

&lt;figure>&lt;a href="original/3146.jpg">&lt;img width="400" height="400" src="3146.jpg"
alt="Sign on a building: « Spectre »" loading="lazy"/>&lt;/a>&lt;figcaption>&lt;a
href="https://spectreattack.com/">Technically&lt;/a>, the reason I was
there.&lt;/figcaption>&lt;/figure>

&lt;figure>&lt;a href="original/3147.jpg">&lt;img width="400" height="400" src="3147.jpg"
alt="Flower buds from trees on the ground after rain"
loading="lazy"/>&lt;/a>&lt;figcaption>It finally rained, and the heat broke. The
ground was covered in these buds.&lt;/figcaption>&lt;/figure>

&lt;figure>&lt;a href="original/3148.jpg">&lt;img width="400" height="400" src="3148.jpg"
alt="Cheese and charcuterie plates" loading="lazy"/>&lt;/a>&lt;figcaption>Cheese and
charcuterie, with a colleague who sits next to me in SF but who was (unknown to
me) in Paris, and a friendly Parisian whom I know from security industry stuff.
At a hipster beer place suggested by another security friend on Twitter.
Everything was v tasty.&lt;/figcaption>&lt;/figure>

&lt;figure>&lt;a href="original/3152.jpg">&lt;img width="400" height="400" src="3152.jpg"
alt="Street sign: « Place Henri Bergson »" loading="lazy"/>&lt;/a>&lt;figcaption>&lt;a
href="https://en.wikipedia.org/wiki/Henri_Bergson">Henri
Bergson&lt;/a>.&lt;/figcaption>&lt;/figure>

&lt;figure>&lt;a href="original/3154.jpg">&lt;img width="400" height="400" src="3154.jpg"
alt="Elegant graffiti of a smoker, in an alcove where smokers hang out"
loading="lazy"/>&lt;/a>&lt;figcaption>Fumeur.&lt;/figcaption>&lt;/figure>

&lt;figure>&lt;a href="original/3155.jpg">&lt;img width="400" height="400" src="3155.jpg"
alt="Intersection" loading="lazy"/>&lt;/a>&lt;figcaption>Walking to l’Arc de
triomphe.&lt;/figcaption>&lt;/figure>

&lt;figure>&lt;a href="original/3156.jpg">&lt;img width="400" height="400" src="3156.jpg"
alt="Croque monsieur and fries" loading="lazy"/>&lt;/a>&lt;figcaption>A slightly
strange but tasty croque monsieur.&lt;/figcaption>&lt;/figure>

&lt;figure>&lt;a href="original/3159.jpg">&lt;img width="400" height="400" src="3159.jpg"
alt="l’Arc de triomphe" loading="lazy"/>&lt;/a>&lt;figcaption>Long shot of the
Arch.&lt;/figcaption>&lt;/figure>

&lt;figure>&lt;a href="original/3162.jpg">&lt;img width="400" height="400" src="3162.jpg"
alt="Salad with cheese and prosciutto" loading="lazy"/>&lt;/a>&lt;figcaption>For some
reason, I ate a lot of prosciutto on this trip. This was dinner on my last
evening before coming home.&lt;/figcaption>&lt;/figure></description><author>Chris Palmer</author><guid>2018/08/13/paris-2018-07/index.html</guid><pubDate>Mon, 13 Aug 2018 00:00:00 +0000</pubDate></item><item><title>Isolating Application-Defined Principals</title><link>https://noncombatant.org/2018/07/19/application-principals/index.content</link><description>&lt;h1>Isolating Application-Defined Principals&lt;/h1>

&lt;p>&lt;time>19 July 2018&lt;/time>&lt;/p>

&lt;p>I just published &lt;a href="/application-principals/">a little article on
securing application-defined principals&lt;/a>, which I used as a discussion piece
at the &lt;a
href="https://conf.researchr.org/track/wossca-2018/wossca-2018-papers">Workshop
On Speculative Side-Channel Analysis&lt;/a>. The workshop was pretty fun and
interesting, and I’m grateful to the organizers and program committee for
setting it up. And now I’m heading back down to Paris on the train for some more
vacation!&lt;/p></description><author>Chris Palmer</author><guid>2018/07/19/application-principals/index.html</guid><pubDate>Thu, 19 Jul 2018 00:00:00 +0000</pubDate></item><item><title>Coping, Maybe Even Thriving, With Chronic Pain</title><link>https://noncombatant.org/2018/06/01/coping-with-pain/index.content</link><description>&lt;h1>Coping, Maybe Even Thriving, With Chronic Pain&lt;/h1>

&lt;p>&lt;time>1 June 2018&lt;/time>&lt;/p>

&lt;p>Normally in this blog, I write about software engineering and music. This
post is about a topic even more personal to me: coping with chronic pain, while
still functioning at a high level and enjoying life. If that feels weird to you,
feel free to skip this post. It’s OK. :)&lt;/p>

&lt;p>From birth, and in exciting new ways since then, my body has been
extraordinarily difficult to live in and with. I have several mostly-invisible
disabilities that severely limit what I can physically do, and when, and to what
extent. And they affect my emotional state and outlook. In spite of that, I have
managed to live a full and adventurous life.&lt;/p>

&lt;p>I’m writing this because over the years people have asked me about it
privately, such as other people with some of the same disabilites as me, in my
profession, or whatever. Lately, some more people close to me are newly
experiencing chronic pain, too. This post is an expanded version of an answer I
posted on Twitter to someone who was asking how to cope.&lt;/p>

&lt;p>Here are some thoughts about things that have worked for me. In the hope that
it helps someone else, here goes.&lt;/p>

&lt;dl>

&lt;dt>Manage your food and medications.&lt;/dt>

&lt;dd>

&lt;p>Do not goof around with your prescribed medications. Take them all in exactly
the right doses at exactly the right times, and communicate regularly with your
doctor(s) about how they make you feel. Request and make changes if necessary.
Take notes so you don’t forget any details. Set alarms or notifications so you
don’t miss any.&lt;/p>

&lt;p>If you have pain related to eating, it is extra important to watch what, and
when, you eat. Cultivate a list of safe foods, happy foods, bad-but-fun foods to
eat rarely, and so on. Again, take notes if that helps.&lt;/p>

&lt;p>Pretty much everyone needs to drink more water than they do.&lt;/p>

&lt;/dd>

&lt;dt>Exercise as much as you can.&lt;/dt>

&lt;dd>

&lt;p>I know this is good advice because I generally don’t follow it, and I
generally pay the price.&lt;/p>

&lt;p>You might not be able to do much; I certainly can’t. But do what you can,
when you can, even if it’s just walking or stretching. Do it on your terms, but
do it. Over time you’ll be able to do more.&lt;/p>

&lt;/dd>

&lt;dt>Control your time and energy.&lt;/dt>

&lt;dd>

&lt;p>Don’t let people take up what little energy you may have left on things that
are not valuable to you. Whenever you do spend energy, make it on your terms and
on your schedule, to the extent possible. You will not always be able to get as
much control as you want, but you can get some if you take it.&lt;/p>

&lt;p>Unfortunately, this can make you difficult to deal with. (People who know me
are nodding vigorously right now.) It’s your responsibility to explain to people
why you need to control your time and energy so carefully. That can mean you
have to talk about uncomfortable things, such as health and pain. You don’t have
to go into a whole lot of detail, but your colleagues, family, and friends do
need to know why you can’t do that thing that day or have to postpone the thing
until tomorrow, or whatever.&lt;/p>

&lt;p>When you are able to do the thing, follow through. If people trust that you
will be reliable, you can sometimes retain more control.&lt;/p>

&lt;p>Another thing that helps you keep control, without incurring a cost on
others, is to reduce physical and schedule clutter. Every material thing in your
life, every digital thing, everything on your to-do list, and everything in your
calendar require your active management and engagement. Even if you don’t
realize it, they are all taking up ‘space’ in your mind and emotions. Various
authors like &lt;a href="http://www.discardia.com/">Dinah Sanders&lt;/a> and &lt;a
href="https://konmari.com/">Marie Kondo&lt;/a> have books and blogs and so on
dedicated to helping people de-clutter. But you don’t necessarily need to buy or
read anything (unless that helps). Just be mindful of whether or not you need
the thing, whether or not you’re really going to ever use or do the thing. (Have
you even touched it in the past year?) If not, give it away or throw it
away.&lt;/p>

&lt;p>This can be difficult, because it can mean giving up illusions. You’ll say to
yourself, “I’ll definitely build this robot someday! I can’t throw away all
these servo motors!” You might not ever build the robot — but giving it up can
free up resources for more realistic goals and dreams.&lt;/p>

&lt;p>You don’t have to (and shouldn’t) go to some ‘minimalist’ extreme, and you
don’t have to (and shouldn’t) throw away things you love or need. And you don’t
necessarily need a ‘reason’ to love a thing. Just try to be mindful of whether
you really do love or need the thing.&lt;/p>

&lt;/dd>

&lt;dt>Plan to rest.&lt;/dt>

&lt;dd>

&lt;p>You’re going to need to rest, so plan to. This may require changing your work
or family schedule. This can be difficult, but it’s better than the alternative:
crashing hard. You can achieve more of your goals with work and rest than you
can by pretending that you don’t need to rest and trying to work through
pain.&lt;/p>

&lt;p>Pain eats up &lt;strong>a lot&lt;/strong> of your energy. Even more than you
realize. When pain hits, you need to rest. Rest whenever you can, so that you
can work whenever you can.&lt;/p>

&lt;/dd>

&lt;dt>Bring small pleasures and safety with you.&lt;/dt>

&lt;dd>

&lt;p>I get a lot of physical and psychological comfort from knowing that I have
what I need with me at all times.&lt;/p>

&lt;p>Find small pleasures, comforts, and safeties, and bring them with you in a
backpack or bag that you always carry. Be mindful to realize anything you feel
like you need: &lt;a href="https://en.wikipedia.org/wiki/Towel_Day">a towel&lt;/a>,
spare socks and underwear, snacks, water, hand sanitizer, whatever. Definitely
any necessary medications. Any time you find yourself wishing for something but
not having it, pack it in your bag.&lt;/p>

&lt;/dd>

&lt;dt>Meditate.&lt;/dt>

&lt;dd>

&lt;p>Meditation helps you focus on what you want to achieve and how you want to
feel. In my experience it is also a pretty good way to control pain, sometimes
including severe pain. &lt;strong>Definitely take necessary medications that your
doctor has prescribed!&lt;/strong> You can’t ignore pain through will alone any
more than you can levitate. But with meditation you can train yourself to keep
some perspective and control even in bad situations.&lt;/p>

&lt;p>There are many books about various meditation techniques. Try reading a
couple different ones. But the gist of them all is: focus on 1 thing, such as
your breathing; and observe your mind, your body, and the world without
judgement and without letting them control you or each other. This is all easier
said than done, of course, but practice works.&lt;/p>

&lt;/dd>

&lt;/dl>

&lt;p>Please feel free to email me if you have more ideas that you think I should
add here. (I’ll keep everything confidential, of course.)&lt;/p></description><author>Chris Palmer</author><guid>2018/06/01/coping-with-pain/index.html</guid><pubDate>Fri, 01 Jun 2018 00:00:00 +0000</pubDate></item><item><title>On Validating Inputs</title><link>https://noncombatant.org/2018/01/15/on-validating-inputs/index.content</link><description>&lt;h1>On Validating Inputs&lt;/h1>

&lt;p>&lt;time>15 January 2018&lt;/time>&lt;/p>

&lt;div id="toc">&lt;/div>

&lt;h2>Introduction&lt;/h2>

&lt;p>A principle of secure software development is that only the callee (sometimes
called the &lt;em>relying party&lt;/em>, RP) should trust itself to validate an input.
Typically, the callee has a higher degree of privilege than the caller, and will
use its privilege to perform some task for the caller if and only if the input
is valid.&lt;/p>

&lt;p>Allowing the caller to assert that an input is valid is unsafe: &lt;em>of
course&lt;/em> a malicious caller will claim the input is valid. A classic example
of this mistake is when a web server trusts client-side validation in
JavaScript.&lt;/p>

&lt;h2>The Problem&lt;/h2>

&lt;p>However, input validation functions are attack surface. Validating inputs is
dangerous, and difficult to do correctly. This is especially true when the input
language is complex or when the validator is implemented in an unsafe language.
Validators can suffer from a variety of bug classes:&lt;/p>

&lt;dl>

&lt;dt>&lt;a href="https://en.wikipedia.org/wiki/Memory_safety">Memory
unsafety&lt;/a>.&lt;/dt>

&lt;dd>&lt;p>In a memory-unsafe language, it’s too easy to write a validation function
that suffers from memory corruption bugs, such as out-of-bounds reads and
writes, and use-after-free. This is especially likely if the input language is
complex, but even simple input languages can be hard to process correctly in
primitive languages.&lt;/p>&lt;/dd>

&lt;dt>&lt;a href="https://en.wikipedia.org/wiki/Type_safety">Type unsafety&lt;/a>.&lt;/dt>

&lt;dd>&lt;p>In a type-unsafe language, it can be easy to write a validation function
that confuses either the types of input objects or of intermediate types
particular to the function’s implementation. Attackers can often exploit such
type confusion (often, but not only, by turning it into memory
corruption).&lt;/p>&lt;/dd>

&lt;dt>Semantic unsafety and application logic bugs.&lt;/dt>

&lt;dd>&lt;p>Some input languages are not necessarily a good match for their problem
domain. They may be overpowered, underpowered, or have a poor mapping to
concepts in the application domain.&lt;/p>

&lt;p>Other input languages have semantics that don’t quite match those of the
validating function’s environment, or are underspecified. For example, &lt;a
href="http://www.ecma-international.org/publications/files/ECMA-ST/ECMA-404.pdf">the
JSON ‘grammar’&lt;/a> allows for arbitrarily-long sequences of digits in numeric
value literals, but the JavaScript language uses fixed-size, 64-bit IEEE
floating point values to represent numbers. JavaScript can correctly represent
&lt;a
href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Number/isSafeInteger">only
53-bit integers&lt;/a>.&lt;/p>&lt;/dd>

&lt;/dl>

&lt;h3>The Paradox Of Validation&lt;/h3>

&lt;p>If the input language is sufficiently complex — &lt;a
href="https://en.wikipedia.org/wiki/XML">which is all too likely in the real
world&lt;/a> — it might be impossible to write a safe validator. In this case, we
have a paradox: the RP can only trust itself to validate its inputs, but cannot
safely do so. For example, consider a web server that needs to validate XML
inputs, or &lt;a
href="http://www.c7zero.info/stuff/ASN1_parsing_issues_in_crypto_Latincrypt2015.pdf">applications
that handle ASN.1&lt;/a>.&lt;/p>

&lt;h2>What Could Go Wrong?&lt;/h2>

&lt;p>There are (at least) 2 different kinds of complexity that create (at least) 2
different kinds of potential problems during input validation.&lt;/p>

&lt;dl>

&lt;dt>Grammatical complexity, and subsequent semantic complexity.&lt;/dt>

&lt;dd>&lt;p>Part of the language-theoretic security goal is to have inputs come from
languages low on the &lt;a
href="https://en.wikipedia.org/wiki/Chomsky_hierarchy">Chomsky hierarchy&lt;/a>.
This reduces the complexity of validators for such inputs, which increases the
likelihood that they will be correct.&lt;/p>

&lt;p>Even if the validator is not compromised or exploited during validation,
there is still the problem of correct semantic interpretation. Complex languages
are harder to interpret correctly, giving rise to the problem that the RP might
misinterpret a correct and correctly-validated input.&lt;/p>&lt;/dd>

&lt;dt>Side-effect complexity.&lt;/dt>

&lt;dd>&lt;p>There is also a question as to the complexity of side-effects that an
input language is designed to cause on the operating environment when
interpreted. Side-effect complexity is orthogonal to grammatical complexity;
even a trivial input language can be used to cause unsafe or undesired
side-effects. For example, consider a shell command validator (perhaps as part
of a system status monitoring web application):&lt;/p>

&lt;pre>
def is_valid_command(command):
 return re.match(r"^\w+$", command)

def run_command(command):
 if not is_valid_command(command):
 raise ValueError("Nice try, goofball")
 os.system(command)
&lt;/pre>

&lt;p>Although the validator is trivially correct (assuming a design calling for
single-word commands with no parameters or shell syntactic metacharacters), and
is invoked correctly, the above code is unsafe. The triviality of the grammar
does lend itself to further validation though, which is another reason to prefer
simpler grammars.&lt;/p>

&lt;p>A tighter validator can help us sleep a little easier:&lt;/p>

&lt;pre>
AllowedCommands = set(("uptime", "dmesg", "netstat"))

def is_valid_command(command):
 return command in AllowedCommands
&lt;/pre>

&lt;p>(Presumably, the designers of the application have accepted the risks of
exposing the outputs of those commands to callers, presumably authenticated and
authorized somehow.)&lt;/p>&lt;/dd>

&lt;/dl>

&lt;h3>What About Sandboxing?&lt;/h3>

&lt;p>What do we gain if the RP delegates validation to a privilege-reduced
validator (PRV; e.g. a sandboxed parser), and then trusts the PRV’s result? If
the PRV was compromised during validation, its result is no more trustworthy
than without sandboxing. But at least the RP would not itself have been
compromised.&lt;/p>

&lt;p>Sandboxing can reduce the range of potential side-effects that the validator
can perform, ensuring that only intended side-effects take place (if any), even
if the validator is compromised.&lt;/p>

&lt;p>Sandboxing does nothing for grammatical or semantic complexity, however, and
does not reduce the risks of later misinterpretation.&lt;/p>

&lt;h3>What About Pre-processing?&lt;/h3>

&lt;p>You might also imagine that we can transform an input into a less complex or
dangerous form: either a normalized or minimized form of the original input
language, or a different, simpler language. I’ll call this &lt;em>downward
transformation&lt;/em>, but it might have a more official name (please email me if
you know it!).&lt;/p>

&lt;p>Downward transformation can be lossless or lossy. (It might seem that
downward transformation would be inherently lossy, but recall that input
languages are sometimes overly powerful. It may be possible to downwardly
transform such a language without semantic loss.)&lt;/p>

&lt;p>Lossy transformation can carry its own application-semantic risks. For
example, consider transforming XML into JSON: XML has the concept of a document
type definition (DTD), enabling XML parsers to enforce structural invariants of
an XML input. After a pre-processor has transformed the document to JSON, the
recipient of the JSON input would have to re-encode the assertions encoded in
the DTD, with attendant risks of semantic skew and divergence over time.&lt;/p>

&lt;p>Although potentially useful, downward transformation is not a reduction in
overall system complexity. In fact, it’s an increase: the system must now be
able to handle 2 languages, not just 1. But it can be possible to separate the
processing of the 2 languages, including sandboxing 1 or both.&lt;/p>

&lt;h2>Approaching Solutions&lt;/h2>

&lt;dl>

&lt;dt>Implement validators in memory-safe languages.&lt;/dt>

&lt;dd>&lt;p>At a minimum, we can and must eliminate the most rinky-dink vulnerability
class: memory corruption.&lt;/p>&lt;/dd>

&lt;dt>Implement validators in type-safe languages.&lt;/dt>

&lt;dd>&lt;p>When it’s trustworthy, we can use the language’s type system to enforce
grammatical and semantic correctness, for example by encoding each syntactic
structure as a distinct type, with assertions about child structures and their
types. &lt;a
href="http://publications.lib.chalmers.se/records/fulltext/local_135303.pdf">Proofs
for free!&lt;/a>&lt;/p>&lt;/dd>

&lt;dt>Accept only well-specified languages.&lt;/dt>

&lt;dd>&lt;p>Unfortunately, this is easier said than done, both because it’s hard to
specify a language, and because a few people are still using JSON. Still, we can
sometimes tighten the effective definitions of poor languages that we are forced
to accept, by defining subsets and dialects and by writing them into the API
definition. (E.g., for a JSON validator: “This function will throw
&lt;code>RangeException&lt;/code> for integers not in the range –(2&lt;sup>53&lt;/sup> – 1)
.. 2&lt;sup>53&lt;/sup> – 1, inclusive.”)&lt;/p>&lt;/dd>

&lt;dt>Sandbox to constrain side-effects.&lt;/dt>

&lt;dd>&lt;p>This is ‘obvious’, but it’s &lt;a
href="https://scarybeastsecurity.blogspot.com/2017/05/bleed-continues-18-byte-file-14k-bounty.html">not
done nearly as often as it should be&lt;/a>. &lt;a
href="https://android.googlesource.com/platform/external/minijail/">Minijail is
a good sandboxing option for Linux&lt;/a>. There is also &lt;a
href="https://github.com/google/nsjail">NsJail&lt;/a>.&lt;/p>&lt;/dd>

&lt;dt>Cross-implementation unit and integration tests.&lt;/dt>

&lt;dd>&lt;p>My favorite example is &lt;a
href="http://seriot.ch/parsing_json.php">Nicolas Seriot’s JSON torture
test/freak show&lt;/a>.&lt;/p>&lt;/dd>

&lt;/dl>

&lt;h3>Benefits Of Safety And Simplicity&lt;/h3>

&lt;p>A memory-safe implementation of a validator for a language with no
side-effects on the environment (e.g. no shell command intepreter) would allow
us to, potentially, skip sandboxing. This is valuable because, outside of &lt;a
href="https://en.wikipedia.org/wiki/Singularity_(operating_system)">a type-safe
virtual machine&lt;/a>, the fundamental sandboxing primitive is the OS’ process
boundary. It can be surprisingly expensive, in both time and space, to create
new processes. The problem gets worse at a high degree of granularity (e.g. a
fresh sandbox per input, or even potentially 2 for downward transformation) and
especially with requirements for high throughput (many inputs) and/or low
latency.&lt;/p>

&lt;p>From a systems perspective, it’s reasonable to question if
unsafe-but-efficient languages are in fact efficient.&lt;/p></description><author>Chris Palmer</author><guid>2018/01/15/on-validating-inputs/index.html</guid><pubDate>Mon, 15 Jan 2018 00:00:00 +0000</pubDate></item><item><title>Pithy (?) Programming Guidelines (?)</title><link>https://noncombatant.org/2017/11/11/pithy-programming-guidelines/index.content</link><description>&lt;h1>Pithy (?) Programming Guidelines (?)&lt;/h1>

&lt;p>&lt;time>11 November 2017&lt;/time>&lt;/p>

&lt;aside>&lt;p>Slightly tweaked and expanded 19 January 2018.&lt;/p>&lt;/aside>

&lt;p>These guidelines are probably insufficiently pithy, and might not be wise at
all. But they seem to work for me.&lt;/p>

&lt;dl>

&lt;dt>&lt;a href="https://www.google.com/about/philosophy.html">Focus on the user and
all else will follow&lt;/a>.&lt;/dt>

&lt;dd>&lt;p>See also &lt;a
href="https://www.w3.org/TR/html-design-principles/#priority-of-constituencies">the
priority of constituencies&lt;/a>. Start with UX mocks and storyboards, user
documentation, API documentation, or whatever is appropriate for the kind of
programming you’re doing. Don’t start writing code first.&lt;/p>&lt;/dd>

&lt;dt>Assert what you assume.&lt;/dt>

&lt;dd>&lt;p>Of course, this requires you to know what you are assuming. Use every
&lt;code>assert&lt;/code>, &lt;code>CHECK&lt;/code>, &lt;code>&lt;a
href="https://www.usenix.org/legacy/events/hotos03/tech/full_papers/candea/candea.pdf">die&lt;/a>&lt;/code>,
or other assumption-checking construct you can. Do not turn them off in
production builds, unless profiling shows an assertion is actually making a hot
spot hotter. (Very little code is actually hot.)&lt;/p>&lt;/dd>

&lt;dt>&lt;a href="https://isocpp.org/wiki/faq/const-correctness">&lt;code>const&lt;/code>
is correct.&lt;/a>&lt;/dt>

&lt;dd>&lt;p>Use whatever facilities your language provides for nailing things down,
and prefer languages that have such facilities. &lt;a
href="https://en.wikipedia.org/wiki/Referential_transparency">This is what
functional programming people are always yelling about&lt;/a>, and they have a
point.&lt;/p>&lt;/dd>

&lt;dt>Names are the best documentation — especially the names of types.&lt;/dt>

&lt;dd>&lt;p>Comments are sometimes necessary. But if your interfaces and even your
implementations don’t explain themselves by their use of names, try using more
and better names and types instead of more comments. &lt;a
href="https://martinfowler.com/bliki/TwoHardThings.html">This is hard&lt;/a>, but
the effort pays off.&lt;/p>&lt;/dd>

&lt;dt>Constructor is best validator.&lt;/dt>

&lt;dd>&lt;p>Don’t even allow ill-defined or invalid objects to come into existence.
Raise an exception or return a well-defined sentinel value.&lt;/p>&lt;/dd>

&lt;dt>Theory becomes practice in compilers.&lt;/dt>

&lt;dd>&lt;p>The claims of academics — &lt;a
href="https://www.imperialviolet.org/2014/09/11/moveprovers.html">formal
verification being possible&lt;/a>, static analysis discovering most or many bugs,
and so on — gradually become increasingly solid enough to ship in production
compilers. Type systems are usable proof systems, and compiler warnings are
usable static analysis — and they’ve been getting better every year. Turn on all
such options at their highest level. They will slow you down for a week and
speed you up for the rest of your life.&lt;/p>&lt;/dd>

&lt;dt>Every dependency is a debt and a nest of bugs.&lt;/dt>

&lt;dd>&lt;p>Think long and hard about each dependency you take on. Mere convenience
for you is inconvenience and unsafety for your users. Be certain that each
dependency is less buggy and debt-laden than what you could do yourself — if it
really needs doing at all.&lt;/p>&lt;/dd>

&lt;dt>&lt;a href="https://en.wikiquote.org/wiki/Albert_Einstein">Everything should be
made as simple as possible, but no simpler&lt;/a>.&lt;/dt>

&lt;dd>&lt;p>If you’re not sure what to do yet, start with &lt;a
href="http://wiki.c2.com/?DoTheSimplestThingThatCouldPossiblyWork">The Simplest
Thing That Could Possibly Work&lt;/a>. It may end up being all you need.&lt;/p>

&lt;p>However, software that is too simple can be unnecessarily hard to
use.&lt;/p>&lt;/dd>

&lt;/dl></description><author>Chris Palmer</author><guid>2017/11/11/pithy-programming-guidelines/index.html</guid><pubDate>Sat, 11 Nov 2017 00:00:00 +0000</pubDate></item><item><title>Some Problems Of URLs</title><link>https://noncombatant.org/2017/11/07/problems-of-urls/index.content</link><description>&lt;h1>Some Problems Of URLs&lt;/h1>

&lt;p>&lt;time>7 November 2017&lt;/time>&lt;/p>

&lt;aside>
 &lt;p>Update 09 Dec 2017 18:09 UTC: A reader pointed me to &lt;a
 href="https://www.blackhat.com/docs/us-17/thursday/us-17-Tsai-A-New-Era-Of-SSRF-Exploiting-URL-Parser-In-Trending-Programming-Languages.pdf">this
 delightful Black Hat talk by Orange Tsai about exploiting URL grammar
 problems&lt;/a>.&lt;/p>
&lt;/aside>

&lt;div id="toc">&lt;/div>

&lt;h2>Background&lt;/h2>

&lt;p>The &lt;a href="https://tools.ietf.org/html/rfc1738">uniform resource locator
 (URL)&lt;/a> is a data structure and an associated serialization format that aims
 to uniquely identify any resource on the Internet (and other networks). (See
 also &lt;a href="https://tools.ietf.org/html/rfc3986">uniform resource identifier
 (URI)&lt;/a>.) That’s a lofty goal, but it has proven more or less tractable and
 practical. Which is astounding and great! A global network namespace enables
 powerful applications, and powerful interactions between applications.&lt;/p>

&lt;p>However, URLs have some problems of usability, security, and economics. Many
 of us have wished for a global namespace with fewer problems. I’ll address that
 first, and then I’ll have some fun with the technical aspects of the problem.
 You can skip that stuff, if you like.&lt;/p>

&lt;a id="names-are-power">&lt;/a>
&lt;h2>Names Are Power&lt;/h2>

&lt;p>URLs have very poor usability both because they are structurally complex, and
 because their textual representation is unnecessarily ambiguous and ugly (&lt;a href="#syntaxyness">syntaxy&lt;/a>). Some of
 the structural complexity is
 necessary, and some of it is not.&lt;/p>

&lt;p>The poor usability of URLs is a weak spot for advocates of semi-decentralized
 naming schemes like URLs and the DNS. People sometimes propose that a
 centralized naming scheme would be less chaotic and hence more usable and more
 safe. They do have a point, and we should address it.&lt;/p>

&lt;p>For example, my colleague &lt;a
 href="https://medium.com/@owencm/rethinking-url-bars-as-primary-browser-ui-e2118339d2c0">Owen
 Campbell-Moore argues that URLs are un-fixably terrible&lt;/a>, and advocates for
 search engines to provide the trusted, and hopefully trustworthy, mapping
 between human-meaningful names and origins or URLs.&lt;/p>

&lt;p>However, that requires the search engine, or other centralized naming
 authority, to be trustworthy. This proves difficult:&lt;/p>

&lt;figure>&lt;img src="whatsapp-minefield.jpg" width="552" height="459" alt="A
screenshot of Google Play Store showing search results for “whatsapp”, with
numerous perfect spoofs." loading="lazy" />
 &lt;figcaption>“This is horrible..
 minefield” — &lt;a href="https://mobile.twitter.com/deathy/status/926861685440249857">Cristian Vat
 on Twitter&lt;/a>&lt;/figcaption>
&lt;/figure>

&lt;p>Similarly, a Google search for [ &lt;a href="https://www.google.com/search?q=download+chrome">download chrome&lt;/a> ] has
 lots of legitimate and correct results up top, but there are still fakes on the
 first page of results (at least at the time of writing, and for as long as I can
 remember). In fact, we used to have a recurring problem that obvious spoofs were
 at the very top of the results. Google’s search engine could not reliably find
 Google’s browser. In one sense, that indicates trustworthiness — Google doesn’t
 seem to put its thumb on the scale. In another sense... sigh. 🤷🏻‍♂️&lt;/p>

&lt;p>Perhaps ✨ machine learning ✨ could be useful in identifying spoofs, such as
 by comparing names and icons for similarity and raising them for human review.
 That would speed up the process of finding potential spoofs, potentially
 improving the centralized naming authority’s trustworthiness. But we’d still be
 trusting the authority with a lot of power.&lt;/p>

&lt;p>Obviously, in most of this post, I agree with Owen about the badness of URLs.
 But ultimately I do not agree that a centralized authority would be better, nor
 that we should switch to one.&lt;/p>

&lt;p>I think the problem Owen poses can be resolved by investigating this
 question:&lt;/p>

&lt;blockquote>“Origins are not very user-friendly”&lt;/blockquote>

&lt;p>I fully agree that &lt;strong>URLs&lt;/strong> are not usable, but I do believe
 that &lt;strong>origins&lt;/strong> (the &lt;a href="https://tools.ietf.org/search/rfc6454">scheme, host, port tuple&lt;/a>) are
 or can be made usable — and that if we succeed at that technical problem, we can
 reduce some of the pressure to centralize power.&lt;/p>

&lt;h3>Making Origins Usable&lt;/h3>

&lt;p>I think we can make origins more usable by doing the following things in the
 Location Bar:&lt;/p>

&lt;ul>

 &lt;li>Show only the hostname. Not the port, not the scheme. If necessary or
 useful, we can also consider showing only the effective TLD + 1 label
 (eTLD+1). In fact I think it will prove necessary and useful.&lt;/li>

 &lt;li>Show a negative security indicator, like Chrome’s &lt;strong>Not
 Secure&lt;/strong> chip, for non-secure schemes.&lt;/li>

 &lt;li>Show no indicator for secure schemes.&lt;/li>

 &lt;li>Continue to deprecate and remove non-secure schemes. Ideally, the ongoing
 project to HTTPS-ify the web could get the number of schemes people regularly
 see down to 1.&lt;/li>

&lt;/ul>

&lt;p>Note that Safari already does most of the above, although it commits what I
 consider an error: for sites with Extended Validation (EV) certificates, it
 shows the EV name instead of the eTLD+1. This opens a whole other can of
 goat-worms (which I have &lt;a
 href="/2017/02/15/decoding-chromes-https-ux/#what-about-extended-validation-certificates">yelled
 about elsewhere&lt;/a>). But you can get a glimpse of a better naming future by
 trying out Safari. Brave for desktop also shows only the hostname until you
 focus the Location Bar.&lt;/p>

&lt;figure>&lt;img src="safari-etld.png" width="648" height="135" alt="A screenshot of
Safari showing only the eTLD+1." loading="lazy" />
 &lt;figcaption>Glorious, isn’t
 it?&lt;/figcaption>
&lt;/figure>

&lt;p>As a practical matter, eTLD+1 names, hostnames, and copied-and-pasted blobs
 are all people really use in the real world. Very few people use URLs as such
 — and that is perfectly fine! To improve URL usability and safety, application
 and platform developers need only go with the flow. Let’s.&lt;/p>

&lt;p>However, some more-or-less tractable problems remain even after we do all of
 the above.&lt;/p>

&lt;ul>

 &lt;li>Ill-formed hostnames will still be confusing.

 &lt;ul>

 &lt;li>I believe confusingness is by itself a useful indicator for people, and that
 well-formed hostnames like “facebook.com” and “baidu.com” make good brands.
 Hostnames are ubiquitous in advertising and pop culture.&lt;/li>

 &lt;li>Ill-formed hostnames are inherently fishy, and people have a decent chance
 to distinguish “facebook.com” from “facebook.com.wumpgarble.phishing.blog”,
 especially if we show only eTLD+1: “phishing.blog” is clearly not
 “facebook.com”.&lt;/li>

 &lt;li>As baidu.com and mixi.jp show, they are even usable across a language and
 character set barrier, although IDNs also exist and can help.&lt;/li>

 &lt;/ul>
 &lt;/li>

 &lt;li>People will still need to share links, and developers will still need to
 read, write, and modify them.

 &lt;ul>

 &lt;li>I think we can handle this by making the full URL visible and editable when
 the Location Bar takes focus.&lt;/li>

 &lt;/ul>
 &lt;/li>

 &lt;li>Homoglyph attacks will continue to exist.

 &lt;ul>

 &lt;li>Note that centralized naming authorities also have this problem.&lt;/li>

 &lt;li>I believe that the mechanisms for coping with it can work either in
 centralized or decentralized naming schemes.&lt;/li>

 &lt;/ul>
 &lt;/li>

&lt;/ul>

&lt;h2>The Problem&lt;/h2>

&lt;p>URLs became user interface components almost immediately: people are expected
 to be able to type in URLs, copy and paste them, and (at least partially) parse
 them to extract security-relevant information, and sometimes to modify them. All
 this, including on tiny phone screens.&lt;/p>

&lt;p>This turns out to be not-so-great, because in order to meet their goal, URLs
 have to be fairly complex, and object serialization and deserialization is a
 surprisingly hard problem even in simple cases. The end result is that most
 people have a very hard time actually using URLs in practice.&lt;/p>

&lt;h3>URLs Are Surprisingly Complex&lt;/h3>

&lt;p>Although &lt;a href="https://cs.chromium.org/chromium/src/url/gurl.h?sq=package:chromium&amp;dr=CSs&amp;l=472">the
 implementation Chrome uses is more complex&lt;/a> (see also &lt;a
 href="https://cs.chromium.org/chromium/src/url/third_party/mozilla/url_parse.h?sq=package:chromium&amp;dr=CSs&amp;l=77">&lt;code>url::Parsed&lt;/code>&lt;/a>),
 we might imagine that the structure of a URL object need not be too complex. For
 example:&lt;/p>

&lt;pre>
class URL {
 string scheme
 string username
 string password
 string host
 string port
 string path
 string query
 string ref // Also called "fragment".
}
&lt;/pre>

&lt;p>Well, that’s a bit too simple. First, TCP and UDP port numbers are unsigned
 16-bit integers, not arbitrary strings. Then, the host could be an IPv4 address,
 an IPv6 address, or an address in another network type. Or it could be a DNS
 hostname, a NetBIOS hostname, or a name in some other domain. Even considering
 just DNS and NetBIOS names, simple strings don’t quite capture the type
 information we need.&lt;/p>

&lt;ul>

 &lt;li>The DNS is hierarchical (having up to 127 levels), and a name consists of 1
 or more &lt;em>labels&lt;/em>, each containing 1 to 63 octets, and the total length of
 the internal representation of a name can be at most 255 octets. (&lt;a
 href="https://en.wikipedia.org/wiki/Domain_Name_System#Domain_name_syntax">Wikipedia&lt;/a>)&lt;/li>

 &lt;li>&lt;a href="https://en.wikipedia.org/wiki/NetBIOS#Name_service">Wikipedia
 says&lt;/a> that “NetBIOS names are 16 octets in length and vary based on the
 particular implementation. Frequently, the 16th octet, called the NetBIOS
 Suffix, designates the type of resource, and can be used to tell other
 applications what type of services the system offers.” That leaves a lot of
 questions open, but we won’t dig into them here.&lt;/li>

&lt;/ul>

&lt;p>So, we’ll have to complicate our representation a bit. Let’s try this:&lt;/p>

&lt;pre>
abstract class NetworkAddress { ... }

class IPv4NetworkAddress extends NetworkAddress { ... }

class IPv6NetAddress extends NetworkAddress { ... }

abstract class HostName { ... }

class DNSName extends HostName { ... }

class NetBIOSName extends HostName { ... }

class HostIdentifier {
 enum Type {
 Address,
 Name
 }

 union {
 NetworkAddress address
 HostName name
 }
}

class URL {
 string scheme
 string username
 string password
 HostIdentifier host
 uint16_t port
 string path
 string query
 string ref // Also called "fragment".
}
&lt;/pre>

&lt;p>We’ve more tightly specified the port, and &lt;code>HostIdentifier&lt;/code> is a
 sum type of 2 abstract &lt;code>NetworkAddress&lt;/code> and &lt;code>HostName&lt;/code>
 types. In turn, the abstract types are made concrete for specific addressing and
 naming systems; we’ve given some modern examples for each.&lt;/p>

&lt;p>Although the real details are madness-inducing, let’s further assume for the
 moment that the &lt;code>string&lt;/code> type is a sequence of Unicode
 characters.&lt;/p>

&lt;p>The real-world analogues to each of these hypothetical classes has at least 1
 serialization function and least 1 deserialization function or parsing
 constructor. Even the IPv4 address, a humble 4-octet data structure, has a
 delightfully wacky set of representations. &lt;a href="ipv4-parser.c">A simple
 program&lt;/a> that uses the BSD functions &lt;code>inet_aton&lt;/code> (deserializer)
 and &lt;code>inet_ntoa&lt;/code> (serializer) produces the following
 equivalencies:&lt;/p>

&lt;pre>
Serialized Deserialized Reserialized 
222.173.190.239 0xDEADBEEF 222.173.190.239
0xDEADBEEF 0xDEADBEEF 222.173.190.239
033653337357 0xDEADBEEF 222.173.190.239
222.11386607 0xDEADBEEF 222.173.190.239
222.173.48879 0xDEADBEEF 222.173.190.239
127.0.0.1 0x7F000001 127.0.0.1 
0x7F000001 0x7F000001 127.0.0.1 
127.1 0x7F000001 127.0.0.1 
127.0.1 0x7F000001 127.0.0.1
&lt;/pre>

&lt;p>As of this writing, Chrome will indeed take &lt;code>http://0x9765C143&lt;/code>,
 convert it to &lt;code>http://151.101.193.67/&lt;/code>, and navigate to it. Firefox
 navigates directly to &lt;code>http://0x9765C143&lt;/code> without first converting it
 to dotted decimal in the Location Bar.&lt;/p>

&lt;p>IPv6 addresses have their own various representations, &lt;a
 href="https://en.wikipedia.org/wiki/IPv6_address#Representation">as Wikipedia
 discusses&lt;/a>. Notably, to disambiguate colon-separated hextets of the IPv6
 address from the colon-separated port number in URL string representations, IPv6
 addresses must be surrounded with square braces in URLs:&lt;/p>

&lt;pre>
https://[2001:db8:85a3:8d3:1319:8a2e:370:7348]:443/foo/bar/noodles
 +------- IPv6 address -------------+ ^
 |
 port
&lt;/pre>

&lt;a id="syntaxyness">&lt;/a>
&lt;h3>Syntaxyness&lt;/h3>

&lt;p>Whenever a language has lots of syntactic meta-characters, especially when
 some of the meta-characters have multiple meanings depending on their context, I
 say the language is “syntaxy”. If you try to write a URL parser, you’ll find
 that it has to keep a fair amount of state to know whether this &lt;code>:&lt;/code>
 is part of the scheme separator &lt;code>://&lt;/code>, or a hextet separator, or the
 port number separator. Similarly, &lt;code>/&lt;/code> has at least 2 meanings.&lt;/p>

&lt;p>Unconsciously perhaps, humans need to build the same state machine in their
 minds to parse URLs — or fail to, and get confused. Add on top of that the fact
 that many URL schemes are not real words, &lt;code>/&lt;/code> looks kind of like
 &lt;code>\&lt;/code>, and so on, and and pretty soon people are just plain confused
 about the URL language. It’s not a language people can speak easily.
&lt;/p>

&lt;h2>Goals For A Solution&lt;/h2>

&lt;p>An ideal solution to the URL usability problem would have (at least) the
 following properties:&lt;/p>

&lt;ul>

 &lt;li>unambiguous grammar&lt;/li>
 &lt;li>clear delineation of the security-relevant origin&lt;/li>
 &lt;li>not too tedious to write&lt;/li>
 &lt;li>not too tedious to read (low in syntaxyness)&lt;/li>
 &lt;li>fewer components to avoid confusion and to reduce the need for syntactic
 complexity&lt;/li>

&lt;/ul>

&lt;h2>Mitigations&lt;/h2>

&lt;p>We can’t truly solve the problem without fundamentally re-thinking URLs. URLs
 are ubiquitous, and their problems are &lt;code>struct&lt;/code>ural: there are just
 too many things in the data structure.&lt;/p>

&lt;p>Perhaps what we can do is mitigate the badness somewhat. Arguably, it is fun
 to brainstorm about how.&lt;/p>

&lt;h3>Deprecate And Remove Fields From URLs&lt;/h3>

&lt;p>First, we can remove parts of the URL we don’t need or which exacerbate our
 problems. There is a beautiful example of syntaxyness gone wrong in &lt;a
 href="https://bugs.chromium.org/p/chromium/issues/detail?id=661005">Chromium
 issue 661005&lt;/a>:&lt;/p>

&lt;pre>
Steps to reproduce the problem:
1. navigate to https://www.google.com:443+q=elon@tesla.com
2. the resulting page should be https://www.tesla.com

What is the expected behavior?
Warn the user that they are about to post credentials
 - username : "www.google.com"
 - password : "443+q=elon"
&lt;/pre>

&lt;p>A more important problem with usernames and passwords in URLs is that they
 obfuscate the URL’s hostname, potentially improving the effectiveness of
 phishing attacks. For example, people might think that the URL
 &lt;code>https://paypal@phishing.com&lt;/code> points to PayPal, but in fact it points
 to phishing.com.
&lt;/p>

&lt;p>&lt;a
 href="https://support.microsoft.com/en-us/help/834489/internet-explorer-does-not-support-user-names-and-passwords-in-web-sit">Internet
 Explorer dropped support for credentials embedded in URLs a long-ass time
 ago&lt;/a>. Wisely, Edge has not resumed supporting them.&lt;/p>

&lt;p>Firefox supports embedded credentials, but warns you about the ambiguity.&lt;/p>

&lt;figure>&lt;img src="firefox-warning.png" width="671" height="261" alt="Firefox
warns you when you browse to a URL that contains embedded credentials." loading="lazy" />
 &lt;figcaption>Firefox warns you when you browse to a URL that
 contains embedded credentials.&lt;/figcaption>
&lt;/figure>

&lt;p>Chrome does not support embedded credentials in URLs for subresources, but &lt;a
 href="https://xkcd.com/1172/">inevitably&lt;/a>, &lt;a
 href="https://bugs.chromium.org/p/chromium/issues/detail?id=779116">that broke
 someone’s use case&lt;/a>.&lt;/p>

&lt;p>If we consider that the problem with embedded credentials is that they
 confuse people, it would seem that we could break as few use cases as possible
 by allowing them in subresource URLs, and (like Firefox) warning the person
 about the ambiguity for top-level navigations.&lt;/p>

&lt;p>But if we consider that the problem is not only that embedded credentials
 confuse people, but that they also increase the complexity, decrease the
 reliability, and decrease the uniformity of our URL parsers, then that suggests
 the minimal-breakage approach does not solve the whole problem.&lt;/p>

&lt;p>Since IE and Edge do not support embedded credentials, they are effectively
 dead as a reliable web platform feature, and have been for over a decade. Why
 should Chrome and Firefox continue to indulge this phishiness?&lt;/p>

&lt;p>(Other &lt;a href="http://seriot.ch/parsing_json.php">partially-specified
 languages, like JSON, suffer from terrible reliability and uniformity
 problems&lt;/a>. A forward-looking platform, as I believe the web should be, should
 seek to gradually, gently, definitely shed these ambiguous legacy interfaces.
 And here’s an interesting &lt;a href="https://github.com/brave/browser-laptop/issues/10825">problem related to
 the non-uniformity of URL parsers&lt;/a>.)&lt;/p>

&lt;h3>Deprecate And Remove Weird Host Address Representations&lt;/h3>

&lt;p>There’s no credible, user-focused reason to support hexadecimal, octal, or
 other strange IP address representations. They might be used in attacks to
 obscure things somewhat (although even a dotted-quad representation might
 sufficiently obscure the nature of the host). &lt;a
 href="https://blogs.msdn.microsoft.com/ieinternals/2014/03/06/browser-arcana-ip-literals-in-urls/">Internet
 Explorer once granted special privileges (‘Intranet Zone’) to URLs with no dots
 in the host component&lt;/a> — including URLs using these obscure forms.&lt;/p>

&lt;p>Other than for attacks, I would bet that nobody uses or wants these address
 forms. Probably at least some people reading this, already a technical audience,
 were surprised to learn that the strange representations exist at all. So let’s
 just get rid of these historical quirks.&lt;/p>

&lt;h2>Imaginary Approaches&lt;/h2>

&lt;p>These are mitigation approaches that perhaps might be nice to do, but which I
 suspct it’s too late to try. Alas. But still...&lt;/p>

&lt;h3>Hierarchical Names That Go In The Same Direction&lt;/h3>

&lt;p>2 of the several namespaces in URLs, DNS hostnames and pathnames, are
 hierarchical. But textually, they go in opposite directions!&lt;/p>

&lt;p>In the DNS name www.example.com, com is the parent of example is the parent
 of www. The labels go left to right, child to parent. I’ll call this &lt;a
 href="https://en.wikipedia.org/wiki/Endianness">little-endian&lt;/a> naming.&lt;/p>

&lt;p>In the pathname /noodles/doodles/poodles.php, noodles is the parent of
 doodles is the parent of poodles.php. The components go left to right, parent to
 child — the opposite relationship of DNS names. I’ll call this big-endian
 naming.&lt;/p>

&lt;pre>
https://www.example.com/noodles/doodles/poodles.php
 --------------- +++++++++++++++++++++++++++
 little-endian big-endian
&lt;/pre>

&lt;p>That’s confusing enough on its own, but it gets weirder when you consider &lt;a
 href="https://en.wikipedia.org/wiki/Internationalized_domain_name">internationalized
 domain names&lt;/a>, and other Unicode URL components. What makes it extra tricky
 is that some languages read right to left (RTL), like Arabic or Hebrew, instead
 of left to right (LTR), like English. Consider further that URLs can contain
 both LTR and RTL components. (Indeed, all URLs with RTL hostnames still have to
 have at least one LTR component: the leading &lt;code>https&lt;/code> or other
 scheme.)&lt;/p>

&lt;p>&lt;a href="https://twitter.com/typhoonfilsy/status/927701344185491456">typhoonfilsy&lt;/a>
 provided a nice example of this:&lt;/p>

&lt;figure>&lt;img src="mixed-ltr-rtl-url.png" alt="URL with both Arabic and English
in both the hostname and path components." width="399" height="42" loading="lazy" />
 &lt;figcaption>URL with both Arabic and English in both the hostname
 and path components.&lt;/figcaption>
&lt;/figure>

&lt;p>So now we have both little- and big-endian names, each containing
 sub-components that go LTR and RTL. Imagine trying to read that (a) at all; and
 (b) correctly; and (c) when trying to make a security decision about an
 origin!&lt;/p>

&lt;p>So it sure would be helpful if the namespace hierarchies all went in the same
 direction, you know? That would reduce at least 1 aspect of the confusion.&lt;/p>

&lt;pre>
https://com.example.www/noodles/doodles/poodles.php
 +++++++++++++++ +++++++++++++++++++++++++++
 big-endian big-endian
&lt;/pre>

&lt;p>This would be less confusing in an RTL language:&lt;/p>

&lt;pre>
php.seldoop/seldood/seldoon/www.elpmaxe.moc://https
+++++++++++++++++++++++++++ +++++++++++++++
 big-endian big-endian
 RTL RTL LTR
&lt;/pre>

&lt;p>However, the &lt;a "href=" https://en.wikipedia.org/wiki/List_of_Internet_top-level_domains">proliferation
 of new top-level domain names&lt;/a> (TLDs) reduces the effectiveness of the
 hypothetical plan to make DNS names big-endian. For example, both blog.google
 and google.blog are legal DNS hostnames with valid TLDs. (Only the former is
 currently registered and serving a live site. Another huge problem with the
 proliferation of TLDs is the creation of new spoofing opportunities.) Swapping
 the endianness of the names would create more confusion, not less, at least for
 these pathological cases.&lt;/p>

&lt;h3>Minimizing Syntaxyness&lt;/h3>

&lt;p>We could also imagine a new URL syntax, with fewer and less ambiguous
 syntactic meta-characters. Just as a thought experiment and not as a serious
 proposal, imagine using only the comma &lt;code>,&lt;/code> to separate URL
 components, and using the slash &lt;code>/&lt;/code> only to separate tokens in
 namespaces:&lt;/p>

&lt;pre>
https,com/example/www,,noodles/doodles/poodles.php
https,com/example/www,443,noodles/doodles/poodles.php
https,com/example/www,,noodles/doodles/poodles.php,q=cute%20puppies
https,com/example/www,,noodles/doodles/poodles.php,q=cute%20puppies,table-of-contents
&lt;/pre>

&lt;p>As always, the meta-characters must be escaped when used inside a given
 component. Here, the &lt;code>,&lt;/code> is escaped as &lt;code>%2C&lt;/code> in the query
 string:&lt;/p>

&lt;pre>
https,com/example/www,,noodles/doodles/poodles.php,q=cute%2C%20puppies
&lt;/pre>

&lt;p>If the &lt;code>,,&lt;/code> indicating the default port for the scheme bothers
 you, and it probably should, we could imagine something like this:&lt;/p>

&lt;pre>
https/443,com/example/www,noodles/doodles/poodles.php
https/8443,com/example/www,noodles/doodles/poodles.php
&lt;/pre>

&lt;p>We could also imagine tagging each component with its name, rather than
 relying on their order. This would remove the requirement of empty placeholders
 for optional or default components. The result is harder to write, but perhaps
 easier to read:&lt;/p>

&lt;pre>
scheme:https,port:443,host:com/example/org
scheme:https,port:443,host:com/example/org,path:a/b/c
scheme:https,host:com/example/org,path:a/b/c
host:com/example/org,path:a/b/c,scheme:https
&lt;/pre>

&lt;p>Now we have a third meta-character to escape (&lt;code>,&lt;/code>, &lt;code>/&lt;/code>,
 and now &lt;code>:&lt;/code>) as well.&lt;/p>

&lt;p>Anyway, you get the idea: other, arguably better and/or differently-bad
 syntaxes are possible. Or, were possible.&lt;/p>

&lt;p>That’s more than enough for now. Time for beeeeeeerrrr...&lt;/p>

&lt;aside>
 &lt;p>Thanks to Eric Lawrence and Yan Zhu for providing some additional
 examples of problems, and thanks to Emily Stark-Dunn and Owen Campbell-Moore for
 reading an early draft and providing helpful thoughts.&lt;/p>
&lt;/aside></description><author>Chris Palmer</author><guid>2017/11/07/problems-of-urls/index.html</guid><pubDate>Tue, 07 Nov 2017 00:00:00 +0000</pubDate></item><item><title>Decoding Chrome’s HTTPS UX</title><link>https://noncombatant.org/2017/02/15/decoding-chromes-https-ux/index.content</link><description>&lt;h1>Decoding Chrome’s HTTPS UX&lt;/h1>

&lt;p>&lt;time>15 February 2017&lt;/time>&lt;/p>

&lt;aside>
 &lt;p>Update, 26 August 2017: My colleague &lt;a
 href="https://textslashplain.com/2017/05/02/inspecting-certificates-in-chrome/">Eric
 Lawrence has replaced your cheese&lt;/a>.&lt;/p>
&lt;/aside>

&lt;div id="toc">&lt;/div>

&lt;h2>Introduction&lt;/h2>

&lt;p>In this post I’ll try to illuminate and explain Chrome’s HTTPS-, TLS-, and
 X.509-related security UX surfaces. They are a bit complicated, and they’ve
 changed recently, and &lt;a href="https://en.wikipedia.org/wiki/Public_key_infrastructure">the Web PKI&lt;/a>
 is very weird, so I think they bear some explanation.&lt;/p>

&lt;p>(People who already know this stuff might want to skim through this section.
 The more contentious/fun stuff comes after the basics.)&lt;/p>

&lt;p>As &lt;a href="https://security.googleblog.com/2016/09/moving-towards-more-secure-web.html">Emily
 Schechter explains&lt;/a>, we’ve recently made some changes in Chrome to make
 non-secure web pages look markedly non-secure, rather than merely ‘neutral’.
 And, we’ve made HTTPS pages actually say “Secure”. Here’s a secure page in
 Chrome 56:&lt;/p>

&lt;figure>&lt;img loading="lazy" src="facebook-location-bar.png" alt="Facebook.com is
labeled “Secure” in Chrome’s Location Bar, because it uses valid HTTPS." width="273" height="42" />
 &lt;figcaption>Facebook.com is labeled “Secure” in
 Chrome’s Location Bar, because it uses valid HTTPS.&lt;/figcaption>
&lt;/figure>

&lt;p>If you click on the lock icon or on the word “Secure”, you get more
 information in a pop-up view we call the Origin Info Bubble. (Or, at least,
 &lt;em>I&lt;/em> call it that. Most other people on my team call it the Page Info
 Bubble, or PIB.)
&lt;/p>

&lt;p>The first thing it says is, “Secure connection. Your information (for
 example, passwords or credit card numbers) is private when it is sent to this
 site.”&lt;/p>

&lt;figure>&lt;img loading="lazy" src="facebook-secure.png" alt="Chrome’s PIB
explaining that the connection to Facebook.com is secure." width="336" height="141" />
 &lt;figcaption>Chrome’s PIB explaining that the connection to
 Facebook.com is secure.&lt;/figcaption>
&lt;/figure>

&lt;p>But for non-secure sites, it has a somewhat sad message: “Your connection to
 this site is not secure. You should not enter any sensitive information on this
 site (for example, passwords or credit cards), because it could be stolen by
 attackers.”&lt;/p>

&lt;figure>&lt;img loading="lazy" src="cnn-not-secure.png" alt="Chrome’s PIB
explaining that the connection to CNN.com is not secure." width="330" height="153" />
 &lt;figcaption>Chrome’s PIB explaining that the connection to CNN.com
 is not secure.&lt;/figcaption>
&lt;/figure>

&lt;p>The PIB actually has a bunch of controls in it that let you manage the site’s
 access to special permissions and features of the web platform. You can turn
 these on or off with the click of a button:&lt;/p>

&lt;figure>&lt;img loading="lazy" src="inbox-oib.png" alt="Chrome’s PIB, showing the
permission settings for inbox.google.com." width="162" height="327" />
 &lt;figcaption>Chrome’s PIB, showing the permission settings for
 inbox.google.com.&lt;/figcaption>
&lt;/figure>

&lt;h2>Site Security Details&lt;/h2>

&lt;p>Experienced Chrome nerds will notice that something else has changed: where
 the PIB now shows a link that says “Learn more”, there used to be a button
 saying Show Certificate that would open up Chrome’s Certificate Viewer UX.&lt;/p>

&lt;p>We didn’t remove the button; we just moved it to the new Security tab in
 Chrome’s Developer Tools UX. Emily Stark, Lucas Garron, Max Walker, and Paul
 Irish worked hard to design and implement the Security tab. It’s pretty cool
 because we have more room there to show you more details than there was room for
 in the PIB. Here you can see the Security tab for inbox.google.com.&lt;/p>

&lt;figure>&lt;img loading="lazy" src="inbox-security-tab-dt.png" alt="Chrome’s
Security tab in Developer Tools shows that inbox uses modern ciphers and the
QUIC secure transport protocol." width="659" height="581" />
 &lt;figcaption>Chrome’s
 Security tab in Developer Tools shows that inbox uses modern ciphers and the
 QUIC secure transport protocol.&lt;/figcaption>
&lt;/figure>

&lt;p>For sites with sub-resources from several different origins, we can show you
 that, and the security details for each different origin. Sometimes they are not
 all secure. Yikes!&lt;/p>

&lt;p>(Chrome will not evaluate or execute code — &lt;em>script content&lt;/em> — from
 non-secure origins when they are included in a page that is from an origin that
 is otherwise secure. Chrome will, however, show you images and other &lt;em>display
 content&lt;/em> from non-secure origins in an a page from a secure origin. It would
 be strictly better to also not show non-secure display content, but we have had
 to make a trade-off for web site compatibility: some origins simply have to
 include non-secure display content.)&lt;/p>

&lt;h2>“You Moved My Cheese!”&lt;/h2>

&lt;p>Some people really like using the Certificate Viewer (CV), and have been
 unpleasantly surprised that we moved it. &lt;a href="https://textslashplain.com/">Eric Lawrence&lt;/a> says that we “moved
 people’s cheese”, and I really feel that because if someone moved my cheese I’d
 be unpleasantly surprised, too.&lt;/p>

&lt;p>I feel very strongly about cheese.&lt;/p>

&lt;p>Most people are mostly happy once they find out that the View Certificate
 button still exists, although there is some understandable grumbling about how
 it now takes more clicks to get to it.&lt;/p>

&lt;p>We made that trade-off knowingly, on the belief that the PIB is a ‘primary’
 UX surface — it has that juicy permissions control panel, after all — and hence
 it should be optimized to serve a more mainstream audience. By contrast, the
 people who want to do things like examine the X.509 certificate details are most
 likely engineers and network administrators, and they’d be better served by a UI
 that shows more detail than just the CV. So, Emily, Lucas, Max, and Paul built
 that.&lt;/p>

&lt;h2>X.509 Certificates And HTTPS Authentication&lt;/h2>

&lt;p>However, it raises a question: What value is there in the full certificate
 details, and who needs or wants those details?&lt;/p>

&lt;p>First, let’s take a look at an example certificate.&lt;/p>

&lt;figure>&lt;img loading="lazy" src="inbox-cv-01.png" alt="Chrome’s CV, showing lots
of details." width="297" height="489" />
 &lt;figcaption>Chrome’s CV, showing lots of
 details.&lt;/figcaption>
&lt;/figure>

&lt;p>Oh, it keeps going, all right:&lt;/p>

&lt;figure>&lt;img loading="lazy" src="inbox-cv-02.png" alt="Even more detail in the
CV." width="294" height="486" />
 &lt;figcaption>Even more detail in the
 CV.&lt;/figcaption>
&lt;/figure>

&lt;p>In these views we can see that the certificate for inbox.google.com was
 issued by “Google Internet Authority G2”, which in turn was issued by “GeoTrust
 Global CA”. We can see that the certificate has serial number 483316...382, what
 algorithm it was signed with and what kind of public key cryptography it uses,
 and so on. And if we selected “Google Internet Authority G2” or “GeoTrust Global
 CA” in the top pane, we’d see the information for those certificates, too.&lt;/p>

&lt;h3>“But what does it all &lt;em>mean&lt;/em>, Basil?”&lt;/h3>

&lt;p>(As Austin Powers famously asked.)&lt;/p>

&lt;p>It means a few surprisingly limited (and even fraught) things:&lt;/p>

&lt;ul>

 &lt;li>Your computer’s operating system trusts a company that calls itself
 “GeoTrust Global CA” to issue (cryptographically sign) certificates that can
 issue certificates for any site on the internet.&lt;/li>

 &lt;li>Whether or not your computer’s (operating system’s) vendor was wise to trust
 these &lt;em>root certificates&lt;/em> (or &lt;em>trust anchors&lt;/em>) is an entirely
 different issue. (Indeed, historically there has been some &lt;a href="/2015/02/21/superfish-round-up/">&lt;em>trust
 rancor...&lt;/em>&lt;/a>)&lt;/li>

 &lt;li>GeoTrust has issued a certificate to an organization calling itself “Google
 Internet Authority G2” (GIA2).&lt;/li>

 &lt;li>GIA2 has issued a certificate for names that end in characters that look on
 your screen like “.google.com”, with at most 1 label before the “.google.com”.
 (DNS hostnames are subdivided into &lt;em>labels&lt;/em>. The name “inbox.google.com”
 has 3 labels: “inbox”, “google”, and “com”.)&lt;/li>

 &lt;li>Chrome has verified that the certificate is allowed (by GIA2) to be used
 with the hostname in the URL, which appears on my screen as
 “https://inbox.google.com/”.&lt;/li>

 &lt;li>The certificate you’re viewing is from the browser’s current connection to
 the server — but that can include revalidating a cached resource. It can happen
 that the resource as cached is still live, but that it was previously retrieved
 on a connection validated by a different certificate chain! So although you can
 check the certificate chain for every connection involved in fetching a page’s
 resources, that is super tedious — and it can’t mean what one might hope it
 means.&lt;/li>

&lt;/ul>

&lt;p>And the CV pointedly does &lt;em>not&lt;/em> mean a few other things:&lt;/p>

&lt;ul>

 &lt;li>Not all strings of text that look the same on the screen are actually the
 same byte values underneath. This is terrible and bad, and is due to the fact
 that &lt;a
 href="https://www.joelonsoftware.com/2003/10/08/the-absolute-minimum-every-software-developer-absolutely-positively-must-know-about-unicode-and-character-sets-no-excuses/">there
 are many &lt;em>character sets&lt;/em> in the world&lt;/a>, and some of them have
 &lt;em>characters&lt;/em> that are very similar, and some of them are displayed with
 similar or identical &lt;a href="https://en.wikipedia.org/wiki/Glyph">&lt;em>glyphs&lt;/em>&lt;/a> by design, and
 sometimes even not by design due to limitations in your operating system’s font
 libraries. And, even if they were always visually distinct, you wouldn’t
 necessarily be able to tell them apart at a glance. This is called the &lt;em>&lt;a
 href="https://en.wikipedia.org/wiki/IDN_homograph_attack">homograph
 attack&lt;/a>&lt;/em>. For an example, compare the Latin ‘A’ (byte value 0x29) to the
 Cyrillic ‘А’ (byte values 0xd090). On my machine, they are pixel-for-pixel
 identical.
 &lt;/li>

 &lt;li>Thus, a certificate issuer might issue a certificate that is perfectly valid
 for a name that looks to humans like, but is not equal to, some other name.&lt;/li>

 &lt;li>Not all of the information in an X.509 certificate, such as Organization,
 Country, Locality, and so on is necessarily true. Many fields in an X.509
 certificate are under the control of attackers trying to forge certificates that
 look good but aren’t. Issuers generally control or validate the many DNS Name
 sub-fields in the Subject Alternative Name field, and the public key is the pair
 of a private key that is computationally infeasible for the attacker to fake.
 (That is, it is not feasible to make a fake public key that would match
 google.com’s real private key.) But the rest... no guarantees.&lt;/li>

 &lt;li>If a certificate chain is valid according to the browser’s validation
 process, that does not actually mean that it is the chain that the true site
 operator intends to use at this time. For example, perhaps 1 of the issuers in
 the chain has been hacked, and attackers are issuing valid but false
 certificates. Or perhaps the certificate chain was valid yesterday, but the site
 operator rotated their keys after a server compromise — and the attacker now
 has, and is using, the old one. Thus, even if you have memorized that
 PayPal.com’s certificate has historically been issued by “Symantec Class 3 EV
 SSL CA - G3”, that doesn’t necessarily mean that’s what PayPal intends
 today.&lt;/li>

&lt;/ul>

&lt;a id="what-about-extended-validation-certificates">&lt;/a>
&lt;h4>What About Extended Validation Certificates?&lt;/h4>

&lt;p>Some web sites use a special mode called Extended Validation (EV), and some
 people believe (not without reason) that the EV process results in an X.509
 certificate in which all the information is true, or at least more true. Or at
 least the Organization and Country fields.&lt;/p>

&lt;p>And, on desktop platforms (only — not mobile), Chrome will show those fields
 in the Location Bar. For example, here is Twitter’s EV certificate:&lt;/p>

&lt;figure>&lt;img loading="lazy" src="twitter-ev.png" alt="Twitter.com uses an EV
certificate calling itself “Twitter, Inc. [US]”." width="330" height="139" />
 &lt;figcaption>Twitter.com uses an EV certificate calling itself
 “Twitter, Inc. [US]”.&lt;/figcaption>
&lt;/figure>

&lt;p>Surely, this is good? It indicates a stronger relationship between the DNS
 name “twitter.com” and the Delaware corporation “Twitter, Inc.”?&lt;/p>

&lt;p>Well, yes and no. First, it’s a &lt;em>Delaware&lt;/em> corporation — hence the
 “[US]”. In other legal jurisdictions, some other entity may call itself
 “Twitter, Inc.”. So, no guarantees. But also, what are we to think when there is
 no obvious relationship between the DNS name and the Organization name?&lt;/p>

&lt;figure>&lt;img loading="lazy" src="yell-ev-hibu.png" alt="Yell.com is owned by
something called “Hibu”, which is located either in the United Kingdom or in
Great Britain." width="353" height="140" />
 &lt;figcaption>Yell.com is owned by
 something called “Hibu”, which is located either in the United Kingdom or in
 Great Britain.&lt;/figcaption>
&lt;/figure>

&lt;p>I enjoy the irony that yell.com is “the UK’s leading online business
 directory” — an organization that should have this name-mapping problem
 solved. Right?&lt;/p>

&lt;p>In addition to having less-than-ideal security UX implications, EV
 certificates do not create a new technical security boundary. The &lt;a href="https://tools.ietf.org/html/rfc6454">web
 origin&lt;/a> is the primary
 defensible security boundary in the open web platform, and &lt;em>it does not
 include any aspect of the certificate&lt;/em>: not the public keys, not the
 Organization name, and not the issuance criteria (EV or other). The origin
 consists only of the scheme, host, and port number that the browser uses to
 connect to the server. For example, for Twitter the tuple is (https,
 twitter.com, 443).&lt;/p>

&lt;h2>So What Does HTTPS Definitely Do?&lt;/h2>

&lt;p>At this point, you might be doubting every pixel on your screen and every
 data field in the obscure 1980s military-grade kludgefest we lovingly call
 “X.5ohgodtheburning”. What can you do to know if you’re connecting to the web
 site you really want to? People don’t have to, &lt;em>and shouldn’t have to&lt;/em>,
 do a whole lot.&lt;/p>

&lt;p>Assuming you have a modern web browser that is up-to-date, you can be
 reasonably certain of some basic facts when you use HTTPS sites:&lt;/p>

&lt;ul>

 &lt;li>If there were anything truly horrible about the server’s TLS protocol
 version, ciphersuites negotiated, or certificate signature crypto, the browser
 would have rejected the connection. (This does happen, and periodically we
 tighten the screws as old crypto dies. Other times, &lt;a
 href="https://blog.chromium.org/2014/09/gradually-sunsetting-sha-1.html">we
 cause the old crypto to die&lt;/a>.)&lt;/li>

 &lt;li>The certificate was issued for a name that matches the hostname in the
 URL.&lt;/li>

 &lt;li>The site’s cookies, local storage, and JavaScript are evaluated in a context
 (the origin) that is more-or-less tied to that hostname. (Sometimes the rules
 are loosened, such that example.com can mix in with foo.example.com. &lt;a
 href="https://code.google.com/archive/p/browsersec/wikis/Part2.wiki">The
 particulars are complicated&lt;/a>.)&lt;/li>

 &lt;li>Also, the site may have included script content from any number of other
 sites. Unfortunately, you must simply assume that the site’s operators verified
 that doing so was safe. (It often isn’t. A really secure site will pull in
 resources only from its own origin.)&lt;/li>

 &lt;li>However, as mentioned above, the browser will not execute script from
 non-secure origins on a page that is otherwise secure.&lt;/li>

 &lt;li>And, as always, sites that do not use HTTPS provide no guarantees at all.
 When there is an active attacker on the network — &lt;a
 href="https://arstechnica.com/tech-policy/2014/09/why-comcasts-javascript-ad-injections-threaten-security-net-neutrality/">and
 when isn’t there, really?&lt;/a> — all non-secure sites are essentially evaluated
 in the same privilege domain: the anonymous, unauthenticated, surveillable
 origin.&lt;/li>

&lt;/ul>

&lt;p>The good news is that most people have nothing to learn from, and thus no
 need for, the level of technical security detail I’ve described in this post.
 Indeed, all this detail is pretty hard even for experts to interpret. It’s
 pretty much only useful to the people actually developing and deploying the web
 site — which is why we moved it to the Developer Tools.&lt;/p>

&lt;h2>The Future&lt;/h2>

&lt;p>There is still the problem that phishing is real (even prevalent), and is a
 highly effective mode of attack. I’m not convinced, at all, that phishing is a
 problem that we can solve with labels, indicators, or icons in an application’s
 UX. Instead, &lt;a
 href="https://www.facebook.com/notes/facebook-security/security-key-for-safer-logins-with-a-touch/10154125089265766/">we
 now have nice origin-bound 2-factor authentication&lt;/a>, and hopefully more and
 more sites will start supporting such very-hard-to-phish credentials.&lt;/p>

&lt;p>In the meantime, we also have the Safe Browsing service (which Safari and
 Firefox also use; it’s open) and Microsoft’s browsers use a similar technology
 called SmartScreen. These services are basically rapidly-updated blacklists of
 known phishing domains. Browsers consult the lists on each page-load.&lt;/p>

&lt;p>To detect certificate misissuance, we have the growing &lt;a
 href="https://www.certificate-transparency.org/">Certificate Transparency&lt;/a>
 (CT) system, in which issuers publicly announce each certificate they’ve issued.
 Site operators who are worried about misissuance for their sites can scan the
 public CT logs (using nifty front-ends like &lt;a href="https://crt.sh/">crt.sh&lt;/a>, or a service like &lt;a
 href="https://sslmate.com/certspotter/">Cert Spotter&lt;/a> that does it for you).
 Eventually, we want to get to where browsers refuse to validate a certificate
 chain that cannot prove that its issuance was announced publicly. We hope this
 will significantly curtail misissuance, possibly including homograph attacks (as
 the log scanners get more sophisticated).&lt;/p>

&lt;aside>
 &lt;p>Thanks to Adrienne Porter Felt, Emily Stark, and Eric Lawrence for
 comments that improved this post! The remaining errors are my fault, of
 course.&lt;/p>
&lt;/aside></description><author>Chris Palmer</author><guid>2017/02/15/decoding-chromes-https-ux/index.html</guid><pubDate>Wed, 15 Feb 2017 00:00:00 +0000</pubDate></item><item><title>Looking Backward To Move Forward In Software Engineering</title><link>https://noncombatant.org/2016/09/16/looking-backward-to-move-forward/index.content</link><description>&lt;h1>Looking Backward To Move Forward In Software Engineering&lt;/h1>

&lt;p>&lt;time>16 September 2016&lt;/time>&lt;/p>

&lt;p>&lt;a href="http://ascii.textfiles.com/archives/5054">Jason Scott has a
delightful blog post&lt;/a> about a hacker, &lt;a
href="https://twitter.com/jbrooksbsi">John Brooks&lt;/a>, who released an update to
Apple’s legacy operating system ProDOS. Without access to source code, Brooks
took the object code of ProDOS 2.0.3 and fixed some of its bugs, added features,
and bundled in some new programs. This is amazing on several levels. I’ll quote
liberally from Scott, but do read the whole enjoyable post:&lt;/p>

&lt;blockquote>

&lt;p>The project is understatement itself, simply called Prodos 2.4. It updates
ProDOS, the last version of which, 2.0.3, was released in 1993.&lt;/p>

&lt;p>[...] compatibility has been repaired for the entire Apple II line, from the
first Apple II through to the Apple IIgs, as well as cases of various versions
of 6502 CPUs [...]. Important utilities related to disk transfer, disk
inspection, and program selection have joined the image. The footprint is
smaller, and it runs faster than its predecessor (a wonder in any case of OS
upgrades).&lt;/p>

&lt;p>First, the pure unique experience of a &lt;em>23-year-gap between upgrades&lt;/em>
means that you can see a rare example of what happens when a computer
environment just sits tight for decades, with many eyes on it and many notes
about how the experience can be improved, followed by someone driven enough to
go through methodically and implement all those requests. [...]&lt;/p>

&lt;p>Next is that this is an operating system upgrade &lt;em>free of commercial and
marketing constraints and drives&lt;/em>. Compared with, say, an iOS upgrade that
trumpets the addition of a search function or blares out a proud announcement
that they broke maps because Google kissed another boy at recess. Or Windows 10,
the 1968 Democratic Convention Riot of Operating Systems, which was designed
from the ground up to be compatible with a variety of mobile/tablet products
that are on the way out, and which were shoved down the throats of current users
with a cajoling, insulting methodology with misleading opt-out routes and
freakier and freakier fake-countdowns.&lt;/p>

&lt;/blockquote>

&lt;p>(Emphasis in original.)&lt;/p>

&lt;p>I had a great time playing with BASIC in &lt;a
href="https://archive.org/details/ProDOS_2_4">the ProDOS 2.4 emulator on
archive.org&lt;/a> last night, and it got me thinking. This ‘primitive’ computing
environment has some advantages that modern systems sometimes lack.&lt;/p>

&lt;dl>

&lt;dt>Immediacy.&lt;/dt> 

&lt;dd>Because it’s small and simple, BASIC starts fast. Some machines of the time
even had BASIC in ROM; some even booted directly into BASIC. Apple BASIC
provides graphics (&lt;code>GR&lt;/code> and &lt;code>HGR&lt;/code>) as well, enabling
people to immediately get started drawing pictures as well as using text mode.
(Python, in a sense a modern BASIC, has &lt;a
href="http://effbot.org/tkinterbook/canvas.htm">similar functionality&lt;/a>, which
is awesome.)&lt;/dd>

&lt;dt>Simplicity and constraints.&lt;/dt>

&lt;dd>Like spreadsheets, BASIC presents an extremely simplified — some would say
fatally limited — model of computation. For example, all variables are global
(!). BASIC has &lt;code>GOTO&lt;/code> and &lt;code>GOSUB&lt;/code>, but most dialects have
no true function calls or exceptions. And so on. But these limitations are not a
problem if the person using the language doesn’t need the features — and it’s
possible to write plenty of useful applications without them. &lt;a
href="http://gizmodo.com/how-steve-wozniak-wrote-basic-for-the-original-apple-fr-1570573636">Steve
Wozniak intended Apple BASIC to be a game development platform&lt;/a>, and &lt;a
href="https://en.wikipedia.org/wiki/Business_Basic">BASIC got a lot of attention
in the business world as well&lt;/a>.&lt;/dd>

&lt;dt>Learnability.&lt;/dt>

&lt;dd>BASIC’s simplicity and constraints make it much easier for people to learn.
There’s simply less to know. We all love C for its compact simplicity, and we
all revile C++ for its complex bloat. And we love how slim our K&amp;amp;Rs are next
to the other tech books on the shelf. But BASIC is so simple that &lt;a
href="http://www.calormen.com/jsbasic/reference.html">Joshua Bell’s Quick
Reference&lt;/a> gives people most of what they would need to write programs near
the upper range of what BASIC is capable of.&lt;/dd>

&lt;/dl>

&lt;p>Obviously, I don’t want to give up the nice modern goodness we have. I like
my hundreds of gigabytes of music, wifi, maps, and the modern web. But I think
it’s hugely important for all software engineers to at least dabble in
retrocomputing once in a while, so that we can see what we’ve lost and what good
lessons we’ve forgotten over the decades.&lt;/p>

&lt;p>We have, in fact, lost and forgotten many things. Software is not, in fact,
necessarily getting better over time; I often feel that we are treading water
and only making insignificant changes in the margins. Worse, basic
infrastructure code for the entire Internet is &lt;a
href="https://en.wikipedia.org/wiki/Libtiff#Website_hijacking">close to being
unmaintained&lt;/a> and is &lt;a
href="http://blog.npmjs.org/post/141577284765/kik-left-pad-and-npm">at risk of
exploding randomly&lt;/a>. We’ve forgotten that stability, by itself, is a feature.
Simplicity, by itself, is a feature. Knowability, learnability, and hackability
are features. (Hackability: I’d bet it’s easier to learn 6502 assembly and patch
a binary than it is to get a truly great result while maintaining code written
in a modern JavaScript front-end framework.)&lt;/p>

&lt;p>A lot of what we are building now seems to be what engineers and other
technical people want, or what their host corporations want, rather than
directly responding to real people’s real computing needs. When Bricklin and
Frankston shipped &lt;a href="https://en.wikipedia.org/wiki/VisiCalc">VisiCalc&lt;/a>,
it directly responded to people’s needs. Even though spreadsheets present a very
limited model of computation, they present a model that people can learn and use
and which is sufficient to solve real problems. You really can run a business
from Microsoft Excel, and people do. Meanwhile, Apple iTunes seems to get more
mazelike with each release...&lt;/p>

&lt;p>At this point, hackers in the audience are getting nervous about all my
cheerleading for non-general-purpose computers. What about &lt;a
href="http://papers.ssrn.com/sol3/papers.cfm?abstract_id=847124">generativity&lt;/a>,
for which we require fully general models of computing? Obviously we
&lt;em>technical people&lt;/em> need that. But general models of computing are not
necessarily what most people need from a machine or software product. And many
or most of the problems people have with computers — unexplainable errors,
malware, unnecessary bugs, and more — are the direct or indirect result of
giving people hacker machines when what they wanted was a spreadsheet
machine.&lt;/p>

&lt;p>Presenting limited models of computing is &lt;em>not&lt;/em> (necessarily) ‘dumbing
the system down’. A system whose users perceive it to be dumbed down is one that
is not sufficient for its purpose, and sufficiency is still our minimum bar for
shipping. Rather, by presenting people systems that they can learn and use to
solve problems, we are &lt;em>enhancing the human&lt;/em>. Consider that presenting a
bash prompt, although it’s incredibly powerful, does not actually empower most
people. Instead, it confuses and disheartens — disempowers — them.&lt;/p>

&lt;p>We technical people need to change our recipe for building and delivering
software. We should not serve only ourselves; we should make sure we’re not
doing something just because we can; we should not love complexity for its own
sake. I’d like to see us follow a recipe more like this:&lt;/p>

&lt;ol>

&lt;li>Find out what someone’s problem is.&lt;/li>

&lt;li>Produce something that is sufficient to solve that problem.&lt;/li>

&lt;li>At this point, the solution is likely to be simple, because it is merely
sufficient. Make the most of the glorious limitations:&lt;/li>

&lt;ul>

&lt;li>The system is small enough for you to document comprehensively. Maybe you
can even document the internals a bit, so that nerds can tinker with it.&lt;/li>

&lt;li>Spend time polishing the simple UX. Go through every possible flow, and make
sure they are all necessary, and as smooth as possible.&lt;/li>

&lt;li>There are fewer bugs, right?&lt;/li>

&lt;li>It should be fast (to run, download, install, et c.), since it’s sufficient
(small) instead of general (large). Make sure that’s that case.&lt;/li>

&lt;/ul>

&lt;li>Iterate, but only if necessary and in response to people’s needs. Take your
time, even as long as 23 years.&lt;/li>

&lt;/ol></description><author>Chris Palmer</author><guid>2016/09/16/looking-backward-to-move-forward/index.html</guid><pubDate>Fri, 16 Sep 2016 00:00:00 +0000</pubDate></item><item><title>Getting Into Security Engineering</title><link>https://noncombatant.org/2016/06/20/get-into-security-engineering/index.content</link><description>&lt;h1>Getting Into Security Engineering&lt;/h1>

&lt;p>&lt;time>20 June 2016&lt;/time>&lt;/p>

&lt;aside>&lt;p>Update 2016-07-06: I added 2 additional books to the reading
suggestions at the bottom.&lt;/p>&lt;/aside>

&lt;aside>&lt;p>Update 2016-07-28: You’ll definitely also want to read my excellent
colleague &lt;a
href="https://medium.com/@laparisa/so-you-want-to-work-in-security-bc6c10157d23">Parisa
Tabriz’ take on the same topic&lt;/a>.&lt;/p>&lt;/aside>

&lt;p>I’ve been talking with various people lately about how to get started in
software security engineering. I noticed I’ve been having similar conversations
with both newbies and experienced engineers, and I figured I should write things
down in 1 place rather than keep repeating myself! I hope someone will find this
useful.&lt;/p>

&lt;h2>Know Your Reasons&lt;/h2>

&lt;p>Know your reasons for wanting to specialize in security. Here are some
examples; you’ll probably have more of your own:&lt;/p>

&lt;ul>

&lt;li>The intellectual challenge excites you&lt;/li>

&lt;li>You want to help people by making software safer&lt;/li>

&lt;li>You want to help people by stopping or catching crime&lt;/li>

&lt;li>You want to refute, ✨with science✨, the false and dangerous claims that
software vendors sometimes make&lt;/li>

&lt;li>You want to help people by &lt;a
href="https://en.wikipedia.org/wiki/Privilege_escalation#Jailbreaking">giving
them control of closed platforms&lt;/a>&lt;/li>

&lt;li>You like the money&lt;/li>

&lt;li>...&lt;/li>

&lt;/ul>

&lt;p>You might want to rank your reasons, so that when you’re faced with career
choices you know what path to follow. For example, you might have a job you like
because it’s intellectually challenging, but someone comes along and offers you
more money to do less-interesting work. You’ll have to decide which is more
important to you. I find it comforting to have ranked my reasons and goals ahead
of time, because for me it makes the choices much less stressful. And you will
most certainly need a moral compass as you progress through this adventure.&lt;/p>

&lt;h2>Go For It!&lt;/h2>

&lt;p>You can, and should, get started right away! Yes, there is a lot to learn,
but you can do it, and you can start being effective immediately. I know this
from first-hand experience, and from seeing other people do it. You might feel
daunted by the size of the problem — everyone is, whether they admit it or not.
The only way anyone has ever made progress is bit by bit, and you can too.&lt;/p>

&lt;p>There are more security problems right now than there are problem solvers. We
need you!&lt;/p>

&lt;h2>Security Engineering Is Just Engineering&lt;/h2>

&lt;p>Security is a specialization within the overall field of software
engineering. In that sense, it is no different than any other specialization
like networking, databases, performance, games, or whatever else. And software
engineering is much more than just reading and writing code — it also includes
design, technical and non-technical writing and communication, interpersonal and
political skills, at least some understanding of business and economics, and
more. Security engineers need those skills, too. Code is definitely important
but it is not the whole story.&lt;/p>

&lt;p>You can learn the general partly by focusing on the specific — and you can
learn the specific by learning the general. That is, you can learn engineering
by diving right into security specifically, and you can also learn about
security by learning engineering generally. (After all, security is really just
another form of engineering quality.)&lt;/p>

&lt;p>I find it’s best to try to view things from both perspectives. In my
experience, it has been productive to focus on security specifically for a
while, then focus on application development for a while, and then iterate.&lt;/p>

&lt;p>Within the field of software security engineering, there are
sub-specializations. My main area is application security engineering: figuring
out what kinds of assets and attacks on those assets are relevant in a
particular application’s domain, and then trying to design and implement the
application to best defend its assets. But there are other sub-specializations
in security, such as digital forensics and incident response (DFIR), network
security, anti-fraud (a close relative of actuarial science and statistics),
anti-abuse/pro-social design, and more.&lt;/p>

&lt;h2>The Security Mindset: Doubt Abstractions And Dependencies&lt;/h2>

&lt;p>The most important thing about a good security engineer is their mindset:
skeptical. A regular engineer is trying to build something that works; a
security engineer is anxious until they’ve found a few new ways in which it
doesn’t work.&lt;/p>

&lt;p>Much of computing science and software engineering is about managing
complexity by creating abstractions. For example, consider this Python code:&lt;/p>

&lt;pre>
f = open("something.txt", "r")
&lt;/pre>

&lt;p>Python gives us this simple way to say, “Give me an object that represents a
persistent data store, and let me read that data.” But that straightforward code
hides tons and tons of complexity. For example, we have no idea (without reading
the Python interpreter and standard library source code) exactly how that object
&lt;code>f&lt;/code> works (nor what it costs). It could be a thin wrapper around the
C library’s &lt;code>FILE&lt;/code> type, which itself is a rather thick (and useful)
wrapper around the operating system’s &lt;em>file descriptor&lt;/em> or
&lt;em>handle&lt;/em> concept. In turn, file descriptors are abstract representations
of a wide variety of hardware and software systems:&lt;/p>

&lt;ul>

&lt;li>Possibly volatile, possibly not&lt;/li>

&lt;li>Possibly stored on a device attached to this computer — or possibly
remote, retrieved over the network in a way that might violate your expectations
for integrity or confidentiality&lt;/li>

&lt;li>Possibly stored on any kind of hardware: spinning disk, tape, SSD — all with
wildly different performance and reliability properties&lt;/li>

&lt;li>Possibly cached at 1 or more places in the &lt;a
href="https://en.wikipedia.org/wiki/Memory_hierarchy">memory hierarchy&lt;/a> — and
possibly stale or inconsistent&lt;/li>

&lt;/ul>

&lt;p>The &lt;em>pathname&lt;/em> of the file, in this case &lt;code>something.txt&lt;/code>,
is also a very high-level abstraction. Different platforms implement different
pathname interpretation semantics, but most do a lot of work to hide complexity.
For example, on Unix-like platforms, pathnames can refer to a variety of kinds
of things:&lt;/p>

&lt;ul>

&lt;li>Hardware devices (e.g. &lt;code>/dev/disk1&lt;/code>)&lt;/li>

&lt;li>Software ‘pseudo-devices’ (e.g. &lt;code>/dev/pty0&lt;/code>)&lt;/li>

&lt;li>Special operating system facilities (e.g. &lt;code>/dev/bpf3&lt;/code>,
&lt;code>/dev/urandom&lt;/code>)&lt;/li>

&lt;li>Remote services on the network (e.g.
&lt;code>/mnt/nfs/your-companys-file-server/accounting/FY2016Q3
Report.xls&lt;/code>)&lt;/li>

&lt;li>And more...&lt;/li>

&lt;/ul>

&lt;p>&lt;a
href="https://googleprojectzero.blogspot.com/2016/02/the-definitive-guide-on-win32-to-nt.html">Windows
systems have even stranger pathname semantics&lt;/a>. PHP will also interpret
pathnames as URLs and &lt;a href="http://php.net/manual/en/wrappers.php">will
perform certain transformations of the data based on the URL scheme!&lt;/a>&lt;/p>

&lt;h3>Abstractions Are Lossy — And Vulnerable&lt;/h3>

&lt;p>They have to be — that’s their value! The purpose of an abstraction is to
hide complexity, and thereby help you get work done faster. An abstraction that
does not hide something from its caller is not an abstraction at all.&lt;/p>

&lt;p>But a security engineer is always skeptical, because they know that in the
gap between what the abstraction &lt;em>seems to provide&lt;/em> and what it
&lt;em>actually provides&lt;/em>, there are exploitable vulnerabilities.&lt;/p>

&lt;p>Neal Stephenson called this &lt;em>metaphor shear&lt;/em> (like windshear) in his
hilarious essay &lt;a
href="https://www.amazon.com/Beginning-was-Command-Line/dp/0380815931/">In The
Beginning Was The Command Line&lt;/a>.&lt;/p>

&lt;p>In general, it’s good engineering practice to &lt;strong>understand the layer
below where you’re working, and understand the layer above&lt;/strong>. Another way
to say this is, &lt;a
href="/2014/08/10/security-as-a-class-of-interface-guarantee/">&lt;strong>know your
callees, and know your callers&lt;/strong>&lt;/a>. The difference between an engineer
and a security engineer is that the security engineer is looking for the tension
and friction in those edges.&lt;/p>

&lt;h2>Skills&lt;/h2>

&lt;p>For the rest of this post, I’ll talk about what skills I have found useful in
application security. But there are other areas, and other paths into them
— this is just one person’s perspective!&lt;/p>

&lt;h3>Foundations&lt;/h3>

&lt;p>Certain skills will be of use throughout your career and will help you build
a foundation from which you can learn anything else you need to learn.&lt;/p>

&lt;ul>

&lt;li>Know at least 1 programming language (C, Ruby, Python, Java, et c.) in
depth.&lt;/li>

&lt;li>Know the standard library of your programming language as well as possible.
This includes collections types (lists, &lt;a
href="/2014/03/02/maps-and-their-applications/">maps&lt;/a>, et c.), basic file
I/O, basic networking, basic text processing, and so on.&lt;/li>

&lt;li>Know at least 1 platform (iOS, Linux, web, Windows, et c.) in depth.&lt;/li>

&lt;li>Know at least the basics of TCP/IP. Spend some quality time with &lt;a
href="https://www.amazon.com/TCP-Illustrated-Protocols-Addison-Wesley-Professional/dp/0321336313/">&lt;em>TCP/IP
Illustrated&lt;/em>&lt;/a> and &lt;a
href="https://www.wireshark.org/">Wireshark&lt;/a>.&lt;/li>

&lt;/ul>

&lt;h3>Progressing&lt;/h3>

&lt;p>After some years building your foundations, there are more things to learn
and more adventures to enjoy. Here are some:&lt;/p>

&lt;ul>

&lt;li>Master additional languages and platforms&lt;/li>

&lt;li>Contribute to the implementation of a language or platform&lt;/li>

&lt;li>Learn about cryptography, and what it does and does not provide&lt;/li>

&lt;li>Learn about hardware engineering&lt;/li>

&lt;li>Learn programming language theory&lt;/li>

&lt;li>Branch out into platform security engineering (changing platforms, and
developing new platforms, to better serve application security needs)&lt;/li>

&lt;li>Study distributed systems theory&lt;/li>

&lt;li>Learn about performance engineering — it’s important to make sure that
security mechanisms are not the cause of performance problems!&lt;/li>

&lt;li>Learn user experience design, so you can build secure &lt;a
href="https://eprint.iacr.org/2007/399.pdf">&lt;em>ceremonies&lt;/em>&lt;/a>&lt;/li>

&lt;/ul>

&lt;h2>Some Light Reading&lt;/h2>

&lt;p>To thoroughly learn a programming language, I find it useful to read 1 very
well written book that covers the language’s syntax, semantics, standard
library, and usage conventions. I like to read the book cover to cover, and then
re-read all or part of it periodically. Preferably, 1 or more of the language’s
inventors or implementors should have written the book. The canonical example is
&lt;em>The C Programming Language&lt;/em> by Kernighan and Ritchie, and other books
have continued and improved on the tradition: &lt;em>The Go Programming
Language&lt;/em> by Donovan and Kernighan; &lt;em>JavaScript: The Definitive
Guide&lt;/em> by Flanagan; &lt;em>The Java Programming Language&lt;/em> by Arnold,
Gosling, and Holmes; and &lt;em>Effective C++&lt;/em> by Meyers. People on Twitter say
that &lt;a href="http://docs.python-guide.org/en/latest/">&lt;em>The Hitchhiker’s
Guide To Python&lt;/em>&lt;/a> by Reitz is a good Python book.&lt;/p>

&lt;p>Saltzer and Schroeder’s &lt;a
href="http://www.cs.virginia.edu/~evans/cs551/saltzer/">&lt;em>The Protection Of
Information In Computer Systems&lt;/em>&lt;/a> is a foundational text.&lt;/p>

&lt;p>For web security, I recommend &lt;em>The Tangled Web&lt;/em> by &lt;a
href="http://lcamtuf.coredump.cx/">Michal Zalewski&lt;/a>. Zalewski also has
another excellent book, &lt;em>Silence On The Wire&lt;/em>, about techniques for
passive surveillance in a variety of domains. Zalewski is also the author of &lt;a
href="http://lcamtuf.coredump.cx/afl/">American Fuzzy Lop&lt;/a>, an excellent &lt;a
href="https://en.wikipedia.org/wiki/Fuzz_testing">fuzzer&lt;/a>.&lt;/p>

&lt;p>&lt;em>Cryptography Engineering&lt;/em> by Ferguson, Schneier, and Kohno is a good
introduction to applied cryptography.&lt;/p>

&lt;p>&lt;em>TCP/IP Illustrated&lt;/em>, at least volume 1, is crucial.&lt;/p>

&lt;p>For understanding C and doing reverse engineering, you’ll want a good
assembly language book, such as &lt;a
href="https://www.nostarch.com/assembly2.htm">&lt;em>Art Of Assembly Language&lt;/em>
by Hyde&lt;/a>.&lt;/p>

&lt;p>Ross Anderson’s excellent omnibus, &lt;em>Security Engineering&lt;/em>, is &lt;a
href="http://www.cl.cam.ac.uk/~rja14/book.html">available online&lt;/a> and on
paper. Another great book is &lt;a
href="https://www.amazon.com/Art-Software-Security-Assessment-Vulnerabilities/dp/0321444426">&lt;em>The
Art Of Software Security Assessment&lt;/em>&lt;/a> by Dowd, McDonald, and Schuh.&lt;/p>

&lt;p>There are many also good blogs and magazines. A random sampling might include
&lt;a href="https://googleprojectzero.blogspot.com/">the Project Zero blog&lt;/a>, &lt;a
href="https://www.alchemistowl.org/pocorgtfo/">PoC||GTFO&lt;/a>, &lt;a
href="http://blog.invisiblethings.org/">Joanna Rutkowska’s blog&lt;/a>, and &lt;a
href="http://blog.cryptographyengineering.com">Matthew Green’s blog&lt;/a>.&lt;/p></description><author>Chris Palmer</author><guid>2016/06/20/get-into-security-engineering/index.html</guid><pubDate>Mon, 20 Jun 2016 00:00:00 +0000</pubDate></item><item><title>Building A Telecaster</title><link>https://noncombatant.org/2016/06/12/building-guitar/index.content</link><description>&lt;h1>Building A Telecaster&lt;/h1>

&lt;p>&lt;time>12 June 2016&lt;/time>&lt;/p>

&lt;p>Last week, I built a Telecaster guitar from scratch, under the excellent
 tutelage of luthier &lt;a href="http://www.meredithcoloma.com/">Meredith
 Coloma&lt;/a>, in Vancouver. It was an exciting and at times harrowing adventure!
 We spent 7 rather exhausting but rewarding days in Meredith’s shop. Meredith is
 a fantastic luthier but also a great teacher! And she went above and beyond the
 call of duty several times for me, so I feel super lucky!&lt;/p>

&lt;p>I have built many guitars and basses (all the ones I play regularly) from &lt;a
 href="https://en.wikipedia.org/wiki/Milling_(machining)">CNC-milled&lt;/a>, pre-fab
 parts (thanks, &lt;a href="http://www.warmoth.com/">Warmoth!&lt;/a>), but I had never
 before built a guitar from scratch — just chunks of wood. Meredith offers
 classes in guitar building, so I signed up!&lt;/p>

&lt;p>It was really stressful to be a total newbie. I had never used most of the
 tools Meredith taught me to use, and I was very afraid of wrecking the wood. But
 now I know at least 1 thing about instrument building, and I’m already planning
 my next instrument. :)&lt;/p>

&lt;p>Here’s a sound sample:&lt;/p>

&lt;audio controls>
 &lt;source src="afrerika.mp3" />
 &lt;a href="afrerika.mp3">Download&lt;/a>
&lt;/audio>

&lt;p>Here are some pictures:&lt;/p>

&lt;figure>&lt;img src="1648.jpg" loading="lazy" width="512" height="512" alt="Photo" />
 &lt;figcaption>&lt;/figcaption>
&lt;/figure>
&lt;figure>&lt;img src="1649.jpg" loading="lazy" width="512" height="512" alt="Photo" />
 &lt;figcaption>&lt;/figcaption>
&lt;/figure>
&lt;figure>&lt;img src="1650.jpg" loading="lazy" width="512" height="512" alt="Photo" />
 &lt;figcaption>&lt;/figcaption>
&lt;/figure>
&lt;figure>&lt;img src="1651.jpg" loading="lazy" width="512" height="512" alt="Photo" />
 &lt;figcaption>&lt;/figcaption>
&lt;/figure>
&lt;figure>&lt;img src="1652.jpg" loading="lazy" width="512" height="512" alt="Photo" />
 &lt;figcaption>&lt;/figcaption>
&lt;/figure>
&lt;figure>&lt;img src="1653.jpg" loading="lazy" width="512" height="512" alt="Photo" />
 &lt;figcaption>&lt;/figcaption>
&lt;/figure>
&lt;figure>&lt;img src="1654.jpg" loading="lazy" width="512" height="512" alt="Photo" />
 &lt;figcaption>&lt;/figcaption>
&lt;/figure>
&lt;figure>&lt;img src="1655.jpg" loading="lazy" width="512" height="512" alt="Photo" />
 &lt;figcaption>&lt;/figcaption>
&lt;/figure>
&lt;figure>&lt;img src="1657.jpg" loading="lazy" width="512" height="512" alt="Photo" />
 &lt;figcaption>&lt;/figcaption>
&lt;/figure>
&lt;figure>&lt;img src="1659.jpg" loading="lazy" width="512" height="512" alt="Photo" />
 &lt;figcaption>&lt;/figcaption>
&lt;/figure>
&lt;figure>&lt;img src="1660.jpg" loading="lazy" width="512" height="512" alt="Photo" />
 &lt;figcaption>&lt;/figcaption>
&lt;/figure>
&lt;figure>&lt;img src="1661.jpg" loading="lazy" width="512" height="512" alt="Photo" />
 &lt;figcaption>&lt;/figcaption>
&lt;/figure>
&lt;figure>&lt;img src="1662.jpg" loading="lazy" width="512" height="512" alt="Photo" />
 &lt;figcaption>&lt;/figcaption>
&lt;/figure>
&lt;figure>&lt;img src="1663.jpg" loading="lazy" width="512" height="512" alt="Photo" />
 &lt;figcaption>&lt;/figcaption>
&lt;/figure>
&lt;figure>&lt;img src="1666.jpg" loading="lazy" width="512" height="512" alt="Photo" />
 &lt;figcaption>&lt;/figcaption>
&lt;/figure>
&lt;figure>&lt;img src="1667.jpg" loading="lazy" width="512" height="512" alt="Photo" />
 &lt;figcaption>&lt;/figcaption>
&lt;/figure>
&lt;figure>&lt;img src="1668.jpg" loading="lazy" width="512" height="512" alt="Photo" />
 &lt;figcaption>&lt;/figcaption>
&lt;/figure>
&lt;figure>&lt;img src="1670.jpg" loading="lazy" width="512" height="512" alt="Photo" />
 &lt;figcaption>&lt;/figcaption>
&lt;/figure>
&lt;figure>&lt;img src="1671.jpg" loading="lazy" width="512" height="512" alt="Photo" />
 &lt;figcaption>&lt;/figcaption>
&lt;/figure>
&lt;figure>&lt;img src="1672.jpg" loading="lazy" width="512" height="512" alt="Photo" />
 &lt;figcaption>&lt;/figcaption>
&lt;/figure>
&lt;figure>&lt;img src="1673.jpg" loading="lazy" width="512" height="512" alt="Photo" />
 &lt;figcaption>&lt;/figcaption>
&lt;/figure>
&lt;figure>&lt;img src="1674.jpg" loading="lazy" width="512" height="512" alt="Photo" />
 &lt;figcaption>&lt;/figcaption>
&lt;/figure>
&lt;figure>&lt;img src="1675.jpg" loading="lazy" width="512" height="512" alt="Photo" />
 &lt;figcaption>&lt;/figcaption>
&lt;/figure>
&lt;figure>&lt;img src="1676.jpg" loading="lazy" width="512" height="512" alt="Photo" />
 &lt;figcaption>&lt;/figcaption>
&lt;/figure>
&lt;figure>&lt;img src="1678.jpg" loading="lazy" width="512" height="512" alt="Photo" />
 &lt;figcaption>&lt;/figcaption>
&lt;/figure>
&lt;figure>&lt;img src="1682.jpg" loading="lazy" width="512" height="512" alt="Photo" />
 &lt;figcaption>&lt;/figcaption>
&lt;/figure>
&lt;figure>&lt;img src="1683.jpg" loading="lazy" width="512" height="512" alt="Photo" />
 &lt;figcaption>&lt;/figcaption>
&lt;/figure>
&lt;figure>&lt;img src="1691.jpg" loading="lazy" width="512" height="512" alt="Photo" />
 &lt;figcaption>&lt;/figcaption>
&lt;/figure>
&lt;figure>&lt;img src="1695.jpg" loading="lazy" width="512" height="512" alt="Photo" />
 &lt;figcaption>&lt;/figcaption>
&lt;/figure>
&lt;figure>&lt;img src="1696.jpg" loading="lazy" width="512" height="512" alt="Photo" />
 &lt;figcaption>&lt;/figcaption>
&lt;/figure>
&lt;figure>&lt;img src="1697.jpg" loading="lazy" width="512" height="512" alt="Photo" />
 &lt;figcaption>&lt;/figcaption>
&lt;/figure>
&lt;figure>&lt;img src="1698.jpg" loading="lazy" width="512" height="512" alt="Photo" />
 &lt;figcaption>&lt;/figcaption>
&lt;/figure>
&lt;figure>&lt;img src="1699.jpg" loading="lazy" width="512" height="512" alt="Photo" />
 &lt;figcaption>&lt;/figcaption>
&lt;/figure>
&lt;figure>&lt;img src="1705.jpg" loading="lazy" width="512" height="512" alt="Photo" />
 &lt;figcaption>&lt;/figcaption>
&lt;/figure>
&lt;figure>&lt;img src="1709.jpg" loading="lazy" width="512" height="512" alt="Photo" />
 &lt;figcaption>&lt;/figcaption>
&lt;/figure>
&lt;figure>&lt;img src="1710.jpg" loading="lazy" width="512" height="512" alt="Photo" />
 &lt;figcaption>&lt;/figcaption>
&lt;/figure>
&lt;figure>&lt;img src="1711.jpg" loading="lazy" width="512" height="512" alt="Photo" />
 &lt;figcaption>&lt;/figcaption>
&lt;/figure>
&lt;figure>&lt;img src="1712.jpg" loading="lazy" width="512" height="512" alt="Photo" />
 &lt;figcaption>&lt;/figcaption>
&lt;/figure>
&lt;figure>&lt;img src="1713.jpg" loading="lazy" width="512" height="512" alt="Photo" />
 &lt;figcaption>&lt;/figcaption>
&lt;/figure>
&lt;figure>&lt;img src="1715.jpg" loading="lazy" width="512" height="512" alt="Photo" />
 &lt;figcaption>&lt;/figcaption>
&lt;/figure>
&lt;figure>&lt;img src="1720.jpg" loading="lazy" width="512" height="512" alt="Photo" />
 &lt;figcaption>&lt;/figcaption>
&lt;/figure>
&lt;figure>&lt;img src="1721.jpg" loading="lazy" width="512" height="512" alt="Photo" />
 &lt;figcaption>&lt;/figcaption>
&lt;/figure>
&lt;figure>&lt;img src="1724.jpg" loading="lazy" width="512" height="512" alt="Photo" />
 &lt;figcaption>&lt;/figcaption>
&lt;/figure>
&lt;figure>&lt;img src="1725.jpg" loading="lazy" width="512" height="512" alt="Photo" />
 &lt;figcaption>&lt;/figcaption>
&lt;/figure>
&lt;figure>&lt;img src="1726.jpg" loading="lazy" width="512" height="512" alt="Photo" />
 &lt;figcaption>&lt;/figcaption>
&lt;/figure>
&lt;figure>&lt;img src="1727.jpg" loading="lazy" width="512" height="512" alt="Photo" />
 &lt;figcaption>&lt;/figcaption>
&lt;/figure>
&lt;figure>&lt;img src="1729.jpg" loading="lazy" width="512" height="512" alt="Photo" />
 &lt;figcaption>&lt;/figcaption>
&lt;/figure>
&lt;figure>&lt;img src="1731.jpg" loading="lazy" width="512" height="512" alt="Photo" />
 &lt;figcaption>&lt;/figcaption>
&lt;/figure>
&lt;figure>&lt;img src="1734.jpg" loading="lazy" width="512" height="512" alt="Photo" />
 &lt;figcaption>&lt;/figcaption>
&lt;/figure>
&lt;figure>&lt;img src="1735.jpg" loading="lazy" width="512" height="512" alt="Photo" />
 &lt;figcaption>&lt;/figcaption>
&lt;/figure>
&lt;figure>&lt;img src="1736.jpg" loading="lazy" width="512" height="512" alt="Photo" />
 &lt;figcaption>&lt;/figcaption>
&lt;/figure>
&lt;figure>&lt;img src="1737.jpg" loading="lazy" width="512" height="512" alt="Photo" />
 &lt;figcaption>&lt;/figcaption>
&lt;/figure>
&lt;figure>&lt;img src="1738.jpg" loading="lazy" width="512" height="512" alt="Photo" />
 &lt;figcaption>&lt;/figcaption>
&lt;/figure>
&lt;figure>&lt;img src="1739.jpg" loading="lazy" width="512" height="512" alt="Photo" />
 &lt;figcaption>&lt;/figcaption>
&lt;/figure>
&lt;figure>&lt;img src="1740.jpg" loading="lazy" width="512" height="512" alt="Photo" />
 &lt;figcaption>&lt;/figcaption>
&lt;/figure>
&lt;figure>&lt;img src="1742.jpg" loading="lazy" width="512" height="512" alt="Photo" />
 &lt;figcaption>&lt;/figcaption>
&lt;/figure>
&lt;figure>&lt;img src="1746.jpg" loading="lazy" width="512" height="512" alt="Photo" />
 &lt;figcaption>&lt;/figcaption>
&lt;/figure>
&lt;figure>&lt;img src="1748.jpg" loading="lazy" width="512" height="512" alt="Photo" />
 &lt;figcaption>&lt;/figcaption>
&lt;/figure>
&lt;figure>&lt;img src="1749.jpg" loading="lazy" width="512" height="512" alt="Photo" />
 &lt;figcaption>&lt;/figcaption>
&lt;/figure>
&lt;figure>&lt;img src="1750.jpg" loading="lazy" width="512" height="512" alt="Photo" />
 &lt;figcaption>&lt;/figcaption>
&lt;/figure>
&lt;figure>&lt;img src="1751.jpg" loading="lazy" width="512" height="512" alt="Photo" />
 &lt;figcaption>&lt;/figcaption>
&lt;/figure>
&lt;figure>&lt;img src="1752.jpg" loading="lazy" width="512" height="512" alt="Photo" />
 &lt;figcaption>&lt;/figcaption>
&lt;/figure>
&lt;figure>&lt;img src="1753.jpg" loading="lazy" width="512" height="512" alt="Photo" />
 &lt;figcaption>&lt;/figcaption>
&lt;/figure>
&lt;figure>&lt;img src="1755.jpg" loading="lazy" width="512" height="512" alt="Photo" />
 &lt;figcaption>&lt;/figcaption>
&lt;/figure>
&lt;figure>&lt;img src="1756.jpg" loading="lazy" width="512" height="512" alt="Photo" />
 &lt;figcaption>&lt;/figcaption>
&lt;/figure>
&lt;figure>&lt;img src="1757.jpg" loading="lazy" width="512" height="512" alt="Photo" />
 &lt;figcaption>&lt;/figcaption>
&lt;/figure>
&lt;figure>&lt;img src="1758.jpg" loading="lazy" width="512" height="512" alt="Photo" />
 &lt;figcaption>&lt;/figcaption>
&lt;/figure>
&lt;figure>&lt;img src="1759.jpg" loading="lazy" width="512" height="512" alt="Photo" />
 &lt;figcaption>&lt;/figcaption>
&lt;/figure>
&lt;figure>&lt;img src="1762.jpg" loading="lazy" width="512" height="512" alt="Photo" />
 &lt;figcaption>&lt;/figcaption>
&lt;/figure>
&lt;figure>&lt;img src="1763.jpg" loading="lazy" width="512" height="512" alt="Photo" />
 &lt;figcaption>&lt;/figcaption>
&lt;/figure>
&lt;figure>&lt;img src="1764.jpg" loading="lazy" width="512" height="512" alt="Photo" />
 &lt;figcaption>&lt;/figcaption>
&lt;/figure>
&lt;figure>&lt;img src="1767.jpg" loading="lazy" width="512" height="512" alt="Photo" />
 &lt;figcaption>&lt;/figcaption>
&lt;/figure>
&lt;figure>&lt;img src="1768.jpg" loading="lazy" width="512" height="512" alt="Photo" />
 &lt;figcaption>&lt;/figcaption>
&lt;/figure>
&lt;figure>&lt;img src="1769.jpg" loading="lazy" width="512" height="512" alt="Photo" />
 &lt;figcaption>&lt;/figcaption>
&lt;/figure>
&lt;figure>&lt;img src="1770.jpg" loading="lazy" width="512" height="512" alt="Photo" />
 &lt;figcaption>&lt;/figcaption>
&lt;/figure>
&lt;figure>&lt;img src="1771.jpg" loading="lazy" width="512" height="512" alt="Photo" />
 &lt;figcaption>&lt;/figcaption>
&lt;/figure>
&lt;figure>&lt;img src="1772.jpg" loading="lazy" width="512" height="512" alt="Photo" />
 &lt;figcaption>&lt;/figcaption>
&lt;/figure>
&lt;figure>&lt;img src="1773.jpg" loading="lazy" width="512" height="512" alt="Photo" />
 &lt;figcaption>&lt;/figcaption>
&lt;/figure>
&lt;figure>&lt;img src="1775.jpg" loading="lazy" width="512" height="512" alt="Photo" />
 &lt;figcaption>&lt;/figcaption>
&lt;/figure>
&lt;figure>&lt;img src="1778.jpg" loading="lazy" width="512" height="512" alt="Photo" />
 &lt;figcaption>&lt;/figcaption>
&lt;/figure>
&lt;figure>&lt;img src="1780.jpg" loading="lazy" width="512" height="512" alt="Photo" />
 &lt;figcaption>&lt;/figcaption>
&lt;/figure>
&lt;figure>&lt;img src="1781.jpg" loading="lazy" width="512" height="512" alt="Photo" />
 &lt;figcaption>&lt;/figcaption>
&lt;/figure>
&lt;figure>&lt;img src="1787.jpg" loading="lazy" width="512" height="512" alt="Photo" />
 &lt;figcaption>&lt;/figcaption>
&lt;/figure></description><author>Chris Palmer</author><guid>2016/06/12/building-guitar/index.html</guid><pubDate>Sun, 12 Jun 2016 00:00:00 +0000</pubDate></item><item><title>To Make Good Software, Make Software For People</title><link>https://noncombatant.org/2016/06/01/constituencies-and-quality/index.content</link><description>&lt;h1>To Make Good Software, Make Software For People&lt;/h1>

&lt;p>&lt;time>1 June 2016&lt;/time>&lt;/p>

&lt;p>Reading the new &lt;a href="https://duo.com/assets/pdf/out-of-box-exploitation_oem-updaters.pdf">Duo
 Labs report on Windows OEM bloatware vulnerabilities, “Out-Of-Box
 Exploitation”&lt;/a>, I was struck by a thought: the reason Apple hardware does not
 have the vulnerable bloatware problem is that Apple does not have a bloatware
 problem at all. And the reason for that is that Apple prioritizes the customer’s
 happiness above all, and the out-of-box experience in particular. So much so, in
 fact, that people fetishize taking the product out of its packaging. This video,
 one of who-knows-how-many, has 737,414 views on YouTube:&lt;/p>

&lt;iframe width="560" height="315" src="https://www.youtube.com/embed/LzEi3aJtde0" frameborder="0" allowfullscreen
 loading="lazy">&lt;/iframe>

&lt;p>So although Microsoft employs very good engineers, including very good
 security engineers, the end result is awful. What went wrong?&lt;/p>

&lt;p>Microsoft famously (historically, and apparently still) catered first to
 application developers (independent software vendors, or ISVs) and to OEMs.
 Microsoft saw, or sees, OEMs and large enterprises as their true customers;
 Apple sees individuals as their true customers. Apple wants to make money by
 making you love their machines, while Microsoft wants to make money by helping
 OEMs make money.&lt;/p>

&lt;p>Obviously, both approaches work great, even though the results are wildly
 different and have huge implications for software security internet-wide.
 Interesting to note is that when you can be Microsoft’s direct customer, such as
 when you are buying thousands of MSDN seats or large IIS and SQL Server
 deployments, you do in fact get Apple-level care and quality.&lt;/p>

&lt;p>One way of understanding that is to observe that, of course, paying customers
 get the quality they want. But I don’t think that fully explains what’s going
 on; after all, Dell’s and Acer’s customers paid money. Is it simply a matter of
 margins?&lt;/p>

&lt;p>I’m not sure it is, because Duo Labs found the same problems even with the
 premium Microsoft Signature Edition machines, even the premium-/business-grade
 Lenovos. I think Microsoft baked the security and user-experience quality
 problems into the platform when they decided to prioritize the needs and
 preferences of OEMs and large enterprises over those of individual people using
 the systems.&lt;/p>

&lt;p>Especially now that we increasingly live in a &lt;a href="https://en.wikipedia.org/wiki/Bring_your_own_device">mixed
 enterprise/personal computing environment&lt;/a> — BYOD started because executives
 wanted to use their fancy iDevices at work, because the devices were so good! —
 &lt;a href="https://www.w3.org/TR/html-design-principles/#priority-of-constituencies">prioritizing
 the needs and preferences of the people actually using the systems&lt;/a> to actually
 do work seems increasingly like a fundamentally good decision for security, user
 experience, and quality generally.
&lt;/p></description><author>Chris Palmer</author><guid>2016/06/01/constituencies-and-quality/index.html</guid><pubDate>Wed, 01 Jun 2016 00:00:00 +0000</pubDate></item><item><title>More New Electronic Music: Time 1</title><link>https://noncombatant.org/2016/05/31/time-1/index.content</link><description>&lt;h1>More New Electronic Music: Time 1&lt;/h1>

&lt;p>&lt;time>31 May 2016&lt;/time>&lt;/p>

&lt;p>Hot off the cyberpresses, I wrote/improvised and recorded 3 new songs this
afternoon: &lt;a href="https://noncombatant.bandcamp.com/album/time-1">&lt;em>Time
1&lt;/em>&lt;/a>. I really like just jamming with the Fingerlab DM1 drum machine app
for the iPad. They keep updating the app with new features and drum kits/sample
sets. A super cool thing now is the ability to apply effects to particular
instruments, rather than to the mix as a whole. These tracks are entirely
off-the-cuff, unlike &lt;a
href="/2016/03/29/object-lifetime/">&lt;em>Object.lifetime&lt;/em>&lt;/a>, which was
somewhat more premeditated and rehearsed. I hope you enjoy!&lt;/p></description><author>Chris Palmer</author><guid>2016/05/31/time-1/index.html</guid><pubDate>Tue, 31 May 2016 00:00:00 +0000</pubDate></item><item><title>New Electronic Music EP: Object.lifetime</title><link>https://noncombatant.org/2016/03/29/object-lifetime/index.content</link><description>&lt;h1>New Electronic Music EP: Object.lifetime&lt;/h1>

&lt;p>&lt;time>29 March 2016&lt;/time>&lt;/p>

&lt;p>After letting it sit for 4 years (?!), I have finally released this EP of
electronic music I wrote shortly after recording &lt;a
href="https://dotpunto.bandcamp.com/album/agua-viva">the 2nd Dot Punto. EP I
worked on, &lt;em>Agua Viva&lt;/em>&lt;/a>. It’s called &lt;a
href="https://noncombatant.bandcamp.com/album/object-lifetime">&lt;em>Object.lifetime&lt;/em>&lt;/a>,
and after thinking about it for all these years I don’t hate it, so maybe it
isn’t too bad. :) You can listen to it on Bandcamp, or you could even pay money
for it, if you were so inclined.&lt;/p></description><author>Chris Palmer</author><guid>2016/03/29/object-lifetime/index.html</guid><pubDate>Tue, 29 Mar 2016 00:00:00 +0000</pubDate></item><item><title>Advice For Myself</title><link>https://noncombatant.org/2016/03/27/advice-for-myself/index.content</link><description>&lt;h1>Advice For Myself&lt;/h1>

&lt;p>&lt;time>27 March 2016&lt;/time>&lt;/p>

&lt;p>Maybe other people might find this useful, too.&lt;/p>

&lt;ul>

&lt;li>&lt;a href="https://en.wikipedia.org/wiki/Mudita">Contribute to someone
else&lt;/a>’s safety, health, or pleasure. Secure your own oxygen mask before
helping others — so that you can help others.&lt;/li>

&lt;li>Do 1 thing at a time. Multitasking is counter-productive.&lt;/li>

&lt;li>Eat a moderate amount of a wide variety of foods. Eat breakfast. Reduce (but
don’t completely eliminate) sugar and alcohol.&lt;/li>

&lt;li>Listen to even more kinds of music, even more often.&lt;/li>

&lt;li>Read even more kinds of text, even more often. Read more long-form than
short-form.&lt;/li>

&lt;li>The mind is the body. Meditate, in some form, for at least 30 minutes each
day. Walk at least 10,000 steps each day.&lt;/li>

&lt;li>Clean your body, clean your clothes, clean your home.&lt;/li>

&lt;li>Prefer craft and technique to tools. But do use the best tools, and take
care of them.&lt;/li>

&lt;li>Doubt yourself — but not too much. Doubt yourself before doubting others,
but do avoid confirmed fools.&lt;/li>

&lt;li>Nail the fundamentals. Be open to improvising around the fundamentals.&lt;/li>

&lt;li>“The shortest answer is doing the thing.” — Ernest Hemingway&lt;/li>

&lt;li>Habits are free. (That can be bad.) Be aware of your habits and break them
if necessary, or even just to change perspective.&lt;/li>

&lt;/ul></description><author>Chris Palmer</author><guid>2016/03/27/advice-for-myself/index.html</guid><pubDate>Sun, 27 Mar 2016 00:00:00 +0000</pubDate></item><item><title>Security Engineering As Caring-For</title><link>https://noncombatant.org/2016/03/27/security-as-caring-for/index.content</link><description>&lt;h1>Security Engineering As Caring-For&lt;/h1>

&lt;p>&lt;time>27 March 2016&lt;/time>&lt;/p>

&lt;blockquote>On security nihilism — I recently read &lt;a
href="https://www.dukeupress.edu/the-theater-of-operations">Joe Masco’s
&lt;em>Theater of Operations: National Security Affect from the Cold War to the War
on Terror&lt;/em>&lt;/a> (VERY GOOD). I was struck by the massive extent to which the
discourse around [computer] security borrows from and follows military discourse
and metaphor. We see this in the increasing departure from probabilistically
provable models to black swan paranoia — the terrorist with the WMD, the hacker
and the power grid. We accept that we must defend against catastrophe without a
good way to estimate its likelihood, and so our defenses and imaginations have
no limits. The hunched paranoid position forever. Any fallibility is a loss, any
weakness a crisis. We are aligned forever against a bad “other.” Who wouldn’t be
exhausted, say fuckit it’s impossible? But...what if we reimagined computer
security as an act of caring-for, as a practice of maintenance and nurturing, as
a vigilant attention to whether the machines and systems we instruct are
respecting the right boundaries, and ensuring others respect them, and working
for those they are meant to serve respectfully? This stance seems much easier to
sustain indefinitely, and IMO much more closely captures the daily nuts and
bolts of security engineering anyway. (I’m sure it makes crappier movie plots,
but...) — &lt;a
href="https://www.facebook.com/permalink.php?story_fbid=231689823833308&amp;id=100009768763867&amp;comment_id=232319317103692&amp;comment_tracking=%7B%22tn%22%3A%22R%22%7D">Meredith
Whittaker&lt;/a>&lt;/blockquote>

&lt;p>Meredith makes an important point well (something she often does). I have
seen so many of my past and present colleagues struggle to find ways to cope
with the pain of dealing with what seems like a Sisyphean task. I developed a
pretty severe eye twitch and an ambient low-grade panic when I was doing the
security consulting gig, for example.&lt;/p>

&lt;p>If the problem of security engineering were merely &lt;em>difficult&lt;/em>, that
would be one thing. (Indeed, that’s the part of this job I most love!) But then
there’s the negligence, efforts to externalize costs and avoid accountability,
the sexism and racism, the juvinility, the &lt;a
href="http://www.theatlantic.com/technology/archive/2015/11/programmers-should-not-call-themselves-engineers/414271/">ignorant
hootings of nay-sayers&lt;/a>... well, it wears a person down pretty quick.&lt;/p>

&lt;p>Part of the low-grade panic comes from the moral and ethical dilemmas we
sometimes face. I’m sure we could all tell hair-raising stories. (And I think we
should. Perhaps in a future post...)&lt;/p>

&lt;p>Even when there’s nothing shady going on, the ability of programmers to avoid
learning anything is as confounding as it is depressing. Many engineers know
what they know from early in their careers, and have never felt the need to
learn much new — even as the junior engineers rely on them for mentorship.&lt;/p>

&lt;p>One winter, after doing a series of unnecessarily frightening security
reviews at healthcare and financial institutions, I did a very short (1 person,
2 weeks) engagement at a small startup. They didn’t have much money, but their
thing was important enough that they decided they needed some security review,
so they paid for as much as they could afford. This company was small but
staffed by experienced engineers from [redacted], and they had done a very good
job at minimizing their attack surface, sticking to secure network protocols,
using a memory-safe language well, and so on.&lt;/p>

&lt;p>If this company had their service compromised, it definitely would matter.
The people who use the company’s service (probably numbering now in the 10s of
millions?) would have some of their definitely-somewhat-interesting information
leaked, and it could spell the end of the company. It probably would hurt the
entire (emerging) market. But, they had their security situation as well in-hand
as I had yet seen. By contrast, I know first-hand that many of the systems that
affect people’s lives are compromised. I have seen the security engineers (when
there are any) at the organizations that run those systems despair, and I have
seen the executives egregiously deprioritize utter pwnage that wouldn’t even be
too expensive to fix.&lt;/p>

&lt;p>In my experience, the more important a system is, the worse its security is.
(You might think the problem is particular to large, old enterprises, and that
new business segments and small startups in old segments are doing well because
they are new or small. Well, &lt;a href="https://twitter.com/internetofshit">about
that&lt;/a>.)&lt;/p>

&lt;p>Many security engineers feel like, or fear feeling like, &lt;a
href="http://www.npr.org/sections/thetwo-way/2016/02/25/466555217/your-letters-helped-challenger-shuttle-engineer-shed-30-years-of-guilt">Bob
Ebeling, who warned about the dangers of launching the Space Shuttle
Challenger&lt;/a> but was overruled. As Meredith characterizes it, we feel we must
“defend against catastrophe without a good way to estimate its likelihood”.
Sometimes, we even do know the likelihood, but find that we can’t get the
resources we need to protect people.&lt;/p>

&lt;p>So, sometimes we cope by getting angry, or mean, or indulging in gallows
humor, or pretending like we don’t really care (“I’m just in this for the &lt;a
href="http://web.cs.ucdavis.edu/~rogaway/papers/moral-fn.pdf">interesting
puzzles&lt;/a>”), or whatever. It’s not good, and I don’t think any of us enjoys
resorting to those coping mechanisms. I certainly engage in all of them myself,
and I hate doing it, and I hate myself for it. Which, of course, only
exacerbates the feelings of burn-out and despair, which leads to more coping,
which...&lt;/p>

&lt;p>It’s certainly not good engineering practice. Good engineering requires
actually believing in the possibility of a real solution, being pro-social,
communicating well, and engaging with the full difficulty of the problems.
Security problems are, after all, most often social problems and communication
problems. (Does your root cause analysis really go all the way to the
&lt;em>real&lt;/em> root?)&lt;/p>

&lt;p>So how can we do our jobs — making driverless cars safe, keeping health
records accurate and private, keeping voting accurate and not coerced,
maintaining people’s rights to read and speak, keeping fraud and theft down to a
dull roar — without falling into despair? Can we even dream of... &lt;em>being
happy?&lt;/em> Can we not fall into a siege mentality? Can we not blame
technology’s victims for its failures?&lt;/p>

&lt;p>Following Meredith’s advice, I believe that we can. When we re-frame security
engineering as caring-for, progress starts seeming possible. Each small victory
starts looking like a tile in a mosaic, rather than as a futile gesture. We can
see the faces of people we’ve helped in the mosaic. We can expand the scope of
our work — yes, security engineering includes securing the right to read! — not
with fatigue or dread, but with purpose and meaning. And we must argue for &lt;a
href="/2016/01/28/against-security-nihilism/">what we know works, and against
what we know does not work&lt;/a> with confidence.&lt;/p>

&lt;p>As we do this, our skills and usefulness will increase. Our ability to
negotiate and plan, rather than make demands as we frantically react, will
improve. We can leave unethical and dysfunctional organizations and communities,
and move to ethical and functional ones. We must, &lt;a
href="http://www.sheepdressedlikewolves.com/self-care/">because we cannot care
for others until we have begun to care for ourselves&lt;/a>.&lt;/p>

&lt;blockquote>The viability of technology, like democracy, depends in the end on
the practice of justice and on the enforcement of limits to power. — Ursula M.
Franklin, &lt;em>The Real World Of Technology&lt;/em>, p. 5&lt;/blockquote>

&lt;!--
&lt;blockquote>At this momentous event in my life — the acceptance of the Nobel
Peace Prize — I want to speak as a scientist, but also as a human being. From my
earliest days I had a passion for science. But science, the exercise of the
supreme power of the human intellect, was always linked in my mind with benefit
to people. I saw science as being in harmony with humanity. I did not imagine
that the second half of my life would be spent on efforts to avert a mortal
danger to humanity created by science. — Joseph Rotblat, &lt;a
href="http://www.nobelprize.org/nobel_prizes/peace/laureates/1995/rotblat-lecture.html">“Remember
Your Humanity”&lt;/a>&lt;/blockquote>
--></description><author>Chris Palmer</author><guid>2016/03/27/security-as-caring-for/index.html</guid><pubDate>Sun, 27 Mar 2016 00:00:00 +0000</pubDate></item><item><title>Everyone Needs Secure Usability</title><link>https://noncombatant.org/2016/01/30/everyone-needs-secure-usability/index.content</link><description>&lt;h1>Everyone Needs Secure Usability&lt;/h1>

&lt;p>&lt;time>30 January 2016&lt;/time>&lt;/p>

&lt;p>There’s an interesting &lt;a href="https://lwn.net/Articles/586838/">article in
LWN about C11 atomic variables and the kernel&lt;/a> that struck me for a few
reasons:&lt;/p>

&lt;ul>

&lt;li>Atomics and concurrency are always weird and fun and surprising&lt;/li>

&lt;li>I keep hoping for C11 to be kind of awesome, or at least interesting, and it
is!&lt;/li>

&lt;li>Although they might not frame it this way, secure usability — &lt;a
href="https://docs.google.com/presentation/d/1Qmpl-5epx0B5C2t4XsUTyjgbwab_rXfK_4iHqX3IC30/pub?start=false&amp;loop=false&amp;delayms=3000&amp;slide=id.gf44795496_0_1">in
the same sense that we worry about it in Chrome&lt;/a> (&lt;a
href="https://www.youtube.com/watch?v=XfFjde0UPbY">see also&lt;/a>) — is a
make-or-break concern for these Linux kernel developers and C standardizers&lt;/li>

&lt;/ul>

&lt;p>In Chrome Land, we’re always trying to improve people’s ability to understand
and effectively use Chrome’s security indicators and controls, such as the
Location Icon (the green padlock, the red padlock, et c.), the Origin Info
Bubble (the bubble you get when you click on the Location Icon), the &lt;a
href="https://developers.google.com/web/updates/2015/12/security-panel?hl=en">Security
Panel in the Dev Tools&lt;/a>, the permissions and Content Settings, the security
exceptions in the JavaScript Console, and so on. (By “people”, you can see that
I mean everyone: ‘end-users’, web developers, system and network administrators,
et al. Those categories are fluid.)&lt;/p>

&lt;p>Similarly, the LWN article describes how the Linux kernel developers and C11
standardizers are trying to improve C developers’ ability to understand and
effectively use atomic variables so that we can all enjoy efficient yet safe
concurrent programs. If the mechanisms that enable concurrency (like locks and
atomics) are confusing, we’re going to get buggy (and vulnerable) programs. But
if they’re too slow or heavyweight, people won’t use them — and we’ll get buggy
(and vulnerable) programs.&lt;/p>

&lt;p>So the first thing to do is to find out what it is that the community using
the product needs and can effectively use. So the C11 standards people, academic
programming language researchers, and kernel developers are all working together
to figure out the shape of the thing.&lt;/p>

&lt;p>Here is a representative example of the kinds of problems that crop up:&lt;/p>

&lt;blockquote>

&lt;p>Another area of concern is control dependencies: situations where atomic
variables and control flow interact. Consider a simple bit of code:&lt;/p>

&lt;pre>
x = atomic_load(&amp;a, memory_order_relaxed);
if (x)
 atomic_store(&amp;y, 42, memory_order_relaxed);
&lt;/pre>

&lt;p>The setting of &lt;code>y&lt;/code> has a control dependency on the value of
&lt;code>x&lt;/code>. But the C11 standard does not currently address control
dependencies at all, meaning that the compiler or processor could play with the
order of the two atomic operations, or even try to optimize the branch out
altogether; see &lt;a href="https://lwn.net/Articles/586854/">this explanation from
GCC developer Torvald Riegel&lt;/a> for details. Again, the results of this kind of
optimization in the kernel context could be disastrous.&lt;/p>

&lt;p>For cases like this, Paul suggested that some additional source-code markup
and a new &lt;code>memory_order_control&lt;/code> memory model could be used in the
kernel to make the control dependency explicit:&lt;/p>

&lt;pre>
x = atomic_load(&amp;a, memory_order_control);
if (control_dependency(x))
 atomic_store(&amp;b, 42, memory_order_relaxed);
&lt;/pre>

&lt;p>But this approach is unlikely to be taken, given just how unhappy Linus was
with the idea. From his point of view, the control dependency should be obvious
— the code is testing the value of &lt;code>x&lt;/code>, after all. Any compiler that
would move the &lt;code>atomic_store()&lt;/code> operation in an externally visible
way, he said, is simply broken.&lt;/p>

&lt;/blockquote>

&lt;p>Just as with ‘end-user’ interfaces, these low-level APIs must adapt to the
needs and expectations of the people who use them. Despite the tendency to
consider ‘end-users’ as ‘ignorant’ or ‘not computer-literate’, and the tendency
to consider kernel hackers as ‘elite’, these different groups have concerns
about and problems with the usability of their every-day tools that are more
similar than people sometimes imagine.&lt;/p>

&lt;p>Another thing that struck me is that magic simply may not be possible, and
our best recourse might just be to live with the limitations of simplicity.
Linus’ way of saying this is arresting:&lt;/p>

&lt;blockquote>

&lt;p>Yet another concern is global optimization. Compiler developers are
increasingly trying to optimize programs at the level of entire source files, or
even larger groups of files. This kind of optimization can work well as long as
the compiler truly understands how variables are used. But the compiler is not
required to understand the real hardware that the program is running on; it is,
instead, required to prove its decisions against a virtual machine defined by
the standard. If the real computer behaves in ways that differ from the virtual
machine, things can go wrong.&lt;/p>

&lt;p>Consider this example raised by Linus: the compiler might look at how the
kernel accesses page table entries and notice that no code ever sets the “page
dirty” bit. It might then conclude that any tests against that bit could simply
be optimized out. But that bit can change; it’s just that the hardware makes the
change, not the kernel code. So any optimizations made based on the notion that
the compiler can “prove” that bit will never be set will lead to bad things.
Linus concluded: “Any optimization that tries to prove anything from more than
local state is by definition broken, because it assumes that everything is
described by the program.”&lt;/p>

&lt;/blockquote>

&lt;p>The article describes the existing concurrency tools that the Linux kernel
developers built for themselves, that the C11 mechanisms would attempt to
replace. The kernel developers understand the tools they made, and they seem to
work, and maybe that’s sufficient.&lt;/p>

&lt;p>I can’t help but be reminded of how a web browser cannot always ‘decide’ for
the person that a certificate validation error is or is not important: it
depends on context that is simply not available to the program interpreting its
impoverished input. Whether it’s the compiler trying to interpret kernel source
code or the browser trying to interpret an X.509 certificate chain, there’s
often simply not enough information to produce an output that is both correct
and optimal.&lt;/p>

&lt;p>There is also a problem of unaligned incentives that contribute to the secure
usability problem, just as we often see happen in the Web PKI and in the design,
implementation, and use of the Open Web Platform: different groups of people
have different interests and are under different pressures, and sometimes their
goals come into conflict.&lt;/p>

&lt;blockquote>The problem is that compilers tend to be judged on the speed of the
code they generate, so compiler developers have a strong incentive to optimize
code to the greatest extent possible. Sometimes those optimizations can break
code that is not written with an attentive eye toward the standard; the kernel
developers’ perspective is that compiler developers will often rely on a
legalistic reading of standards to justify “optimizations” that (from the kernel
developer’s viewpoint) make no sense and break code needlessly. Highly
concurrent code, as is found in the kernel, tends to be more susceptible to
optimization-caused problems than just about anything else. So kernel developers
have learned to be careful.&lt;/blockquote>

&lt;p>This pressure — speed, speed, speed! — leads compiler developers to make the
language opaque, and to break the conceptual integrity of the language in a way
that can actually make it unsafe and unusable:&lt;/p>

&lt;blockquote>

&lt;blockquote>There are too many compiler optimisations for people to reason
directly in terms of the set of all transformations that they do, so we need
some more concise and comprehensible envelope identifying what is allowed, as an
interface between compiler writers and users.&lt;/blockquote>

&lt;p>The C11 standard is meant to be that “envelope,” though, as Peter admitted,
it is “not yet fully up to that task.” But if the remaining uncertainties and
problems can be addressed, C11 atomics could become a common language with which
developers can reason about concurrency and allowable optimizations. Developers
might come to understand the issues better, and kernel code might become a bit
more widely accessible to developers who understand the standard.&lt;/p>

&lt;/blockquote>

&lt;p>Cryptographer Dan Bernstein &lt;a
href="https://cr.yp.to/talks/2015.04.16/slides-djb-20150416-a4.pdf">has been
saying a similar thing&lt;/a>: Do compilers actually &lt;em>need&lt;/em> to produce
high-performance code, in the general case? Where needed, &lt;em>can&lt;/em> they? And
if not, is the damage to the language’s conceptual integrity worth it? He
contends (as I read him, at least) that the answer to these questions is No:
Most code is not hot (run often and hence in need of optimization); and, true
hot spots require optimizations that compilers cannot yet perform — only humans,
locally optimizing, understand their application domain and their machine well
enough to get a good result. (Bernstein is generally working on cryptographic
algorithms that he optimizes to work absolutely as well as possible on each
distinct chip — local optimizables that the general-purpose (‘global’, if you
will) compiler optimizations don’t really help with.) From Bernstein’s
presentation:&lt;/p>

&lt;blockquote>Mike Pall, LuaJIT author, 2011: “If you write an interpreter loop in
assembler, you can do much better... There’s just no way you can reasonably
expect even the most advanced C compilers to do this on your
behalf.”&lt;/blockquote>

&lt;p>Thus it might not be that people need optimizing compilers; instead, they may
benefit more from dumb-but-conceptually-integral compilers, and more usable
tools for writing, profiling, and testing hand-written assembly code.&lt;/p>

&lt;p>I think we can learn a few widely-applicable UX design lessons from all this
compiler talk:&lt;/p>

&lt;ul>

&lt;li>Augment the human, rather than try (and fail) to replace them.&lt;/li>

&lt;li>Optimize locally only — we know that we don’t know everything we need to
know to best serve people.&lt;/li>

&lt;li>Check that the local optimizations are actually optimizations.&lt;/li>

&lt;li>Never violate the conceptual integrity of the system.&lt;/li>

&lt;li>Sometimes it’s better to give people tools to build their own tools, rather
than try to build The Ultimate Thing.&lt;/li>

&lt;/ul></description><author>Chris Palmer</author><guid>2016/01/30/everyone-needs-secure-usability/index.html</guid><pubDate>Sat, 30 Jan 2016 00:00:00 +0000</pubDate></item><item><title>Against Security Nihilism</title><link>https://noncombatant.org/2016/01/28/against-security-nihilism/index.content</link><description>&lt;h1>Against Security Nihilism&lt;/h1>

&lt;p>&lt;time>28 January 2016&lt;/time>&lt;/p>

&lt;p>There’s a lot of security nihilism in the technology community, and in the
culture generally. Many people believe that “defense is impossible”, that
“security is a losing battle”, that nothing can be done, that we should stop
trying and divert resources spent on security to other worthy things like
features and performance. There is even nihilism in the security community
itself — although, I suspect, moreso from the offensive side.&lt;/p>

&lt;p>I disagree that defensive security is impossible. Yes, the software
equivalent of this:&lt;/p>

&lt;iframe width="420" height="315" src="https://www.youtube.com/embed/j-zczJXSxnw"
frameborder="0" allowfullscreen loading="lazy">&lt;/iframe>

&lt;p>does happen often. However, software engineering, and software security
engineering in particular, are very young engineering disciplines. Imagine how
bad bridge building was in year 70; then imagine how bad it was given that
randos and governments kept trying to destroy them all the time.&lt;/p>

&lt;p>But in the short time we’ve had to learn how to engineer software, we have
learned techniques that definitely do work, and some that definitely don’t. I’d
say we’ve learned a lot, fast. And we know we have, all too often, ignored
things we already knew.&lt;/p>

&lt;p>For example, the early programming language designer C. A. R. Hoare
recognized that security is really just an ‘extreme’ form of correctness, and
that a language’s first duty is to enable programmers to write correct programs.
In &lt;a
href="http://zoo.cs.yale.edu/classes/cs422/2011/bib/hoare81emperor.pdf">“The
Emperor’s Old Clothes”&lt;/a> he says:&lt;/p>

&lt;blockquote>The first principle was &lt;em>security&lt;/em>: The principle that
every syntactically incorrect program should be rejected by the compiler and 
that every syntactically correct program should give a result or an error
message that was predictable and comprehensible in terms of the source
language program itself. Thus no core dumps should ever be necessary. It was 
logically impossible for any source language program to cause the computer
to run wild, either at compile time or at run time. A consequence of this
principle is that every occurrence of every subscript of every subscripted
variable was on every occasion checked at run time against both the upper
and the lower declared bounds of the array. Many years later we asked our 
customers whether they wished us to provide an option to switch off these
checks in the interests of efficiency on production runs. Unanimously, they
urged us not to — they already knew how frequently subscript errors occur on
production runs where failure to detect them could be disastrous. I note
with fear and horror that even in 1980, language designers and users have
not learned this lesson. In any respectable branch of engineering, failure
to observe such elementary precautions would have long been against the 
law.&lt;/blockquote>

&lt;p>...and yet here we are, in 2016, shipping new software in languages we know
are unsafe.&lt;/p>

&lt;p>The Big Problem in security engineering is not that it’s impossible. I’d even
argue that some sound techniques are not even (technically) difficult. Often,
the problems are economic, political, and even inter-personal.&lt;/p>

&lt;p>I also often find that software engineers are simply unaware of sound
security techniques. Even simple things like &lt;a
href="https://golang.org/pkg/html/template/">HTML templating libraries that
automatically defang HTML metacharacters&lt;/a> — which are now common and
widely-available, and which enable developers to get a solid handle on the XSS
problem — are unknown to many working programmers (!).&lt;/p>

&lt;h2>Things We Know Work&lt;/h2>

&lt;ul>

&lt;li>&lt;a href="http://www.lucacardelli.name/Papers/TypefulProg.pdf">Typeful
programming&lt;/a>, and &lt;a
href="http://homepages.inf.ed.ac.uk/wadler/papers/propositions-as-types/propositions-as-types.pdf">propositions
as types&lt;/a>&lt;/li>

&lt;li>&lt;a href="https://en.wikipedia.org/wiki/Unit_testing">Unit testing&lt;/a> for
propositions we can’t easily represent as types&lt;/li>

&lt;li>&lt;a href="https://en.wikipedia.org/wiki/Privilege_separation">Privilege
separation&lt;/a>&lt;/li>

&lt;li>&lt;a
href="https://en.wikipedia.org/wiki/Principle_of_least_privilege">Privilege
reduction&lt;/a>&lt;/li>

&lt;li>&lt;a href="https://en.wikipedia.org/wiki/Memory_safety">Memory-safe
languages&lt;/a>&lt;/li>

&lt;li>&lt;a href="https://en.wikipedia.org/wiki/Type_safety">Type-safe
languages&lt;/a>&lt;/li>

&lt;li>&lt;a href="http://langsec.org/">Language-theoretic security&lt;/a>&lt;/li>

&lt;li>Choosers to grant resources, rather than broad ambient authority to access
resources&lt;/li>

&lt;li>APIs resilient against misuse and developer confusion (for example, &lt;a
href="https://en.wikipedia.org/wiki/Authenticated_encryption">AEAD ciphers&lt;/a>;
consider also high-level languages with real string types instead of the
standard C library’s impoverished string handling)&lt;/li>

&lt;li>Frequent, &lt;a
href="https://www.chromium.org/chromium-os/chromiumos-design-docs/filesystem-autoupdate">safe
(A/B)&lt;/a>, signed, and automatic updates&lt;/li>

&lt;li>&lt;a
href="https://www.chromium.org/chromium-os/chromiumos-design-docs/firmware-boot-and-recovery">Authenticating
the bootstrapping process&lt;/a>&lt;/li>

&lt;li>Not overpromising in the UX&lt;/li>

&lt;li>&lt;a href="http://lcamtuf.coredump.cx/afl/">Fuzzing&lt;/a> and &lt;a
href="http://clang.llvm.org/docs/AddressSanitizer.html">dynamic
analysis&lt;/a>&lt;/li>

&lt;li>Minimizing dependencies&lt;/li>

&lt;li>Defense in depth: 2 mechanisms, each of which could work in principle;
well-defined and -defended fallback guarantees in case the primary guarantee is
broken&lt;/li>

&lt;li>Integrating development, operations/deployment, business requirements, and
QA (see for example &lt;a
href="https://en.wikipedia.org/wiki/DevOps">DevOps&lt;/a>)&lt;/li>

&lt;/ul>

&lt;h2>Things We Know Don’t Work&lt;/h2>

&lt;ul>

&lt;li>&lt;a
href="http://www.ranum.com/security/computer_security/editorials/dumb/">Enumerating
badness&lt;/a>&lt;/li>

&lt;li>&lt;a href="https://en.wikipedia.org/wiki/Antivirus_software">Evaluating
Turing-complete languages to infer&lt;/a> an &lt;a
href="https://www.ietf.org/rfc/rfc3514.txt">evil bit&lt;/a>&lt;/li>

&lt;li>Layers of cruft, or what I call “false defense in depth” (many speedbumps
don’t make a wall)&lt;/li>

&lt;li>Dis-integrating development, operations/deployment, business requirements,
and QA&lt;/li>

&lt;/ul></description><author>Chris Palmer</author><guid>2016/01/28/against-security-nihilism/index.html</guid><pubDate>Thu, 28 Jan 2016 00:00:00 +0000</pubDate></item><item><title>Episode 72 Of The Code Newbie Podcast</title><link>https://noncombatant.org/2016/01/27/code-newbie-podcast/index.content</link><description>&lt;h1>Episode 72 Of The Code Newbie Podcast&lt;/h1>

&lt;p>&lt;time>27 January 2016&lt;/time>&lt;/p>

&lt;p>&lt;a href="http://bloggytoons.com/">Saron Yitbarek&lt;/a> interviewed me for the
&lt;a href="http://www.codenewbie.org/podcast/security-newbie">Code Newbie&lt;/a>
podcast (&lt;a href="code-newbie-72.mp3">local copy&lt;/a>) 2 weekends ago, and she
published it this past Monday. &lt;a href="http://www.codenewbie.org/">The Code
Newbie community&lt;/a> is “the most supportive community of programmers and people
learning to code”. &lt;a href="/2014/07/31/my-curvy-career-trajectory/">I was
fortunate&lt;/a> to have a group of friends to learn from and with when I was a
newbie, and I’ve found that when I lacked such a community, my progress
faltered.&lt;/p>

&lt;p>While you’re there, do check out some of the previous episodes. By listening,
we in the technology community — which you may have noticed is skewed white and
male — can learn a lot about what we’re building, and for whom, and why. We
won’t really be living in the future until &lt;em>everyone&lt;/em> is.&lt;/p>

&lt;p>Saron has done a great job curating and documenting these stories. I have not
yet listened to all the episodes, but I do plan to. (I can listen to at least
1.5 per day, on my commute!)&lt;/p>

&lt;p>In this episode I talk about how I got into software, and security
specifically, and about how I think the fields are still so new that none of us
entirely know what we’re doing. That’s especially true for security and privacy,
goals that are not always even clearly defined — let alone achieved. I think
there is still an openness in the field; it’s very much the the case that a code
newbie can arrive and make a significant contribution.&lt;/p></description><author>Chris Palmer</author><guid>2016/01/27/code-newbie-podcast/index.html</guid><pubDate>Wed, 27 Jan 2016 00:00:00 +0000</pubDate></item><item><title>“Airbag”</title><link>https://noncombatant.org/2015/12/21/airbag/index.content</link><description>&lt;h1>“Airbag”&lt;/h1>

&lt;p>&lt;time>21 December 2015&lt;/time>&lt;/p>

&lt;audio controls>
 &lt;source src="airbag.mp3" />
 &lt;a href="airbag.mp3">Download&lt;/a>
&lt;/audio>

&lt;p>This weekend I went down to South Pasadena to hang with my friends &lt;a href="http://shannoncurtis.net/">Shannon
 Curtis&lt;/a> and &lt;a href="http://secretagentaudio.com/">Jamie Hill&lt;/a>, to record a cover of one of
 my favorite tunes: “Airbag” by &lt;a href="http://www.radiohead.com/">Radiohead&lt;/a>.&lt;/p>

&lt;p>Like the narrator of the song, I feel very grateful for having survived many
 deadly mishaps through incredible luck and incredible technology.&lt;/p>

&lt;p>I had a ton of fun working with my talented friends, who have worked hard to
 create an autonomous zone for music. Dissecting Radiohead’s complex arrangement
 was a great learning experience. We stuck pretty close to ‘canon’, but I think
 the things we changed are pretty cool. I’m very happy with all the performances.
 The original has lots of Easter eggs for the attentive listener, and we put in
 some of our own. Listen with headphones!&lt;/p>

&lt;p>
 &lt;strong>Shannon Curtis:&lt;/strong> voice&lt;br />
 &lt;strong>Jamie Hill:&lt;/strong> production, engineering, drum programming,
 synthesizers&lt;br />
 &lt;strong>Chris Palmer:&lt;/strong> guitar, bass, synthesizers, voice
&lt;/p></description><author>Chris Palmer</author><guid>2015/12/21/airbag/index.html</guid><pubDate>Mon, 21 Dec 2015 00:00:00 +0000</pubDate></item><item><title>Some Interface Examples</title><link>https://noncombatant.org/2015/12/13/some-interface-examples/index.content</link><description>&lt;h1>Some Interface Examples&lt;/h1>

&lt;p>&lt;time>13 December 2015&lt;/time>&lt;/p>

&lt;p>In &lt;a href="/2015/12/12/interface-design-principles/">my previous post on
 interface design principles&lt;/a>, I sort of assumed that people would know what I
 meant by “primary interface definition”. In &lt;a href="/2014/08/10/security-as-a-class-of-interface-guarantee/">Security
 As A
 Class Of Interface Guarantee&lt;/a> I defined it it as follows:&lt;/p>

&lt;blockquote>The &lt;strong>primary interface definition&lt;/strong> is the immediately
 accessible surface of the interface itself, e.g. a function or method
 declaration, an IDL specification or other code generation/specification system
 for network protocols, the grammar of a programming language, or a user-facing
 GUI or CLI. A &lt;strong>secondary interface definition&lt;/strong> is supplementary
 material; usually documentation, annotation, post-facto errata, entries in issue
 trackers, commit log messages, et c.&lt;/blockquote>

&lt;p>Our ideal is, or should be, to make interfaces so simple to use that people
 can learn them immediately, and use them readily. Additionally, it should be
 impossible (or at least difficult) to use the interface unsafely. (“Unsafety”
 could mean whatever you like: deleting important information, not deleting
 information that the person needs deleted, sending information to the wrong
 person, not sending information to the right person, crashing the machine, and
 so on.)&lt;/p>

&lt;p>A learnable interface explains itself upon contact — the person using it has
 no need of secondary interface definitions such as documentation. Like a
 screwdriver, the shape of the head either fits or does not fit the screw. If the
 person somehow manages to crank the wrong screwdriver into a screw head, the
 damage will be immediate, obvious, and commensurate with how hard the person
 cranked it. (Unlike so much software that explodes silently, a week
 later...)&lt;/p>

&lt;figure>&lt;img src="screws.jpg" alt="Picture of screwdrivers and their matching
screw heads." width="456" height="232" loading="lazy" />
 &lt;figcaption>From &lt;a href="http://universalscrewdriver.com/">Universal Screwdriver&lt;/a>. Maybe we can
 make software interfaces more universal.&lt;/figcaption>
&lt;/figure>

&lt;p>I also assumed people would know what it means for an interface to be as
 simple as possible, but no simpler. For example, maybe the &lt;a href="http://universalscrewdriver.com/">Universal
 Screwdriver&lt;/a> really works —
 but maybe it doesn’t. It seems unlikely to perfectly fit the different types of
 screw heads. It’s worth a try, but we should fall back to regular screwdrivers
 if necessary.&lt;/p>

&lt;p>Here are 2 more examples. I am a fan of dialog boxes that really offer
 choice, rather than the often meaningless &lt;strong>OK&lt;/strong> and
 &lt;strong>Cancel&lt;/strong> ‘non-dialog’ boxes. Sometimes, those 2 choices are just
 not enough to give the person what they need.
&lt;/p>

&lt;figure>&lt;img src="3-choice-2.png" alt="Screenshot of 3 choices when deleting a
recurring calendar event: Only This Instance, All Following, and All Events In
The Series." width="755" height="253" loading="lazy" />
 &lt;figcaption>Screenshot of
 3 choices when deleting a recurring calendar event: &lt;strong>Only This
 Instance&lt;/strong>, &lt;strong>All Following&lt;/strong>, and &lt;strong>All Events In The
 Series&lt;/strong>.&lt;/figcaption>
&lt;/figure>

&lt;figure>&lt;img src="3-choice-1.png" alt="Screenshot of 3 choices when exiting a
text editor: Close Without Saving, Cancel, and Save As." width="714" height="559" loading="lazy" />
 &lt;figcaption>Screenshot of 3 choices when exiting a
 text editor: &lt;strong>Close Without Saving&lt;/strong>, &lt;strong>Cancel&lt;/strong>, and
 &lt;strong>Save As&lt;/strong>.
 &lt;/figcaption>
&lt;/figure>

&lt;p>The only way to simplify the calendar example would be to over-simplify it:
 to remove meaningful choices. The safest choice, &lt;strong>Only This
 Instance&lt;/strong>, is first, followed by the still-pretty-safe &lt;strong>All
 Following&lt;/strong>. But &lt;strong>All Events In The Series&lt;/strong> is sometimes
 necessary. And of course, Google Calendar does offer &lt;strong>Undo&lt;/strong>.&lt;/p>

&lt;p>The text editor example could be simplified; for example, Mac OS X
 TextEdit.app and Google Docs both constantly auto-save. They entirely get rid of
 the concept of saving, which is great because people throughout the Cyber Age
 have lost tons of work because they forgot to save. All that remains of the old
 &lt;strong>Save&lt;/strong>/&lt;strong>Save As...&lt;/strong> paradigm is the
 still-meaningful &lt;strong>Export...&lt;/strong>, &lt;strong>Rename...&lt;/strong>, and
 &lt;strong>Make A Copy...&lt;/strong>.
&lt;/p>

&lt;p>Note that auto-saving applications must either automatically name files (&lt;a
 href="https://developer.apple.com/library/mac/documentation/General/Conceptual/MOSXAppProgrammingGuide/CoreAppDesign/CoreAppDesign.html">Mac
 OS X&lt;/a>; see “The Document Architecture Provides Many Capabilities for Free”),
 or do away with the concept of the filesystem by replacing it with search
 (Google Drive).&lt;/p>

&lt;p>One could argue, as I probably would, that a programmer’s or engineer’s text
 editor still needs a concept of &lt;em>explicit commit&lt;/em>, and hence should not
 auto-save or at least not auto-name. Therefore, such editors do still need to
 raise a dialog if there are un-committed buffers on exit; given that, Gedit’s
 3-choice dialog seems to fit people’s needs well. On the other hand, one could
 argue that the revision control system (e.g. Git; ideally integrated into the
 editor as in most IDEs) exists to provide explicit commit, and that the editor
 could and hence should auto-save (possibly into a temporary, private branch in
 the RCS). But it probably still could not auto-name.&lt;/p>

&lt;p>Thus, even in the case of the engineer’s text editor, no further
 simplification is possible. You can move the complexity around, creating 1
 giant complex system (e.g. Eclipse) or integrating many small tools with
 glue code (e.g. bash + vim + git), but you can’t eliminate it without losing
 something crucial.&lt;/p>

&lt;p>Although the examples so far have been of UIs, we can apply the same
 interface design principles to APIs. APIs are, after all, UIs for engineers.
 (The same is true of a programming language’s syntax, and the principles apply
 there, too.) Consider the &lt;code>get&lt;/code> method of the Java
 &lt;code>HashMap&lt;/code> class. From &lt;a
 href="https://docs.oracle.com/javase/7/docs/api/java/util/HashMap.html#get(java.lang.Object)">the
 documentation&lt;/a>:
&lt;/p>

&lt;blockquote>
 &lt;code>public V get(Object key)&lt;/code>

 &lt;p>Returns the value to which the specified key is mapped, or null if this map
 contains no mapping for the key.&lt;/p>

 &lt;p>More formally, if this map contains a mapping from a key k to a value v such
 that (&lt;code>key==null ? k==null : key.equals(k)&lt;/code>), then this method
 returns v; otherwise it returns &lt;code>null&lt;/code>. (There can be at most one
 such mapping.)&lt;/p>

 &lt;p>A return value of &lt;code>null&lt;/code> does not &lt;em>necessarily&lt;/em> indicate
 that the map contains no mapping for the key; it’s also possible that the map
 explicitly maps the key to &lt;code>null&lt;/code>. The &lt;code>containsKey&lt;/code>
 operation may be used to distinguish these two cases.&lt;/p>

 &lt;p>&lt;strong>Specified by:&lt;/strong>&lt;/p>

 &lt;p>&lt;code>get&lt;/code> in interface &lt;code>Map&amp;lt;K,V&amp;gt;&lt;/code>&lt;/p>

 &lt;p>&lt;strong>Overrides:&lt;/strong>&lt;/p>

 &lt;p>&lt;code>get&lt;/code> in class &lt;code>AbstractMap&amp;lt;K,V&amp;gt;&lt;/code>&lt;/p>

 &lt;p>&lt;strong>Parameters:&lt;/strong>&lt;/p>

 &lt;p>key - the key whose associated value is to be returned&lt;/p>

 &lt;p>&lt;strong>Returns:&lt;/strong>&lt;/p>

 &lt;p>the value to which the specified key is mapped, or &lt;code>null&lt;/code> if this
 map contains no mapping for the key&lt;/p>

 &lt;p>&lt;strong>See Also:&lt;/strong>&lt;/p>

 &lt;p>&lt;code>put(Object, Object)&lt;/code>&lt;/p>
&lt;/blockquote>

&lt;p>Look how verbose the documentation is. Part of the verbosity is ‘necessary’
 to explain the interface’s unfortunate ambiguity (the meaning of a
 &lt;code>null&lt;/code> return value), and part of the verbosity is gratuitous (the
 meaning of the &lt;code>key&lt;/code> parameter, whose name and type make it obvious
 to a reader who has read and understood the &lt;code>Map&lt;/code> interface).
&lt;/p>

&lt;p>Note also that the documentation as verbose as it is, does not explain the
 exceptions that the implementation might throw. The reader has to follow the &lt;a
 href="http://docs.oracle.com/javase/7/docs/api/java/util/Map.html#get(java.lang.Object)">links
 up the inheritance chain to find the exceptions&lt;/a>.&lt;/p>

&lt;p>Still, this interface does have the virtue of explaining itself immediately
 upon contact, somewhat like the screwdriver. Compare it to Python’s online
 help:&lt;/p>

&lt;pre>
>>> &lt;strong>help({}.__getitem__)&lt;/strong>
Help on built-in function __getitem__:

__getitem__(...)
 x.__getitem__(y) &lt;==> x[y]
&lt;/pre>

&lt;p>And of course, Python exceptions are all run-time exceptions; there is no
 equivalent of Java’s checked exceptions (which make up part of the declared and
 statically-checked type of an interface).&lt;/p>

&lt;p>Between these extremes of annoying verbosity and useless terseness, there is
 the admirably concise but eye-rollingly gnomic &lt;a
 href="https://en.wikipedia.org/wiki/Hindley%E2%80%93Milner_type_system">Hindley-Milner
 type system&lt;/a> notation.&lt;/p>

&lt;p>It’s easy to imagine, and in C++ and Java easy to actually achieve, interface
 definitions that explain themselves concisely like Hindley-Milner, but without
 the gnomic Greek. For example, a better &lt;code>Map.get&lt;/code> in Java:&lt;/p>

&lt;pre>
public V get(K key) throws NoSuchKeyException
&lt;/pre>

&lt;p>Or, if you dislike exceptions and like Maybe types as I do,&lt;/p>

&lt;pre>
public MaybeV get(K key)
&lt;/pre>

&lt;p>Either way, the interface explains itself in 1 concise line, without the
 ambiguity of &lt;code>null&lt;/code>, with no need for verbosity, and with no need to
 crawl up the inheritance chain for more clues. Just as the labels in buttons
 like &lt;strong>All Events In The Series&lt;/strong> and &lt;strong>Close Without
 Saving&lt;/strong> explain themselves concisely, the names of types and identifiers
 explain themselves to readers who have understood the 1-paragraph definitions of
 &lt;code>Map&lt;/code> and &lt;code>Maybe&lt;/code>. Callers that violate the interface
 simply won’t compile, let alone run — no nasty run-time surprises like in
 Python.
&lt;/p>

&lt;p>(Note that in defining the key type &lt;code>K&lt;/code> as the argument type of
 &lt;code>get&lt;/code>, we avoid another ambiguity in the Java &lt;code>Map&lt;/code>
 interface: the possibility of &lt;code>ClassCastException&lt;/code> (&lt;a
 href="https://docs.oracle.com/javase/7/docs/api/java/util/Map.html#get(java.lang.Object)">documented
 as “optional”&lt;/a>). Recall from the documentation above that Java’s
 &lt;code>Map.get&lt;/code> takes &lt;code>Object&lt;/code> as the argument type — which may
 not correctly cast, at run-time (!), to &lt;code>K&lt;/code>.)
&lt;/p>

&lt;p>There is a whole rant to be written on another topic I touched on in the last
 post: Whether or not an interface’s guarantee is &lt;em>computable&lt;/em>. But, it
 will have to wait; for now, it is time to compose these 2 interfaces:&lt;/p>

&lt;pre>
class Person {
 // ...
 MaybeSatisfaction eat(Eatable* eatable) mutable;
 // ...
}

class ChocolateChipPancake : public Eatable {
 // ...
}
&lt;/pre></description><author>Chris Palmer</author><guid>2015/12/13/some-interface-examples/index.html</guid><pubDate>Sun, 13 Dec 2015 00:00:00 +0000</pubDate></item><item><title>Interface Design Principles</title><link>https://noncombatant.org/2015/12/12/interface-design-principles/index.content</link><description>&lt;h1>Interface Design Principles&lt;/h1>

&lt;p>&lt;time>12 December 2015&lt;/time>&lt;/p>

&lt;p>For any kind of interface. See also: &lt;a
href="/2014/08/10/security-as-a-class-of-interface-guarantee/">Security As A
Class Of Interface Guarantee&lt;/a>.&lt;/p>

&lt;ul>

&lt;li>Provide choices — not warnings or notifications.&lt;/li>

&lt;li>Provide contextually-relevant choices —

 &lt;ul>
 &lt;li>but not relying on context that only a strong AI could perceive;&lt;/li>
 &lt;li>don’t confuse mere statistics for strong AI;&lt;/li>
 &lt;li>don’t use implicit context to take away relevant choices.&lt;/li>
 &lt;/ul>&lt;/li>

&lt;li>Make the interface as simple as possible — but no simpler.&lt;/li>

&lt;li>Assume that the people using the interface are intelligent and motivated —
but busy and focused on their ultimate goal.&lt;/li>

&lt;li>Promise only computable guarantees.&lt;/li>

&lt;li>Prefer to surface all guarantees in the primary interface definition —
callers are unlikely to consult secondary definitions.&lt;/li>

&lt;/ul></description><author>Chris Palmer</author><guid>2015/12/12/interface-design-principles/index.html</guid><pubDate>Sat, 12 Dec 2015 00:00:00 +0000</pubDate></item><item><title>What Is HPKP For?</title><link>https://noncombatant.org/2015/11/24/what-is-hpkp-for/index.content</link><description>&lt;h1>What Is HPKP For?&lt;/h1>

&lt;p>&lt;time>24 November 2015&lt;/time>&lt;/p>

&lt;aside>
 &lt;p>Note: Slightly edited for clarity 25 Nov 2015 03:40 UTC.&lt;/p>
&lt;/aside>

&lt;p>Every time &lt;a href="https://www.duosecurity.com/blog/dude-you-got-dell-d-publishing-your-privates">something
 like this happens&lt;/a> (&lt;a href="/2015/02/21/superfish-round-up/">...again&lt;/a>),
 people start clamoring for public key pinning to ‘solve’ the problem.&lt;/p>

&lt;p>The core problem here is that, although the people who bought the computers
 did not want a certificate installed that makes MITM attacks easy, the computer
 vendors sold them that way anyway. The people who bought the computers did not,
 in effect, really have full ownership of what they bought. Additionally, people
 did not come to realize this until many months after the computers were sold!
 (See also &lt;a
 href="http://arstechnica.com/security/2015/11/dell-does-superfish-ships-pcs-with-self-signed-root-certificates/">Ars
 Technica’s coverage&lt;/a>.)&lt;/p>

&lt;p>People who want HPKP to solve the problem wish that, when setting public key
 pins, servers should be able to expect clients to perform Pin Validation
 unconditionally — to &lt;em>always&lt;/em> obey the server’s requirements, regardless
 of the client’s configuration. Even, if necessary, taking priority over the
 requirements of the client machine’s owner. This would be a weak form of Remote
 Attestation. The goal, in this case, is to make things like the Superfish and
 Dell certificates ineffective for use in attacks or mischief: the interloper
 certificates just wouldn’t work, and would hence be discovered immediately.&lt;/p>

&lt;p>However, it is not possible for a low-privilege application to defend against
 the platform it runs on, if the platform is intent on undermining the
 application’s expectations. To try would be futile, and would necessarily also
 violate a crucial digital rights principle: The computer’s owner should get to
 decide how the computer behaves. Dell and Lenovo let their customers down in
 that way, but for better and for worse, it’s not something that a web browser
 can fix.&lt;/p>

&lt;p>Our idea when designing HPKP was to &lt;a href="/2015/05/01/about-http-public-key-pinning/">allow a site to reduce the
 number of issuers that can issue certificates for the site&lt;/a> — assuming the
 client is not already compromised. We assumed that because we must: as &lt;a
 href="https://www.chromium.org/Home/chromium-security/security-faq">the Chromium
 Security FAQ&lt;/a> and &lt;a
 href="http://blogs.technet.com/b/rhalbheer/archive/2011/06/16/ten-immutable-laws-of-security-version-2-0.aspx">Microsoft’s
 10 Immutable Laws Of Security&lt;/a> document, if a computer’s operating system is
 compromised, there is nothing certain that a mere userland application — which
 must depend on the underlying layers, including the OS — can do.&lt;/p>

&lt;p>Specifically, browsers do not perform Pin Validation when the presented
 certificate chain chains up to a locally-installed, ‘private’, or ‘non-system’
 trust anchor. (Microsoft ships a standard set of trust anchors for the system,
 but also enables the system’s administrators/owners to install additional, local
 anchors.) There are 3 reasons for this:&lt;/p>

&lt;ul>

 &lt;li>There are legitimate reasons to proxy TLS connections — &lt;a href="http://www.telerik.com/fiddler">not least of
 which is debugging&lt;/a>.
 Personally I am extremely skeptical of the value of AV/IDS/IPS/DLP proxies, but
 some people use them on the computers they own. To them, that’s legitimate use,
 too.&lt;/li>

 &lt;li>A user program cannot defend against software running at the same or a
 higher level of privilege, and it is pointless to try. The effort will be either
 entirely wasted, or will outweigh any marginal, temporary gains.&lt;/li>

 &lt;li>Computers should do what their owners want, or at least give the owner
 priority over the desires of a remote server operator.&lt;/li>

&lt;/ul>

&lt;p>All the same, people seem to wish that servers could say to clients, “Here
 are my expected keys, and you should fail to connect to me if I seem to present
 different keys, &lt;em>even if the person who owns the computer wants to connect
 anyway&lt;/em>.” That would be beneficial in that non-consensual proxying would be
 exposed sooner and with somewhat more certainty. But if a server could get such
 a guarantee, it could also be used in ways very much counter to the open
 Internet we know and love. Thus, frankly, I’m glad that Remote Attestation is
 impossible. (Or, if you prefer, so impractical and theoretical as to be
 impossible for now.)&lt;/p>

&lt;p>There are many, many ways in which the higher-privilege operating system or
 other software can force the lower-privilege client program to connect through a
 proxy, in spite of a hypothetical ‘strict’ HPKP behavior. Here are a few
 examples — I don’t imagine this list is exhaustive:&lt;/p>

&lt;ul>

 &lt;li>Installing a new trust anchor in the local store&lt;/li>

 &lt;li>Installing a new trust anchor in the system store&lt;/li>

 &lt;li>Injecting a DLL that overrides the usual Pin Validation and X.509 validation
 code&lt;/li>

 &lt;li>Overwriting the application’s code on disk&lt;/li>

 &lt;li>Overwriting the application’s code in memory at run-time&lt;/li>

 &lt;li>Installing a &lt;a href="https://en.wikipedia.org/wiki/Layered_Service_Provider">layered service
 provider&lt;/a> (LSP)&lt;/li>

&lt;/ul>

&lt;p>The ironic thing is that, if clients did implement the ‘strict’ form of Pin
 Validation, many of the same people who are now calling for it would either
 resort to the above means to do their legitimate proxying, or would buy their
 proxy software from someone who does.&lt;/p></description><author>Chris Palmer</author><guid>2015/11/24/what-is-hpkp-for/index.html</guid><pubDate>Tue, 24 Nov 2015 00:00:00 +0000</pubDate></item><item><title>What Is A ‘Permission’?</title><link>https://noncombatant.org/2015/10/28/what-is-a-permission/index.content</link><description>&lt;h1>What Is A ‘Permission’?&lt;/h1>

&lt;p>&lt;time>27 October 2015&lt;/time>&lt;/p>

&lt;aside>
 &lt;p>Updated 28 October 2015 to clarify a bit, and to elaborate on what
 choosers provide.&lt;/p>
&lt;/aside>

&lt;p>Every application platform needs to decide on 1 or more &lt;em>protection
 mechanisms&lt;/em> to protect &lt;em>principals&lt;/em> from each other — and thereby to
 protect the &lt;em>assets&lt;/em> that the principals operate on. (If you are
 wondering what those words mean, start by reading the classic &lt;a
 href="http://www.cs.virginia.edu/~evans/cs551/saltzer/">“The Protection Of
 Information In Computer Systems”&lt;/a> by Saltzer and Schroeder.)&lt;/p>

&lt;p>Of course, platforms don’t &lt;em>need&lt;/em> to provide a protection mechanism; I
 was being a bit hyperbolic in the previous paragraph. For example, DOS and Mac
 OS Classic had no protection mechanisms. But, well, they’re dead, aren’t they?
 It’s no coincidence: they are dead in part due to their lack of protection.&lt;/p>

&lt;p>So, platforms need to provide some protection mechanism to be viable on the
 modern internet. This includes &lt;a href="https://en.wikipedia.org/wiki/Open_Web_Platform">the Open Web Platform&lt;/a>
 (OWP). As a Chrome security engineer, I am obviously interested in what
 protection mechanisms the OWP provides; as a Chrome secure usability engineer, I
 am interested in how well people can understand and use those protection
 mechanisms, and how we can improve their effectiveness and usability.&lt;/p>

&lt;p>Most platforms, including the OWP, use a hybrid design in which more than 1
 protection mechanism is at play. As we’ll see, there are reasons for this.
 However, the more mechanisms there are, the more complicated their interaction
 and the more complicated the overall system. That complexity makes it more
 difficult it is for the system’s designers, developers, and users to build
 accurate mental models of the system.&lt;/p>

&lt;p>Thus, we should like to have a ‘pure’ system: a system that uses a single,
 solid, understandable protection mechanism. When that is not possible, the
 system should strive to make 1 of the mechanisms primary, and use the other
 mechanism(s) to bootstrap the primary mechanism.&lt;/p>

&lt;p>In the context of the OWP, we want to understand what we call ‘permissions’:
 special powers that the person browsing a web origin gives to that origin, such
 as the ability to determine the person’s computer’s geolocation, to read and
 upload a file from the computer’s local storage, to listen on the computer’s
 microphone, and so on.&lt;/p>

&lt;h2>Definitions&lt;/h2>

&lt;p>A &lt;em>permission&lt;/em> is a (possibly persistent, possibly ephemeral)
 capability grant. Think of a &lt;code>Permission&lt;/code> as a hypothetical abstract
 superclass that the hypothetical subclasses &lt;code>ObjectCapability&lt;/code> and
 &lt;code>SymbolicCapability&lt;/code> implement. I’ll try to explain what I mean by
 that in the rest of this post.
&lt;/p>

&lt;p>I use the term &lt;em>capability&lt;/em> in the sense of a &lt;a
 href="https://en.wikipedia.org/wiki/Capability-based_security">capability-based
 protection mechanism&lt;/a> (as opposed to an &lt;a href="https://en.wikipedia.org/wiki/Access_control_list">access
 control
 list-based protection mechanism&lt;/a>). (In other contexts ‘capability’ can mean
 other things — naming things remains a Hard Problem in computing science.)&lt;/p>

&lt;p>The key features of capabilities are:&lt;/p>

&lt;ul>

 &lt;li>&lt;strong>Unforgeability&lt;/strong>: A process cannot falsely claim to hold a
 capability. The system will detect and reject false claims.&lt;/li>

 &lt;li>&lt;strong>Transferability&lt;/strong>: A process can (generally) pass a
 capability on to another process. In some systems (‘pure’ capability systems),
 this may be the only way any process ever gets any capabilities.&lt;/li>

 &lt;li>&lt;strong>Inherent authorization&lt;/strong>: A process that holds a capability
 is &lt;em>by that fact alone&lt;/em> known to be authorized to use the capability.

 &lt;blockquote>In some systems, that is not true, or sometimes not true. &lt;a
 href="http://blogs.technet.com/b/markrussinovich/archive/2005/10/19/the-bypass-traverse-checking-or-is-it-the-change-notify-privilege.aspx">Windows
 includes an option to re-check that the bearer of a capability is still
 authorized on each access&lt;/a>. This setting is almost always disabled — except
 in Chrome’s sandboxed renderer processes! Weird but true.&lt;/blockquote>
 &lt;/li>

 &lt;li>&lt;strong>Opacity&lt;/strong>: A capability is some kind of opaque reference —
 the value of the reference has no special meaning to its holder. Different
 processes holding the same capability might possibly have different opaque
 representations of a reference to the same underlying object. (Compare e.g. a
 pointer in C, on which the ++ operator is meaningful, to a POSIX file
 descriptor.) Opacity and unforgeability are closely related but distinct.&lt;/li>

&lt;/ul>

&lt;p>By contrast, &lt;em>access control list&lt;/em>-based mechanisms have only
 unforgeability. As an example, consider the POSIX file permissions model (which
 is relatively simple, compared to e.g. Windows). For each file, there are 3
 principals: the user-owner, the group-owner, and ‘other’ (all other principals).
 Each principal has 0 or more of 3 access rights on the file: read, write, or
 execute. Whenever a process tries to &lt;code>open&lt;/code> the file, the operating
 system kernel checks the process’ principal (user ID and group ID) against the
 file’s access control list.&lt;/p>

&lt;pre>
$ &lt;strong>ls -l /Music/Thelonious\ Monk/Brilliant\ Corners/&lt;/strong>
total 48392
-rwxr-xr-x 1 chris chris 8392333 Sep 8 2009 01 Brilliant Corners.mp3
-rwxr-xr-x 1 chris chris 15283234 Sep 8 2009 02 Ba-Lue Bolivar Ba-Lues-Are.mp3
-rwxr-xr-x 1 chris chris 10443816 Sep 8 2009 03 Pannonica.mp3
-rwxr-xr-x 1 chris chris 7029272 Sep 8 2009 04 I Surrender, Dear.mp3
-rwxr-xr-x 1 chris chris 8395820 Sep 8 2009 05 Bemsha Swing.mp3
&lt;/pre>

&lt;p>The user &lt;strong>chris&lt;/strong> can read, write, and execute these MP3 files;
 any user in the &lt;strong>chris&lt;/strong> group can read or execute them; and any
 other user can read or execute them.&lt;/p>

&lt;p>User &lt;strong>chris&lt;/strong> can change the permissions:&lt;/p>

&lt;pre>
$ &lt;strong>chmod -x /Music/Thelonious\ Monk/Brilliant\ Corners/*&lt;/strong>
$ &lt;strong>ls -l /Music/Thelonious\ Monk/Brilliant\ Corners/&lt;/strong>
total 48392
-rw-r--r-- 1 chris chris 8392333 Sep 8 2009 01 Brilliant Corners.mp3
-rw-r--r-- 1 chris chris 15283234 Sep 8 2009 02 Ba-Lue Bolivar Ba-Lues-Are.mp3
...
&lt;/pre>

&lt;p>including granting write access to ‘other’:&lt;/p>

&lt;pre>
$ &lt;strong>chmod o+w /Music/Thelonious\ Monk/Brilliant\ Corners/*&lt;/strong>
$ &lt;strong>ls -l /Music/Thelonious\ Monk/Brilliant\ Corners/&lt;/strong>
total 48392
-rwxr-xrwx 1 chris chris 8392333 Sep 8 2009 01 Brilliant Corners.mp3
-rwxr-xrwx 1 chris chris 15283234 Sep 8 2009 02 Ba-Lue Bolivar Ba-Lues-Are.mp3
...
&lt;/pre>

&lt;p>which is kind of like transferability. But it’s better to read
 transferability as meaning “transference to a &lt;em>specific&lt;/em> process or
 principal”. And we can see that this is not possible with POSIX file
 permissions:&lt;/p>

&lt;pre>
$ &lt;strong>grep nobody /etc/passwd&lt;/strong>
nobody:x:65534:65534:nobody:/nonexistent:/usr/sbin/nologin
$ &lt;strong>chown nobody /Music/Thelonious\ Monk/Brilliant\ Corners/*&lt;/strong>
chown: changing ownership of ‘/Music/Thelonious Monk/Brilliant Corners/01 Brilliant Corners.mp3’: Operation not permitted
chown: changing ownership of ‘/Music/Thelonious Monk/Brilliant Corners/02 Ba-Lue Bolivar Ba-Lues-Are.mp3’: Operation not permitted
...
&lt;/pre>

&lt;p>A good example of transferability is &lt;a
 href="http://blog.varunajayasiri.com/passing-file-descriptors-between-processes-using-sendmsg-and-recvmsg">sending
 a file descriptor from 1 process to another over a UNIX domain socket using
 &lt;code>sendmsg&lt;/code> and &lt;code>recvmsg&lt;/code>&lt;/a>.&lt;/p>

&lt;h2>Prefer Capabilities Over ACLs&lt;/h2>

&lt;p>On the web platform we would like to use a capability-based protection
 mechanism to the greatest extent possible, rather than an ACL-based mechanism.
 There are a few reasons for this.&lt;/p>

&lt;h3>Capabilities Make For Good UX&lt;/h3>

&lt;p>Capabilities are a good fit for a well-known secure UX pattern: the
 &lt;em>chooser&lt;/em>. An untrustworthy process (like a web renderer) can ask a
 trustworthy process (like the browser) for a capability (say, a file descriptor
 from which to read data to upload to the web origin). Only the trustworthy
 process can grant it. The trustworthy process shows the person a chooser UX, the
 person selects a file (or, no file), and the trustworthy process opens the file
 and passes the descriptor to the untrustworthy process. The untrustworthy
 process has no ambient authority, and the user gets an understandable,
 empowering interface to selectively grant authority.
&lt;/p>

&lt;figure>&lt;img src="chooser-example.png" loading="lazy" width="852" height="679" alt="A screenshot of a file chooser" />
 &lt;figcaption>The return value of the file
 chooser UX flow is, or should be, a file descriptor or other
 capability.&lt;/figcaption>
&lt;/figure>

&lt;p>Choosers can let people choose much more than just files and directories. A
 chooser can return any kind of object. Everything that a computer program can
 represent can be handled as an &lt;em>object capability&lt;/em>: any kind of &lt;a
 href="https://technet.microsoft.com/en-us/library/cc781716(v=ws.10).aspx">&lt;em>securable
 object&lt;/em>&lt;/a> that the operating system can process; any kind of function,
 object, closure, or continuation.&lt;/p>

&lt;p>Additionally, choosers can grant specific objects at a specific time in a
 specific context. For example, maybe you would like to grant hangouts.google.com
 access to the external USB camera just this once, not all the time. Choosers
 make that easy; by contrast, setting an ACL on &lt;code>/dev/camera&lt;/code> may turn
 out to be a surprisingly broad grant.&lt;/p>

&lt;h3>ACLs Can Make For Bad UX&lt;/h3>

&lt;p>ACLs are a pain in the ass (a) generally; (b) especially when the principals
 are complex (as web origins + Chrome profiles + people are); and (c) when the
 principals are numerous (how many web origins do you visit? 90 billion per
 day).&lt;/p>

&lt;h3>Namespaces Are Ambient Authority&lt;/h3>

&lt;p>The ambient namespace that most ACL-based mechanisms provide (e.g. the
 filesystem, the namespace of named pipes on Windows, et c.) often turns out to
 provide more information and authority to untrustworthy processes than the
 person intended. For example, the pathnames themselves might give away
 information, ACLs have a notable tendency to diverge from the intended
 permission grant (because they impose a maintenance burden), et c.&lt;/p>

&lt;p>Closing the gaps left open in ACL-based systems has proved difficult and
 inelegant. (See e.g. &lt;a href="https://msdn.microsoft.com/en-us/library/bb625963.aspx">Windows integrity
 levels&lt;/a>, or &lt;a href="https://en.wikipedia.org/wiki/Security-Enhanced_Linux">SELinux&lt;/a>.)&lt;/p>

&lt;blockquote>“Applications can be designed to run at a low integrity level.
 Protected Mode Internet Explorer is an example of a Windows Vista application
 that is designed to run at low integrity. Applications at low integrity might
 need folders in the file system where they can write temporary files or
 application data. In the case of Protected Mode Internet Explorer, the Temporary
 Internet File folder in the user’s profile is used. How can a low application
 write to a file system folder? The folder must be assigned an explicit mandatory
 label that permits write access from a low integrity process.” — &lt;a
 href="https://msdn.microsoft.com/en-us/library/bb625963.aspx">MSDN, “Windows
 Integrity Mechanism Design”&lt;/a>&lt;/blockquote>

&lt;p>ACLs (especially highly &lt;a href="https://technet.microsoft.com/en-us/library/cc781716(v=ws.10).aspx">complex
 ACLs like in Windows&lt;/a>) have proved to be hard to use. By contrast, choosers
 are so easy to use they are now nearly invisible — even engineers often don’t
 realize how large of a problem they handily solve.&lt;/p>

&lt;h2>Ephemeral vs. Persistent Capabilities&lt;/h2>

&lt;p>Normally, “capability” means &lt;em>object capability&lt;/em> (such as a POSIX file
 descriptor, a Windows &lt;code>HANDLE&lt;/code>, a Python object reference, et c.).
 However, in the context of the web platform, we often need to persist
 capabilities across instantiations of the principal. That is, different renderer
 processes running the origin (https, www.example.com, 443) on behalf of profile
 1 owned by chris@goatbeast.localdomain might all need to get a reference to the
 same capability, even across browser restart or computer reboot.&lt;/p>

&lt;p>For persistent capabilities, we need to persist a symbolic representation: a
 &lt;em>symbolic capability&lt;/em> instead of an object cap. (This is a limitation of
 the memory persistence mechanisms in common operating systems, not of objects
 caps themselves; see below.) There must be a way to bootstrap the symbolic cap
 into an object cap. 1 way to do this is with an ACL, although ACLs are not
 the only way to achieve this.
&lt;/p>

&lt;blockquote>Cryptographic capabilities are another form of symbolic cap that a
 process can bootstrap into an object cap; for example, consider encrypted and
 integrity protected HTTP cookies that store the session state. In effect, this
 cookie is an opaque, transferable reference to the next continuation in the
 session — a persistent capability that requires no ACL to bootstrap. — &lt;a
 href="https://en.wikipedia.org/wiki/Capability-based_security#Sharing_of_capabilities_between_processes">Wikipedia,
 “Capability-based security”&lt;/a>&lt;/blockquote>

&lt;p>In Chrome, we persist capabilities as symbolic caps coupled with a simple
 form of ACL. In this picture, the &lt;strong>Hostname Pattern&lt;/strong> names a
 (group of) origins, and the &lt;strong>Behavior&lt;/strong> describes the access
 grant.&lt;/p>

&lt;figure>&lt;img src="permission-list.png" width="555" height="357" loading="lazy"
 alt="A screenshot of Chrome’s ACL for the Notifications API" />
 &lt;figcaption>This is
 an ACL for persisted, symbolic capabilities to the browser’s Notifications
 API.&lt;/figcaption>
&lt;/figure>

&lt;p>Finally, if we had &lt;a
 href="https://en.wikipedia.org/wiki/Persistence_(computer_science)#Orthogonal_or_transparent_persistence">operating
 systems that could persist the live object graphs of processes&lt;/a>, we wouldn’t
 need the bootstrapping step, and we could have all object caps all the time.
 When booting up, the operating system would resuscitate a live object graph from
 non-volatile storage into working memory, and all object capabilities would be
 live. That would be nice and fancy, but it’s not strictly necessary. ACLs can be
 a perfectly good way to bootstrap caps — &lt;em>if and only if bootstrapping is the
 only action that uses ACLs&lt;/em>. (Consider the design of POSIX, which has both
 &lt;code>stat&lt;/code> and &lt;code>fstat&lt;/code>, &lt;code>open&lt;/code> and
 &lt;code>openat&lt;/code>, &lt;code>unlink&lt;/code> but not &lt;code>funlink&lt;/code>, and so
 on. It would be better — “more cappy” — if POSIX provided only
 &lt;code>openat&lt;/code>, &lt;code>fstat&lt;/code>, &lt;code>funlink&lt;/code>, and so on.) For
 example, all sorts of &lt;a
 href="https://en.wikipedia.org/wiki/Time_of_check_to_time_of_use">time-of-check/time-of-use&lt;/a>
 (TOCTOU) and other vulnerable race conditions are a direct result of operations
 on file pathnames (symbolic capabilities) rather than on file descriptors (live
 object capabilities).
&lt;/p>

&lt;h2>Therefore&lt;/h2>

&lt;p>Hybrid ACL/cap platforms should strive to use only object capabilities
 wherever possible. Where persistence is necessary, we should persist symbolic
 capabilities and ACLs which we use only to bootstrap live object caps.&lt;/p>

&lt;h2>Stay Tuned&lt;/h2>

&lt;p>I’ve got a draft half-written that talks about a few other protection
 mechanisms, and their engineering trade-offs.&lt;/p></description><author>Chris Palmer</author><guid>2015/10/28/what-is-a-permission/index.html</guid><pubDate>Tue, 27 Oct 2015 00:00:00 +0000</pubDate></item><item><title>A New (?) Guitar Circuit</title><link>https://noncombatant.org/2015/10/10/new-guitar-circuit/index.content</link><description>&lt;h1>A New (?) Guitar Circuit&lt;/h1>

&lt;p>&lt;time>10 October 2015&lt;/time>&lt;/p>

&lt;p>I love the trivial yet effective circuitry of an electric guitar or bass.
That sweet spot of usefulness and simplicity pretty much defines my aesthetic
sense for all things!&lt;/p>

&lt;p>The &lt;a href="https://en.wikipedia.org/wiki/Guitar_wiring">basic guitar
circuit&lt;/a> has just a few elements, all 1930s technology:&lt;/p>

&lt;ul>

&lt;li>1 – 3 passive magnetic pickups&lt;/li>

&lt;li>Passive cut master volume potentiometer (“pot”), or 1 passive volume for
each pickup&lt;/li>

&lt;li>Passive cut master tone control (low-pass filter: 1 pot and 1 capacitor), or
1 passive tone for each pickup&lt;/li>

&lt;li>If more than 1 pickup, switch(es) to select between the pickups&lt;/li>

&lt;/ul>

&lt;p>There are many possible combinations of these simple elements, and many
possible embellishments.&lt;/p>

&lt;ul>

&lt;li>Switches to enable or disable each pickup individually, allowing all
possible pickup combinations&lt;/li>

&lt;li>Switches to disable 1 of the coils of a double-coil pickup&lt;/li>

&lt;li>Switches to run 2 pickup coils in either parallel or series&lt;/li>

&lt;li>Active tone control circuits (most common on basses, where they really
help)&lt;/li>

&lt;li>Pickup blend pots&lt;/li>

&lt;/ul>

&lt;p>So anyway, I had a dream last night of a circuit I think might be
surprisingly useful while still being very simple. I imagined this circuit for a
2-pickup guitar like a Telecaster or Les Paul, but I bet it could be adapted for
guitars with 3 pickups, or a single 2-coil pickup, or whatever.&lt;/p>

&lt;ul>

&lt;li>Neck pickup (any type)&lt;/li>

&lt;li>Bridge pickup (any type)&lt;/li>

&lt;li>Volume 1, for 1 pickup&lt;/li>

&lt;li>Volume 2, for the other pickup&lt;/li>

&lt;li>Master tone control&lt;/li>

&lt;li>Switch to control which volume control controls which pickup&lt;/li>

&lt;/ul>

&lt;p>With this circuit, the player can blend the 2 pickups in any combination,
e.g. bridge alone, neck alone, both at full volume, neck at full volume and
bridge at half, et c.&lt;/p>

&lt;p>Furthermore, the player can reverse the blend by throwing the volume control
switch — if volume 1 is on 10 and volume 2 is on 0, it’s a traditional pickup
selector. But it could also change the sound from neck volume 10 + bridge volume
5 → neck volume 5 + bridge volume 10, or other pickup blends.&lt;/p>

&lt;p>For visual cleanliness and (I think) playability, the volume control switch
should be packaged together with volume 1 in a &lt;a
href="http://www.warmoth.com/Push-Push-Pot-500k-with-DPDT-Switch-On-On-P732.aspx">push-push
pot&lt;/a>.&lt;/p>

&lt;p>As an embellishment, you can imagine additional switches to change the 2
pickups to be in series or parallel, or to coil-tap the pickups, and so on. You
could also use the switch in a push-push pot to take that pot in or out of the
circuit. The extreme form of the idea would be for all 3 pots to have a
push-push switch, and use each switch for something.&lt;/p></description><author>Chris Palmer</author><guid>2015/10/10/new-guitar-circuit/index.html</guid><pubDate>Sat, 10 Oct 2015 00:00:00 +0000</pubDate></item><item><title>Review: Tech 21 Fly Rig 5</title><link>https://noncombatant.org/2015/09/26/fly-rig-5-review/index.content</link><description>&lt;h1>Review: Tech 21 Fly Rig 5&lt;/h1>

&lt;p>&lt;time>26 September 2015&lt;/time>&lt;/p>

&lt;p>I hate guitar amplifiers. They’re heavy, unwieldy, noisy, highly directional,
 and too loud. I obviously can’t play through an amplifier in my apartment. I
 live in SF, so driving to gigs is a drag because parking; yet there’s no chance
 I could take an amp on public transport. I’ve longed for a more convenient
 alternative that still produces good tone.&lt;/p>

&lt;p>To solve this problem, I bought a bunch of pre-amps and speaker emulators to
 and the winner is the &lt;a href="http://www.tech21nyc.com/products/sansamp/flyrig.html">Tech 21 Fly Rig
 5&lt;/a>. I might review the runners-up in a later post. Here, I’ll talk about the
 Fly Rig.&lt;/p>

&lt;p>The Fly Rig, along with everything else I need, fits in my guitar case. This
 is now all I need to bring to rehearsal and gigs:&lt;/p>

&lt;figure>&lt;img src="guitar-rig.jpg" alt="My complete guitar rig" width="1000" height="750" loading="lazy" />
 &lt;figcaption>My complete gig-ready guitar rig: &lt;a href="http://www.warmoth.com/">Warmoth&lt;/a> Strat, Tech 21 Fly Rig
 5, clip-on
 tuner, extra strings, picks, ear plugs. I quite like the &lt;a
 href="http://www.skbcases.com/music/products/proddetail.php?id=775">light-weight
 SKB case&lt;/a>.&lt;/figcaption>
&lt;/figure>

&lt;p>I plug the Fly Rig into our PA for rehearsal, and it sounds great. Katya can
 control my volume and the overall mix easily, so our volume and EQ don’t get out
 of control (as happens so often when guitar players control their amp volume).
 Similarly, the sound engineer at a live venue will hate you the least of all
 guitar players.&lt;/p>

&lt;p>The Fly Rig has all the basic sounds I need:&lt;/p>

&lt;ul>

 &lt;li>Sans Amp speaker emulation with 3-band EQ, &lt;strong>Level&lt;/strong>, and
 &lt;strong>Drive&lt;/strong> controls.
 &lt;/li>

 &lt;li>A decent spring reverb emulation. I love reverb and almost always leave it
 dialed to 3:00 or 5:00!&lt;/li>

 &lt;li>Distortion with &lt;strong>Level&lt;/strong>, &lt;strong>Tone&lt;/strong>, and
 &lt;strong>Drive&lt;/strong> controls.
 &lt;/li>

 &lt;li>Independent boost with selectable level (&lt;strong>Hot&lt;/strong>).&lt;/li>

 &lt;li>Tap-tempo delay — fundamental to my playing style. As a bonus it has a
 &lt;strong>Drift&lt;/strong> control for chorus-y delay effects. You can get a decent
 warbly chorus by turning &lt;strong>Drift&lt;/strong> up and &lt;strong>Level&lt;/strong>,
 &lt;strong>Repeats&lt;/strong>, and &lt;strong>Time&lt;/strong> down.
 &lt;/li>

&lt;/ul>

&lt;p>Each control has an LED light inside, so you can easily see which options are
 turned on and what their knobs are set at:&lt;/p>

&lt;figure>&lt;img src="close-up.jpg" alt="Close-up of the Tech 21 Fly Rig 5" width="1000" height="438" loading="lazy" />
 &lt;figcaption>Close-up view of the Fly
 Rig, all lights on.&lt;/figcaption>
&lt;/figure>

&lt;p>When recording at home or in the studio, I tend to use more delays, a looper
 pedal, and a dedicated reverb and tremolo box (&lt;a href="http://www.strymon.net/products/flint/">the beautiful and
 perfect Strymon
 Flint&lt;/a>). But carrying just 1 case to a gig is so convenient that I will give
 up the extra delays!&lt;/p>

&lt;h2>Sounds&lt;/h2>

&lt;p>The signal chain for all sound samples is Strat → Fly Rig → Radial J48 DI box
 → Alesis Multimix 8 mixer → Garage Band. The recordings are pretty noisy because
 I live near Sutro Tower. :) The Strat has 6 pickup positions, which you’ll hear
 me switching through in the first sample: bridge double, bridge single, both
 pickups double, neck single, neck double, both pickups single.&lt;/p>

&lt;p>Here are the Fly Rig’s basic sounds:&lt;/p>

&lt;audio controls>
 &lt;source src="basic-sounds.mp3" />
 &lt;a href="basic-sounds.mp3">Download&lt;/a>
&lt;/audio>

&lt;p>I didn’t include it in that sample, but you can get a vicious
 fuzz/direct-to-mixer sound by turning the distortion on and the Sans Amp speaker
 emulator off.&lt;/p>

&lt;p>Here is the tap tempo delay doing dotted eighth notes, which a touch of
 Drift:&lt;/p>

&lt;audio controls>
 &lt;source src="deep-below-intro.mp3" />
 &lt;a href="deep-below-intro.mp3">Download&lt;/a>
&lt;/audio>

&lt;p>And here is a Yngwie-like sound: Marshall-style distortion with the Strat on
 the neck pickup in single-coil mode:&lt;/p>

&lt;audio controls>
 &lt;source src="a-minor-noodle.mp3" />
 &lt;a href="a-minor-noodle.mp3">Download&lt;/a>
&lt;/audio>

&lt;h2>Conclusion&lt;/h2>

&lt;p>If you share my view of amps, definitely get one of these or something else
 from Tech 21. I love the Fly Rig.&lt;/p>

&lt;p>&lt;strong>Good:&lt;/strong>&lt;/p>

&lt;ul>

 &lt;li>Easy to use: you can just turn every knob to noon and
 start playing immediately.&lt;/li>

 &lt;li>Reasonable price ($250).&lt;/li>

 &lt;li>Usable as a headphone amp (with a mono-to-stereo adapter).&lt;/li>

&lt;/ul>

&lt;p>&lt;strong>Bad:&lt;/strong>&lt;/p>

&lt;ul>

 &lt;li>For some reason, the Fly Rig powers up with all options turned on. This is
 loud if your channel on the mixing board is not set to 0 when you turn on. It
 seems like that could damage something.&lt;/li>

 &lt;li>No stereo output. I love stereo delay, and when you use the Fly Rig as a
 headphone amp, unless you have a mono-to-stereo adapter, you’ll only get sound
 in 1 ear.&lt;/li>

 &lt;li>Requires a special AC adapter: 12V, 150mA instead of the more standard
 Boss-style 9V. The adapter that comes with the Fly Rig is not as robust as the
 excellent Visual Sound ones. Visual Sound does sell a 12V adapter.&lt;/li>

&lt;/ul>

&lt;p>&lt;strong>Ugly:&lt;/strong> Only some of the knobs come with rubber grippers on
 them. The gripper-less knobs are very hard to use. If you like, you can let Tech
 21 nickel-and-dime you: They sell extra grippers, 10 for $7. Plus shipping.&lt;/p>

&lt;figure>&lt;img src="knob-grippies.jpg" alt="Extra rubber knob grippers, sold
separately" width="500" height="572" loading="lazy" />
 &lt;figcaption>&lt;a href="http://www.tech21nyc.com/products/accessories/index.html">Additional knob
 grippers sold separately&lt;/a>, for 7 friggin’ dollars.&lt;/figcaption>
&lt;/figure>

&lt;p>The Fly Rig is almost perfect! I hope never to use a guitar amp ever
 again.&lt;/p></description><author>Chris Palmer</author><guid>2015/09/26/fly-rig-5-review/index.html</guid><pubDate>Sat, 26 Sep 2015 00:00:00 +0000</pubDate></item><item><title>Security And Apparentness</title><link>https://noncombatant.org/2015/09/20/security-and-apparentness/index.content</link><description>&lt;h1>Security And Apparentness&lt;/h1>

&lt;p>&lt;time>20 September 2015&lt;/time>&lt;/p>

&lt;aside>

&lt;p>Update 28 October 2015: &lt;a
href="http://conferences2.sigcomm.org/imc/2015/papers/p27.pdf">“Neither Snow Nor
Rain Nor MITM… An Empirical Analysis of Email Delivery Security”&lt;/a> by
Durumeric, et al. confirms my assertion that opportunistic security must be
either useless or rarely adopted:&lt;/p>

&lt;blockquote>We analyze the mail sent to Gmail from these hosts and find that in
seven countries, more than 20% of all messages are actively prevented from being
encrypted. In the most severe case, 96% of messages sent from Tunisia to Gmail
are downgraded to cleartext.&lt;/blockquote>

&lt;p>If you actually need STARTTLS, you can’t count on it doing anything. One
solution would be for Gmail to require STARTTLS, and to require some kind of
Certificate Transparency or key pinning for STARTTLS certificates. But then the
next problem would arise: surfacing the connection failures to people. Due to
the asynchronous and ‘it just works’ nature of email, I don’t see an elegant or
even minimally workable solution to that problem. I’d love to be proven
wrong...&lt;/p>

&lt;/aside>

&lt;p>Original post follows:&lt;/p>

&lt;hr/>

&lt;p>If an application (or platform, or protocol, or...) cannot communicate a
particular security guarantee to the person — perhaps because there is no
channel by which to communicate the message — then the mechanism that provides
the security guarantee can be at best &lt;em>opportunistic&lt;/em>. The mechanism
provides the guarantee if conditions are favorable; otherwise, it does not.&lt;/p>

&lt;p>With an opportunistic security mechanism, there arises a question: whether or
not the effort to develop the mechanism, and the attack surface the mechanism
exposes, is worth the benefit — which is likely to be negligible.&lt;/p>

&lt;p>The reason the benefit of an opportunistic security mechanism is likely to be
negligible is that, because the application cannot communicate failures to the
person, the success or failure of the mechanism cannot possibly be part of the
person’s mental model of the system. Thus, the person is very likely to rank
other benefits — such as availability or performance — above the security
benefit that they cannot even perceive.&lt;/p>

&lt;p>Thus, opportunistic security mechanisms almost certainly must fail open,
rather than fail closed. If an opportunistic security mechanism were to fail
closed, but the application could not communicate a particular reason or
recourse to the person, people would be likely to reject the application as
being flaky and unpredictably unavailable.&lt;/p>

&lt;p>Thus, in the presence of an attacker, the opportunistic security mechanism
must, by design, be useless or rarely adopted.&lt;/p>

&lt;p>An application may also fail to communicate the failure of a security
mechanism not because the communication channel to the person is lacking, but
because it is too complex. Too much communication can be just as bad as too
little.&lt;/p>

&lt;p>If the application cannot communicate the security guarantee to the person
because the semantics of the security are too complex, the application
developers should simplify the security guarantee. Specifically, by simplifying
(or “quantizing”) the security guarantee &lt;em>upward&lt;/em>. (Or, equivalently,
quantizing the semantic complexity downward.)&lt;/p>

&lt;p>For example, it can be very difficult to explain in an application’s UX that
the person’s communications with their friend are encrypted but not
authenticated; or authenticated but not encrypted. Thus, it is better to provide
both authentication and encryption together, and clearly label that state
‘secure’; or to provide neither and clearly label that state ‘non-secure’.
(Alternately, an application whose users will accept occasional unavailability
may instead report a connection error and explain that no ‘secure’ connection is
available at the time.)&lt;/p>

&lt;p>To &lt;a href="http://iang.org/ssl/h1_the_one_true_cipher_suite.html">paraphrase
Ian Grigg&lt;/a>, we can characterize the ultimate security quantization as, “There
is 1 mode, and it is secure”. Allowing less-secure or non-secure modes
complicates the mechanism’s semantics and implementation. Such complexity makes
it difficult both for the people who use the application and the people who
develop the application to model the application’s states accurately.&lt;/p>

&lt;p>In fact, there is much less of a bright line between ‘developers’ and ‘users’
than either group believes. Developers, just like users, inevitably create
inaccurate models of the application. Developers call it &lt;em>abstraction&lt;/em>,
and call it a necessary virtue. And they are right.&lt;/p></description><author>Chris Palmer</author><guid>2015/09/20/security-and-apparentness/index.html</guid><pubDate>Sun, 20 Sep 2015 00:00:00 +0000</pubDate></item><item><title>Technology, Longevity, And Art</title><link>https://noncombatant.org/2015/08/31/technology-longevity-art/index.content</link><description>&lt;h1>Technology, Longevity, And Art&lt;/h1>

&lt;p>&lt;time>31 August 2015&lt;/time>&lt;/p>

&lt;p>Guitarist &lt;a href="http://www.pledgemusic.com/projects/allanholdsworth">Allan
Holdsworth is running a Pledge Music campaign to help produce his latest
recordings&lt;/a>. As a contributor, I have access to a video interview with him in
which he describes how he’s recording the material, and he had some interesting
thoughts on technology that struck me.&lt;/p>

&lt;blockquote>

&lt;p>0:13: [After improvising a melody on the guitar, connected to his large Mac
OS X-based digital audio workstation set-up] It’s OK, but now I can keep going
back and tweezing with it, which is [cackle] the last thing you want to give
somebody like me the opportunity to do, ’cause I’ll just keep going forever. It
was kind of easier in the old days, because when you finished your solo, you
were done. There was not much you could do with it. Now I can keep going, like I
said before, until the computer decides &lt;em>it&lt;/em> didn’t like it, and it eats
it, and says, “Thank you! Good night! Next!” Then you have to do it all again.
It’s the Crash Syndrome.&lt;/p>

&lt;p>1:40: And here we go. A blast from the past. This is my old Atari [ST]. I
have 2 of them — I actually have 4 of them. But I have 2 of them right here.
This one’s running the DX-7 program SynthWorks, because I love DX-7s. And you
can’t buy DX-7s. I have a whole rack of DX-7s here, which I think are absolutely
spectacular. Why Yamaha makes something and discontinues it 2 weeks later, I
don’t know, but they do. Anyway [pointing to another Atari ST], here’s Cubase 3.
With a company up in San Francisco that makes an adapter so you can use a big
monitor on it [the Atari is connected to a modern flat panel display]. That
thing is &lt;em>flawless&lt;/em>. It. Never. Crashes. I’m extremely proud of that.
That was my connection, of course, with this guy [indicates SynthAxe]. The
SynthAxe was the major connection between me and Atari. And Steinberg. ’Cause
they were the only people who wrote the software that would even record this
thing. So there they are, the old [indicates Atari, Cubase, and SynthAxe] and
the new [indicates modern Mac OS X DAW].&lt;/p>

&lt;/blockquote>

&lt;p>Holdsworth was known in the 80s and 90s for adopting new technology, such as
the &lt;a href="https://en.wikipedia.org/wiki/Yamaha_DX7">Yamaha DX-7
synthesizer&lt;/a> and the &lt;a
href="https://en.wikipedia.org/wiki/SynthAxe">SynthAxe MIDI controller&lt;/a>:&lt;/p>

&lt;blockquote>

&lt;p>When originally produced, the SynthAxe was priced at £10,000 (approximately
$13,000) and eventually sold for about $8,000.00. It was such a sophisticated
and expensive piece of machinery that few were sold making it difficult to keep
the company afloat. Eventually Virgin Games took over the distribution but let
it go after a couple of years.&lt;/p>

&lt;p>The SynthAxe is no longer produced and it is very difficult to locate used
units (fewer than 100 were made). Most musicians who desire a MIDI guitar
controller often use other alternatives, such as Roland or Axon systems that can
convert a guitar’s output to MIDI via 13-pin cables and outboard devices or
older systems such as the Roland GR-300.&lt;/p>

&lt;/blockquote>

&lt;p>I got interested in the Atari ST, and found some interesting clips about it
and Cubase. Here it is in action as a MIDI sequencer:&lt;/p>

&lt;iframe width="560" height="315"
src="https://www.youtube.com/embed/OlspnqVcJho?list=RDOlspnqVcJho"
frameborder="0" allowfullscreen loading="lazy">&lt;/iframe>

&lt;p>And here’s a vintage difference engine boffin discussing the ST’s history as
a simple, powerful, beautiful, and musical machine:&lt;/p>

&lt;iframe width="560" height="315" src="https://www.youtube.com/embed/O4kf1Wbaruo"
frameborder="0" allowfullscreen loading="lazy">&lt;/iframe>

&lt;blockquote>6:30: “One of the things I really liked about this machine [...] is
that, these machines were complex enough that you could use them [in] a way we
use machines now; I had word processors, desktop publishers, and so on, and [I]
used them for all sorts of things [...] But, they were still simple enough that
one person could understand, not just the software and how to write programs,
but actually how the hardware would work.”&lt;/blockquote>

&lt;p>By contrast, the regular electric guitar is extremely simple 1930s – 1940s
technology. &lt;a
href="http://www.openculture.com/2012/04/making_fender_guitars_then_1959_and_now_2012.html">Here
are 2 videos showing how guitars were were made in 1959 and then again in
2012&lt;/a>. Basically, nothing changed except for quantity. Like a violin, a
guitar is forever. Short of total physical destruction, a guitar will keep
playing well, and knowledge of how to repair it is easy to discover (even if
repairs still require skill to perform well).&lt;/p>

&lt;p>Violins and guitars are inherently open source — you can just look at them to
see how they work. You’ll need to read 1 book about woodworking and 1 book about
introductory electronics to get the basic idea. (Building them well is a
lifetime’s work, of course.) When they fail, full repair is usually possible. I
have a 53-year old Fender Musicmaster that still plays perfectly and sounds as
beautiful as it did on the day it left the factory. The frets have physically
worn down over the decades, but that is entirely fixable.&lt;/p>

&lt;p>Even extreme repairs are amazingly possible:&lt;/p>

&lt;iframe width="560" height="315" src="https://www.youtube.com/embed/w86n1oGPPqI"
frameborder="0" allowfullscreen loading="lazy">&lt;/iframe>

&lt;p>Erlewine makes it look easy because he’s an experienced professional. And it
is easy to understand, but very hard to do.&lt;/p>

&lt;p>But what about Holdsworth’s SynthAxe, Atari, and Cubase, with software and
saved music stored on unreliable floppy disks? As with Erlewine’s heroic
woodworking, dedicated engineers labor to restore ancient computers. The &lt;a
href="http://www.mame.net/">Multiple Arcade Machine Emulator project&lt;/a> is an
example of that. It’s beautiful work; &lt;a
href="https://medium.com/@fogleman/i-made-an-nes-emulator-here-s-what-i-learned-about-the-original-nintendo-2e078c9b28fe">here’s
another fun story&lt;/a>.&lt;/p>

&lt;p>Crucially, though, the Atari and the arcade machines are gloriously simple
computers, compared to what we have today. And Cubase 3 is a gloriously simple
program, compared to what we have today. If the last Cubase floppy in existence
were to experience an unrecoverable sector error, a genius software
archaeologist could likely restore it (since a floppy sector is only 512
bytes). But more damage could prove fatal, and Holdsworth’s masterful SynthAxe
playing could never be replicated on ‘period instruments’. Yet people still rock
the krumhorn, no problem:&lt;/p>

&lt;iframe width="560" height="315" src="https://www.youtube.com/embed/2bYh0Mq9TOc"
frameborder="0" allowfullscreen loading="lazy">&lt;/iframe>

&lt;p>But what about more complicated hardware and software? What about proprietary
data formats and interfaces, and the threat of lawsuits?&lt;/p>

&lt;p>I’m anxious entrusting something as important as art to a computer system.
Notoriously complex, and notoriously closed. (And often shipped on absurd
schedules.) Before computers are really reliable enough for anything important,
we need to get them fully opened and decomplexified. I’m very excited about &lt;a
href="http://riscv.org/">the RISC-V project&lt;/a>, which aims to do just that.&lt;/p></description><author>Chris Palmer</author><guid>2015/08/31/technology-longevity-art/index.html</guid><pubDate>Mon, 31 Aug 2015 00:00:00 +0000</pubDate></item><item><title>About Public Key Pinning</title><link>https://noncombatant.org/2015/05/01/about-http-public-key-pinning/index.content</link><description>&lt;h1>About Public Key Pinning&lt;/h1>

&lt;p>&lt;time>1 May 2015&lt;/time>&lt;/p>

&lt;div id="toc">&lt;/div>

&lt;aside>&lt;p>postd.cc has posted &lt;a
href="http://postd.cc/about-public-key-pinning/">a Japanese translation of this
article&lt;/a>.&lt;/p>&lt;/aside>

&lt;aside>&lt;p>My colleague Emily Stark has posted &lt;a
href="https://developers.google.com/web/updates/2015/09/HPKP-reporting-with-chrome-46">an
introduction to HPKP reporting&lt;/a> that you might also find useful.&lt;/p>&lt;/aside>

&lt;aside>&lt;p>Scott Helme has developed &lt;a
href="https://scotthelme.co.uk/hpkp-toolset/">a set of tools to make deploying
HPKP a bit easier&lt;/a>. He also runs &lt;a
href="https://report-uri.io/">report-uri.io&lt;/a>, a service endpoint for
collecting HPKP and CSP reports.&lt;/p>&lt;/aside>

&lt;h2>Introduction&lt;/h2>

&lt;p>At long last, the Internet Engineering Task Force (IETF) has published &lt;a
href="https://tools.ietf.org/html/rfc7469">RFC 7469, Public Key Pinning
Extension for HTTP&lt;/a> (HPKP). Thanks to my colleagues Ryan Sleevi, Adam
Langley, and Chris Evans for coming up with the idea; and thanks to Ryan and
Chris E. for helping me write the many drafts that preceded the final RFC.
Thanks also to the many IETF participants who commented on the drafts and helped
shepherd the document through to RFC status.&lt;/p>

&lt;h2>What Is Pinning, And What Does It Solve?&lt;/h2>

&lt;p>HPKP is an attempt to solve 1 of the big problems in the &lt;a
href="https://datatracker.ietf.org/wg/wpkops/charter/">Web PKI&lt;/a>: the fact
that essentially any certification authority (CA) or intermediate issuer can
issue end-entity (EE, or “leaf”) certificates for essentially any web site. For
example, even though the certificate for mail.google.com is issued by “Google
Internet Authority G2”, which in turn is issued by the root CA “GeoTrust Global
CA”, &lt;a href="https://en.wikipedia.org/wiki/DigiNotar">an obscure Dutch CA can
also try to issue certificates for mail.google.com&lt;/a>. So, we’d really like
some way to stop clients from having to trust such &lt;em>misissued&lt;/em>
certificates.&lt;/p>

&lt;figure>&lt;img src="certificate-viewer-mail.png" alt="The Chrome Certificate
Viewer showing the mail.google.com issuance chain." width="227" height="279"
loading="lazy"/>&lt;figcaption>The Chrome Certificate Viewer showing the
mail.google.com issuance chain.&lt;/figcaption>&lt;/figure>

&lt;p>Often, people propose to solve this problem by partitioning the web: either
they would like to configure their clients to trust only CAs from their own
nation; or they would like for CAs of nation &lt;var>X&lt;/var> to be banned from
issuing certificates for organizations from nations &lt;var>Y&lt;/var> and
&lt;var>Z&lt;/var>; or both. There are a couple problems with this. Crucially, the Web
is World-Wide by nature and its many great benefits flow directly from that.
Additionally, it is not always clear what nation a given organization is really
‘from’, and hence it is not always clear what CA ‘should’ have issued the
organization’s certificates.&lt;/p>

&lt;p>There can be no perfect set of ‘golden roots’ — you cannot construct a
minimal set of issuing certificates whose operators are more certain than some
other set not to mis-issue (whether on purpose or by accident). If you partition
the web, you reduce its value without actually reducing the threat of
mis-issuance. So we need something else.&lt;/p>

&lt;p>HPKP is 1 way to do that. HPKP enables a web server to tell clients (like
browsers) to expect the server to always present, in its X.509 certificate
chain, at least 1 of a set of public keys; and otherwise to to reject the
certificate chain. Thus, a web site operator can effectively reduce the set of
issuers that can issue for their site, without partitioning the web.&lt;/p>

&lt;h2>How Does Pinning Work?&lt;/h2>

&lt;p>To understand key pinning, first consider the classic simple case: SSH host
key management. When you first connect to an SSH server with a client that has
no previous knowledge of the server, you see this:&lt;/p>

&lt;pre>
chris@goatbeast:~ $ &lt;strong>ssh freebsd&lt;/strong>
The authenticity of host 'freebsd (10.0.0.4)' can't be established.
ECDSA key fingerprint is b0:79:74:0f:58:20:80:fd:c7:47:33:d6:9c:40:df:20.
Are you sure you want to continue connecting (yes/no)? 
&lt;/pre>

&lt;p>My server, freebsd, is presenting its public key to the SSH client to prove
its identity. The problem is, my client has no knowledge of that
(&lt;var>server-name&lt;/var>, &lt;var>public-key&lt;/var>) pair. So it asks me to resolve
the confusion. I am supposed to perform some out-of-band check that the key
fingerprint is correct, and say Yes or No.&lt;/p>

&lt;p>Assuming I say Yes, my client will henceforth expect this server to present
that key &lt;em>and only that key&lt;/em>. If my server ever presents a different key
— whether due to legitimate key rotation or an actual network attack — my client
will refuse to connect, and print a message like this:&lt;/p>

&lt;pre>
No ECDSA host key is known for freebsd and you have requested strict checking.
Host key verification failed.
&lt;/pre>

&lt;p>The reason this works for SSH is that almost everyone who uses SSH is an
expert user: a systems administrator, devops engineer, or software engineer.
They understand the error message, know what to do in case of key verification
failure, and can act on it. The community of people who use any given server is
small. They can simply talk to each other: “Hey, did you rotate the keys for the
server?”&lt;/p>

&lt;p>But on the world-wide web, that won’t fly. Key rotation is common, we need a
friction-free introduction for that first connection, and the people using
browsers have no special knowledge of cryptographic authentication. Therefore,
we must still rely on CAs to provide the introductions, and we still use chains
of certificates to give us flexible continuity for our web servers’
cryptographic identities. And rather than pinning a &lt;em>single&lt;/em> end-entity
key, as in SSH, we can pin a &lt;em>set&lt;/em> of keys — potentially at several
places in the certificate chain. As we’ll see below, this can greatly increase
reliability.&lt;/p>

&lt;p>&lt;a href="https://tools.ietf.org/html/rfc7469#section-2.6">HPKP Pin
Validation&lt;/a> is essentially &lt;em>set intersection&lt;/em>: given the set of public
keys in the signed certificate chain, are &lt;em>any&lt;/em> of them the same as any
of the keys the server has asserted (“pinned”) as known-good? If so, Pin
Validation succeeds; if not, the client should behave like an SSH client: drop
the invalid connection. In Chrome, that looks like this:&lt;/p>

&lt;figure>&lt;img src="pin-validation-failure.png" alt="A screenshot of Chrome
rejecting an invalid pin set." width="421" height="328"
loading="lazy"/>&lt;figcaption>Chrome rejecting an invalid pin
set.&lt;/figcaption>&lt;/figure>

&lt;h2>How Do I Configure HPKP For My Site?&lt;/h2>

&lt;blockquote>&lt;strong>WARNING:&lt;/strong> Public key pinning for web sites can be
very dangerous. If you make a mistake, you might cause clients to pin a set of
keys that validates today but which stops validating a week or a year from now,
if something changes. In that case, you’ll end up denying service to your own
site! People won’t be able to connect. (We call this “bricking your site”.)
Unless you are very confident that you understand the Web PKI, and unless you
are very confident that you can manage your site’s cryptographic identity very
well, you should not use key pinning. Stick to regular, un-pinned Web PKI until
you get more confident.&lt;/blockquote>

&lt;p>There are several steps you have to take to pin 1 or more of the public keys
in your site’s certificate chain(s):&lt;/p>

&lt;ol>

&lt;li>Figure out your site’s certificate chain(s) &lt;em>as served&lt;/em> and &lt;em>as
validated by clients&lt;/em>&lt;/li>

&lt;li>Decide where in the chain(s) you’d like to pin&lt;/li>

&lt;li>Set up 1 or more backup pins&lt;/li>

&lt;li>Configure your (test) server to issue a short-lived HPKP header and test it
out&lt;/li>

&lt;li>Gradually increase the lifetime of the pin set as you get more comfortable
with it&lt;/li>

&lt;/ol>

&lt;p>In the following sections I’ll describe how to do each step.&lt;/p>

&lt;h3>Determine Your Site’s Certificate Chain(s)&lt;/h3>

&lt;p>As we saw in the Certificate Viewer screenshot, a site’s certificate is at
the end of a chain of (usually) at least 3 certificates: the &lt;em>root
certificate&lt;/em> or &lt;em>trust anchor&lt;/em>, 1 or more &lt;em>intermediate issuer
certificates&lt;/em>, and finally the &lt;em>end-entity certificate&lt;/em>. Typically,
the web server must serve as part of its TLS handshake all of these certificates
except the root or trust anchor — the client maintains a set of trust anchors
and finds 1 that signed the top-most intermediate. In certain cases, a server
can serve only its EE and the clients will discover the intermediate issuers,
but this often leads to trouble. Generally, expect to have to serve a chain
containing the intermediate issuer(s).&lt;/p>

&lt;p>However, be aware that the chain you serve is not necessarily the chain that
clients will (re)build when validating the chain! This is due to
&lt;em>cross-signing&lt;/em>, and the generally &lt;a
href="http://tools.ietf.org/html/rfc5280#section-6">surprisingly complicated way
in which clients build and validate certificate chains&lt;/a>. You can partially
control this by ensuring that you serve good chains with well-known intermediate
issuers that chain up to a single well-known trust anchor. Even so, you must
test with a variety of clients to make sure you know what chains clients will
really build and validate.&lt;/p>

&lt;p>Crucially, clients perform Pin Validation on the chain they build during
chain validation, which is not necessarily the same as the chain you serve. So,
unfortunately, you can’t always simply pin the keys in the chain you serve and
be certain that Pin Validation will succeed. (Although see the next section for
ways to get better coverage.)&lt;/p>

&lt;p>Some sites use a distinct EE certificate for each distinct server in a
cluster. Perhaps each EE is issued by the same issuers, but perhaps not. If not,
your situation is likely very complex and key pinning might not work for you.
(Or, it may only work with a very large pin set.)&lt;/p>

&lt;h3>Decide What Keys To Pin&lt;/h3>

&lt;p>Now that you have a grip on what certificate chain(s) clients will build and
validate, it’s time to decide where in that chain to pin. For the sake of
discussion, I’ll assume a simple server deployment model:&lt;/p>

&lt;ul>

&lt;li>the organization has 2 data centers, each hosting a cluster of web servers
&lt;/li>

&lt;li>the organization obtains 1 EE certificate for 1 cluster, and another EE
certificate for the other cluster&lt;/li>

&lt;li>the organization has the same CA issue both EEs&lt;/li>

&lt;li>the CA issues through 1 intermediary&lt;/li>

&lt;/ul>

&lt;p>Thus, we have 2 certificate chains in production: CA → intermediary → EE1,
and CA → intermediary → EE2. The servers in the 2 clusters are configured,
correctly, to serve the chains intermediary → EE1 (for data center 1) and
intermediary → EE2 (for DC 2).&lt;/p>

&lt;p>Let’s further assume for simplicity that clients do indeed build a path
through the intermediary to the same CA certificate as we expect. (Again, in
reality, you &lt;em>cannot simply assume this&lt;/em>.)&lt;/p>

&lt;p>We can choose to pin the keys of any of the 4 certificates: CA, intermediary,
EE1, and EE2. The implications of pinning at different levels vary:&lt;/p>

&lt;dl>

&lt;dt>Pinning at the EE(s).&lt;/dt> &lt;dd>This gives the site operator a security
guarantee as strong as SSH: any misissuance will cause clients to reject the
misissued chain. The downside is that the server operator ties themselves to
those specific EE public keys — simply getting a new EE issued by the same
issuer(s) will not work (although see below about backup pins).&lt;/dd>

&lt;dt>Pinning at the intermediary/ies.&lt;/dt> &lt;dd>This reduces the threat of
misissuance to only the pinned intermediary/ies — a significant improvement over
the status quo, but not strictly as strong as pinning to only the EEs. By the
same token, any new certificate issued for the site by those issuers will pass
Pin Validation.&lt;/dd>

&lt;dt>Pinning at the root(s).&lt;/dt> &lt;dd>This is similar to pinning to the
intermediary/ies. Often, the same organization controls the private keys of the
root and the intermediary/ies. If that is not the case, then this option becomes
different from pinning to intermediaries: the site operator now trusts more or
different private key holders not to misissue.&lt;/dd>

&lt;/dl>

&lt;p>By pinning at multiple levels in the certificate chain — e.g. the EEs and the
intermediaries, the EEs and the root, the intermediaries and the root, or at all
3 — the site operator can trade off trusting more issuers with greater ease of
avoiding bricking the site.&lt;/p>

&lt;h3>Generate A Backup Pin&lt;/h3>

&lt;p>The RFC mandates that hosts MUST provide a backup pin: A pin that is
&lt;em>not&lt;/em> present in the chain that the client validates. This is for your
own good: if you lose control of your private keys and need to re-key your site
and get new certificates, you don’t want your site to have any down time — and
certainly not to be bricked! Unless clients have already pinned your backup key,
your site would be bricked until the max-age timed out.&lt;/p>

&lt;p>In this example, I’ll use a backup EE certificate as a backup pin. (You
could, and likely should, also use an alternate intermediary or root issuer
certificate for your backup. Additionally, it is best to get your backup signed
by a valid issuer, &lt;em>before&lt;/em> disaster strikes, so that you really can put
it into production at a moment’s notice!)&lt;/p>

&lt;p>This script generates a new key and an associated certificate signing request
(CSR; which is what you would send to a CA for them to sign). This is a way to
generate a primary and/or backup EE key and CSR for your site. Again, the safest
thing to do is to actually get your backup key in a valid certificate issued by
a real issuer, so that you could put it into production immediately if
necessary.&lt;/p>

&lt;pre>
#!/bin/sh

openssl genrsa -out "$1".key 2048
openssl req -new -key "$1".key -out "$1".csr
&lt;/pre>

&lt;h3>Test The HPKP Header&lt;/h3>

&lt;p>This script makes a key pin: it reads in either an X.509 certificate (in PEM
format) or a certificate signing request (also in PEM format), extracts its
subject public key info (SPKI) section, hashes the SPKI with SHA-256, and then
base 64-encodes that:&lt;/p>

&lt;pre>
#!/bin/sh

type="x509"
case "$1" in
 x509)
 type="x509"
 ;;
 req)
 type="req"
 ;;
 *)
 echo "Usage: $0 x509 certificate-pathname"
 echo " $0 req certificate-signing-request-pathname"
 exit 1
esac

openssl $type -noout -in "$2" -pubkey | \
 openssl asn1parse -noout -inform pem -out public.key
openssl dgst -sha256 -binary public.key | openssl enc -base64
&lt;/pre>

&lt;p>The output of this script is what you will put in your PKP headers. For
example, this is an example Apache header directive that I am currently using
for nonfreesoftware.org (lines folded to fit):&lt;/p>

&lt;pre>
Header add Public-Key-Pins "max-age=500; includeSubDomains;
 pin-sha256=\"wBVXRiGdJMKG7vQhr9tZ9br9Md4l7cO69LF2a88Au/o=\";
 pin-sha256=\"fv1+PWVvrBGKldX8uRtODY3sDbBKlsJOa48mI9s+6Mk=\";
 pin-sha256=\"lT09gPUeQfbYrlxRtpsHrjDblj9Rpz+u7ajfCrg4qDM=\""
&lt;/pre>

&lt;p>I’ve pinned my end-entity, an issuer, and a backup key. I’ve set the max-age
for 500 seconds, so that I can’t brick the site for very long. And, of course,
I’ve pinned only an alternate name for the site, not the canonical name (which
is noncombatant.org).&lt;/p>

&lt;p>Finally, check to make sure that your client has read and understood the key
pins. In this screenshot, you can see that Chrome has recognized my
Public-Key-Pins header:&lt;/p>

&lt;figure>&lt;img src="hsts-internals.png" alt="A view of
chrome://net-internals/#hsts showing key pins for nonfreesoftware.org"
width="539" height="354"
loading="lazy"/>&lt;figcaption>chrome://net-internals/#hsts allows you to query the
state of Chrome’s HSTS and HPKP database.&lt;/figcaption>&lt;/figure>

&lt;aside>&lt;p>Update 08 Mar 2017: A previous version of this post used the word
‘Balkanize’ to mean ‘partition’. A nice reader took the time to email me to say
that the term is offensive to people from the Balkans — something that I admit I
had not realized or considered. I’ve switched to using the term ‘partition’
instead. I apologize for that! And thanks to the helpful reader.&lt;/p>&lt;/aside></description><author>Chris Palmer</author><guid>2015/05/01/about-http-public-key-pinning/index.html</guid><pubDate>Fri, 01 May 2015 00:00:00 +0000</pubDate></item><item><title>Tycho: Awake</title><link>https://noncombatant.org/2015/01/26/tycho-awake/index.content</link><description>&lt;h1>Tycho: &lt;em>Awake&lt;/em>&lt;/h1>

&lt;p>&lt;time>26 January 2015&lt;/time>&lt;/p>

&lt;p>Tycho plays beautiful rock instrumentals with guitar, bass, acoustic and
electronic drums, and keys, building dreamy echoes and drones. This record
is an instant favorite — I am immensely jealous, because this is the kind of
record I would love to have written and played on. The layers of simple
melody and light grooves relax me but keep my interest — it’s sweet, but not
boring.&lt;/p>

&lt;p>High points: “Awake”, “L”; but every track is gold.&lt;/p>

&lt;p>&lt;em>Guitars, bass, keys, and drums by &lt;a
href="https://en.wikipedia.org/wiki/Tycho_(musician)">Scott Hansen&lt;/a>;
guitars and bass by Zac Brown; live drums by Rory O’Connor; Produced by
Scott Hansen.&lt;/em>&lt;/p></description><author>Chris Palmer</author><guid>2015/01/26/tycho-awake/index.html</guid><pubDate>Mon, 26 Jan 2015 00:00:00 +0000</pubDate></item><item><title>Aphex Twin: Syro</title><link>https://noncombatant.org/2015/01/26/aphex-twin-syro/index.content</link><description>&lt;h1>Aphex Twin: &lt;em>Syro&lt;/em>&lt;/h1>

&lt;p>&lt;time>26 January 2015&lt;/time>&lt;/p>

&lt;p>Luscious, bubbly synths and rhythm machines, with wonderful moments of
the calculatedly off-kilter intonation that I associate with Adult.
Everything is warm and enveloping, and the music rewards careful, repeated
listening.&lt;/p>

&lt;p>The minimal cover art is a musicians’ lament: A listing of the 12 tracks
and their tempos in beats per minute, followed by a litany of hundreds of
marketing and travel expenses denominated in hundreds of thousandths of GBP
— underscoring their relative importance. An inner sleeve includes the
&lt;a href="https://en.wikipedia.org/wiki/Syro#Packaging">“disinfographic”
listing all the musical instruments&lt;/a>. I’m glad that my collection of
effects units is relatively tiny...&lt;/p>

&lt;p>High points: Every track is beautiful, but my favorite is “produk 29” for
its thump and warbly waves of melody.&lt;/p>

&lt;p>&lt;em>Written and produced by Richard D. James.&lt;/em>&lt;/p></description><author>Chris Palmer</author><guid>2015/01/26/aphex-twin-syro/index.html</guid><pubDate>Mon, 26 Jan 2015 00:00:00 +0000</pubDate></item><item><title>Thoughts On Platform Security Features</title><link>https://noncombatant.org/2015/01/02/platform-security-features/index.content</link><description>&lt;h1>Thoughts On Platform Security Features&lt;/h1>

&lt;p>&lt;time>2 January 2015&lt;/time>&lt;/p>

&lt;p>Here are some off-the-cuff thoughts on security features that are
available, and which I would like to see.&lt;/p>

&lt;p>We need a superset of a subset of the union of the security features of
“mobile” platforms and “desktop” platforms. Although these are not
clearly-defined terms, I’ll try to roughly characterize them by naming
examples. Desktop platforms as of 2015 include:&lt;/p>

&lt;ul>
&lt;li>Mac OS X&lt;/li>
&lt;li>Windows&lt;/li>
&lt;li>Desktop and server Linux and BSD distributions, e.g. FreeBSD,
Ubuntu&lt;/li>
&lt;/ul>

&lt;p>Mobile platforms include:&lt;/p>

&lt;ul>
&lt;li>Chrome OS&lt;/li>
&lt;li>iOS (Apple, not Cisco)&lt;/li>
&lt;li>Android&lt;/li>
&lt;/ul>

&lt;p>&lt;a href="https://www.webplatform.org/">The web platform&lt;/a> seems to straddle
the line in some ways.&lt;/p>

&lt;p>The key differentiators between the 2 classes of platform are security
features and userland APIs. (And the hardware they run on.) Obviously, I’ll
focus on security features, and touch on userland APIs only insofar as they
affect security.&lt;/p>

&lt;p>Here are the security features of mobile platforms that I think we need
in all platforms going forward:&lt;/p>

&lt;ul>

&lt;li>A 2-part principal: (user, source of code); the code source must be
cryptographically authenticated. For example, Android gives each package (or,
package signing key) its own Linux user ID, isolating it from other packages.
(&lt;a
href="https://source.android.com/devices/tech/security/overview/app-security.html">More
details&lt;/a>.) iOS puts each app in a sandbox and isolates its storage; again all
code is signed. The open web uses the &lt;a
href="https://tools.ietf.org/html/rfc6454">origin model&lt;/a>, with optional
cryptographic code authentication (HTTPS).&lt;/li>

&lt;li>Usable ways to share resources between 2-part principals (strongest on
Android; OK on iOS; rather ad hoc on the web). This is mostly a consequence
of the userland APIs that the platform makes available to applications;
Android is rich here.&lt;/li>

&lt;li>Tamper-evident storage, verified at least on boot (“secure boot”, e.g. &lt;a
href="https://code.google.com/p/cryptsetup/wiki/DMVerity">dm-verity&lt;/a>).&lt;/li>

&lt;li>Encrypted storage, preferably on by default, preferably
whole-device.&lt;/li>

&lt;li>The integrity checking and the encryption should both be backed by hardware,
e.g. a &lt;a
href="https://en.wikipedia.org/wiki/Trusted_Platform_Module">TPM&lt;/a>.&lt;/li>

&lt;li>Privilege reduction, a way for userland programs to reduce their own access
to the kernel. Chrome OS, Mac OS X, iOS, and someday soon Android, have such
mechanisms: &lt;a
href="https://www.kernel.org/doc/Documentation/prctl/seccomp_filter.txt">Seccomp-BPF&lt;/a>
and &lt;a
href="https://developer.apple.com/library/mac/documentation/Security/Conceptual/AppSandboxDesignGuide/AboutAppSandbox/AboutAppSandbox.html">Seatbelt&lt;/a>.&lt;/li>

&lt;/ul>

&lt;p>By contrast, there are security features desktop platforms have that
mobile platforms lack:&lt;/p>

&lt;ul>

&lt;li>Considerably greater owner control over the device — debuggers, root and
ring 0 access, et c. “Digital rights management” seems to have caught on more
strongly on mobile platforms. &lt;a
href="https://www.chromium.org/chromium-os/poking-around-your-chrome-os-device">Chrome
OS has a Developer Mode&lt;/a>; I wish more closed platforms would follow
suit.&lt;/li>

&lt;li>Memory and CPU powerful enough to rebut the (usually, but not always,
mistaken) arguments against using &lt;a
href="https://en.wikipedia.org/wiki/Type_safety">type-safe&lt;/a> or at least &lt;a
href="https://en.wikipedia.org/wiki/Memory_safety">memory-safe&lt;/a> code. Current
mobile devices are as powerful or moreso as desktop computers of a decade ago,
so we do technically have the horsepower to run e.g. Java, C#, F#, Haskell, et
c. in these devices. In fact, Android, iOS, and the web all make heavy use of
languages with expensive features like late binding, object orientation,
run-time type checking, interpreted non-native code, and so on. Yet it has
proven hard to actually use those expensive features for safety — people always
want to call into C/C++ code for “efficiency”, and then find out the hard way
how easy it is to write unsafe C/C++. Developers seem happy to traverse many
pointers to finally get to a callable method but are not happy to check the
bounds on arrays. Although unsafe code will always seem marginally faster than
safe code, at some point we have to draw the line: &lt;em>this&lt;/em> is fast enough,
&lt;em>that&lt;/em> is not safe enough.&lt;/li>

&lt;/ul>

&lt;p>Things we still need on both classes of platform, or which I’m not sure
we have yet:&lt;/p>

&lt;ul>

&lt;li>A &lt;a href="https://en.wikipedia.org/wiki/Secure_attention_key">secure
attention sequence&lt;/a>. iOS’ Home button might actually be one; I don’t know the
implementation. I am not certain if Control-Alt-Delete still is a SAS on Windows
— please email me if you know more. SAS is a simple and powerful idea but it
depends crucially on implementation details that are hard to keep robust as
products change over time.&lt;/li>

&lt;li>UI isolation: each application should only be able to “see” its own windows,
should be able to reliably know when they have the highest z-order, and should
be able to reliably know when input events are really coming from the user (via
the kernel). (See &lt;a
href="https://www.usenix.org/legacy/publications/library/proceedings/sec04/tech/full_papers/shapiro/shapiro.pdf">Design
Of The EROS Trusted Window System&lt;/a>.) Android almost has this, at least last
time I looked. Windows are accessible only through a capability, but as of
Honeycomb (?) there can be windows that overlap and the active application is
not necessarily the highest in z-order. I could be wrong about that. I also
don’t know the iOS implementation; it may provide some or all of this. (Please
email me if you know more!)&lt;/li>

&lt;li>A kernel with high (...or any) unit test coverage.&lt;/li>

&lt;li>Robust defense against malicious peripherals and I/O devices (e.g. &lt;a
href="http://arstechnica.com/security/2014/07/this-thumbdrive-hacks-computers-badusb-exploit-makes-devices-turn-evil/">“BadUSB”
exploit makes devices turn “evil”&lt;/a> and &lt;a
href="http://gizmodo.com/5832167/public-charging-kiosks-may-steal-your-data">Public
Charging Kiosks May Steal Your Data&lt;/a>). Device firmwares, kernel device
drivers, and filesystems must all be robust against malicious inputs, but
typically are not.&lt;/li>

&lt;li>Safe, sane firmware written to semi-modern standards of code quality,
including open source solutions. There is &lt;a
href="http://www.coreboot.org/">CoreBoot&lt;/a>, but as far as I know only &lt;a
href="https://www.chromium.org/chromium-os/developer-information-for-chrome-os-devices/custom-firmware">Chrome
OS uses it and successors&lt;/a>. Unfortunately I know nothing of iOS
firmware.&lt;/li>

&lt;li>Safe, sane baseband operating systems written to semi-modern standards of
code quality, including open source solutions. &lt;a
href="http://archive.hack.lu/2010/Weinmann-All-Your-Baseband-Are-Belong-To-Us-slides.pdf">All
your baseband are belong to Ralf-Philipp Weinmann&lt;/a> (&lt;a
href="https://www.youtube.com/watch?v=TzR7R6fBr00">video&lt;/a>).&lt;/li>

&lt;li>Error-recovering filesystems or block devices, such as with &lt;a
href="https://en.wikipedia.org/wiki/Erasure_code">erasure coding&lt;/a>. Due to
their wonderfully high capacities, &lt;a
href="http://www.storagenewsletter.com/rubriques/market-reportsresearch/why-raid-dead-for-big-storage-cleversafe/">modern
storage devices are highly likely to experience unrecoverable block errors&lt;/a>,
making it impossible to read back data previously stored.&lt;/li>

&lt;/ul>

&lt;p>I’m sure I’m forgetting something crucial, and that I got at least 1
thing wrong, and that you’ll let me know. :)&lt;/p></description><author>Chris Palmer</author><guid>2015/01/02/platform-security-features/index.html</guid><pubDate>Fri, 02 Jan 2015 00:00:00 +0000</pubDate></item><item><title>TLS All The Things: Security With Performance</title><link>https://noncombatant.org/2014/11/23/tls-all-the-things/index.content</link><description>&lt;h1>TLS All The Things: Security With Performance&lt;/h1>

&lt;p>&lt;time>23 November 2014&lt;/time>&lt;/p>

&lt;p>I gave a talk last Wednesday at the &lt;a
href="https://developer.chrome.com/devsummit/">Chrome Dev Summit&lt;/a> about how
TLS and HTTPS are not the big performance problem that people often think they
are. You can have security and performance, and in fact security
&lt;em>enables&lt;/em> the new, performant application protocol &lt;a
href="http://en.wikipedia.org/wiki/HTTP/2">HTTP/2&lt;/a>.&lt;/p>

&lt;p>It was fun, and was chuffed to find that many or even most people were on
board with the basic idea that they do in fact need to transport their apps over
HTTPS. At last?&lt;/p>

&lt;iframe width="560" height="315" src="//www.youtube.com/embed/ayD0LiZkWLQ"
frameborder="0" allowfullscreen loading="lazy">&lt;/iframe>

&lt;p>My safety-loving colleagues Adrienne Porter-Felt and Alex Russell also gave
excellent talks earlier in the morning. This YouTube video has them all.&lt;/p>

&lt;iframe width="560" height="315" src="//www.youtube.com/embed/0b9ZE1V4uRk"
frameborder="0" allowfullscreen loading="lazy">&lt;/iframe></description><author>Chris Palmer</author><guid>2014/11/23/tls-all-the-things/index.html</guid><pubDate>Sun, 23 Nov 2014 00:00:00 +0000</pubDate></item><item><title>Security As A Class Of Interface Guarantee</title><link>https://noncombatant.org/2014/08/10/security-as-a-class-of-interface-guarantee/index.content</link><description>&lt;h1>Security As A Class Of Interface Guarantee&lt;/h1>

&lt;p>&lt;time>10 August 2014&lt;/time>&lt;/p>

&lt;div id="toc">&lt;/div>

&lt;p>This post is an attempt to pin down my intuition that an “interface”, broadly
defined, can be a productive conceptual frame for a wide variety of security
problems and solutions. I can’t promise that this post makes total sense; it’s
just thinking out loud at this point.&lt;/p>

&lt;p>There are many ways to understand software security engineering. One
(all-too-)prevalent view is of security as a cat-and-mouse game: by hook or by
crook, any little thing you can do to attack or avoid being attacked counts as
“security engineering”. Especially for defenders, this view leads directly to
failure. It’s analogous to micro-optimizing a fragment of code (a) before
profiling it to see if it’s really a hot spot; (b) without testing to see if the
micro-optimizations help or hurt; and (c) without any quantified performance
target.&lt;/p>

&lt;p>For example, consider a web application firewall (WAF). People often buy
these to “secure” their web applications, saying things like, “Hey, even if the
web application is well-engineered, &lt;a
href="http://en.wiktionary.org/wiki/belt_and_suspenders">belt and suspenders,
right&lt;/a>?! Belt and suspenders!” But ask: How much does the WAF cost to buy?
How much does it cost to install, configure, and run? Who looks at its logs and
reports, and how much does that person’s time cost? (Don’t forget the
opportunity cost.)&lt;/p>

&lt;p>How does the WAF affect the application’s performance and reliability?
Possibly not well.&lt;/p>

&lt;p>How much attack surface does the WAF itself create and expose? Often, a WAF
can create significant new risk. I once found an XSS vulnerability in a web
application, and ran a demonstration exploit so I could document that it worked.
No big surprise there. After a while, a guy came up to me and said he was he WAF
operator for that app, and did these weird pop-ups he kept seeing have anything
to do with my security testing? I didn’t even know the app was (supposedly)
being protected by a WAF, but I had accidentally exploited both the app and the
WAF in one shot.&lt;/p>

&lt;p>A correct WAF configuration is equivalent to fixing the bug in the original
application. Why not just do that?&lt;/p>

&lt;p>I want to forget all about both belts and suspenders; instead, I want to buy
pants that actually fit.&lt;/p>

&lt;aside>A note on terminology: In this blog post, I’ll use the
term &lt;strong>interface&lt;/strong> to mean any of: user interface, programming
language syntax and semantics, in-process API, system call, RPC and network
protocol, or &lt;a href="https://eprint.iacr.org/2007/399.pdf">ceremony&lt;/a>. I’ll
use &lt;strong>guarantee&lt;/strong> to include design contracts with explicit
non-guarantees. I’ll use &lt;strong>caller&lt;/strong> to mean any of: human
programmer, human user, call-site in source code, or requesting network protocol
peer. A &lt;strong>callee&lt;/strong> is a person who receives a message (e.g. an
individual or the operator of a remote service), an API or library
implementation or other in-process called function, or an RPC or network
protocol respondent. An &lt;strong>interface definition&lt;/strong> is any
programmatic function signature (including identifiers and type annotations),
type semantics, visual &lt;a
href="http://en.wikipedia.org/wiki/Semiotic_engineering">semiotics&lt;/a> of a GUI
or &lt;a href="http://en.wikipedia.org/wiki/Command-line_interface">CLI&lt;/a>, et c.
that attempts to communicate the meaning and guarantees of the interface to
callers. The &lt;strong>primary interface definition&lt;/strong> is the immediately
accessible surface of the interface itself, e.g. a function or method
declaration, an IDL specification or other code generation/specification system
for network protocols, the grammar of a programming language, or a user-facing
GUI or CLI. A &lt;strong>secondary interface definition&lt;/strong> is supplementary
material; usually documentation, annotation, post-facto errata, entries in
issue trackers, commit log messages, et c.&lt;/aside>

&lt;h2>Security Is Part Of Every Interface&lt;/h2>

&lt;p>I prefer to think of security as a class of interface guarantee. In
particular, security guarantees are a kind of correctness guarantee. At every
interface of every kind — user interface, programming language syntax and
semantics, in-process APIs, kernel APIs, RPC and network protocols, ceremonies —
&lt;a href="http://en.wikipedia.org/wiki/Design_by_contract">explicit and implicit
design guarantees&lt;/a> (promises, contracts) are in place, and determine the
degree of “security” (however defined) the system can possibly achieve.&lt;/p>

&lt;p>Design guarantees might or might not actually hold in the implementation —
software tends to have bugs, after all. Callers and callees can sometimes (but
not always) defend themselves against untrustworthy callees and callers
(respectively) in various ways that depend on the circumstances and on the
nature of caller and callee. In this sense an interface is an &lt;a
href="http://en.wikipedia.org/wiki/Attack_surface">attack surface&lt;/a> — but
properly constructed, it can also be a &lt;strong>defense surface&lt;/strong>.&lt;/p>

&lt;p>Here are some example security guarantees in hypothetical and real
interfaces:&lt;/p>

&lt;ul>

&lt;li>&lt;p>The function &lt;code>bool isValidEmailAddress(String address, Set
knownTLDs)&lt;/code> returns true if the email address is syntactically valid for
SMTP addresses according to RFC 3696, and if the domain part is in a known
top-level domain.&lt;/p>&lt;/li>

&lt;li>&lt;p>All array accesses are checked at run time; an attempt to use an index
that is less than zero or greater than or equal to the length of the array
causes an &lt;code>ArrayIndexOutOfBoundsException&lt;/code> to be thrown. (From the &lt;a
href="http://docs.oracle.com/javase/specs/jls/se8/html/jls-10.html#jls-10.4">Java
Language Specification&lt;/a>.)&lt;/p>&lt;/li>

&lt;li>&lt;p>DNS queries and responses can be read, copied, deleted, altered, and
forged by an attacker on any network segment between client and server.&lt;/p>&lt;/li>

&lt;li>&lt;p>Within a single goroutine, the happens-before order is the order
expressed by the program. (From the &lt;a href="http://golang.org/ref/mem">Go
language documentation&lt;/a>.)&lt;/p>&lt;/li>

&lt;/ul>

&lt;h2>The Interface Perception Gap&lt;/h2>

&lt;p>The true technical security guarantee that an interface’s implementation
provides is not necessarily the same as the guarantee the caller perceives. I’ll
call this the &lt;strong>interface perception gap&lt;/strong>, for lack of a
less-awful term. The gap could exist for many reasons, including at least:&lt;/p>

&lt;ul>

&lt;li>&lt;p>the guarantee is implicit (i.e. not in the interface definition)&lt;/p>&lt;/li>

&lt;li>&lt;p>the guarantee is explicit, but the caller did not read or understand the
interface definition&lt;/p>

&lt;ul>

&lt;li>&lt;p>possibly because the interface definition is too complex for the caller
to understand&lt;/p>&lt;/li>

&lt;li>&lt;p>possibly because the guarantee is not in the caller’s mental model of the
interface or of the caller’s own requirements&lt;/p>&lt;/li>

&lt;/ul>
&lt;/li>

&lt;li>&lt;p>the interface misuses terms in its own definition&lt;/p>&lt;/li>

&lt;li>&lt;p>the interface definition is so poor that the caller must imagine their
own implicit definition&lt;/p>&lt;/li>

&lt;/ul>

&lt;p>Gaps in contracts tend, over time, to become implicit guarantees and
non-guarantees. It can be possible to assert new technical guarantees in the
gaps. Consider &lt;a
href="http://en.wikipedia.org/wiki/Address_space_layout_randomization">address
space layout randomization&lt;/a> (ASLR). The executable loaders of operating
systems never specified the precise location in memory of the program text,
heap, stack, libraries, et c. in memory; this freed up implementors to randomize
those locations to thwart exploit developers, cat-and-mouse style. When it was
invented, ASLR was a decent way to buy some time (a couple years at most) for
the authors of programs written in unsafe languages to fix their bugs or port to
safe languages. However, it was never going to be possible for ASLR to fully
solve the problems of unsafe languages, for many reasons, including at
least:&lt;/p>

&lt;ul>

&lt;li>&lt;p>ASLR was a new technical guarantee retrofitted into the interface
perception gap of pre-existing executable loaders that had to be &lt;em>compatible
with existing code&lt;/em>, and thus not all program components could be randomized
with a high degree of entropy.&lt;/p>

&lt;ul>

&lt;li>And ASLR is an all-or-nothing affair: If the attacker can reliably locate
&lt;em>any&lt;/em> executable code, they can almost certainly find gadgets useful for
exploitation there.&lt;/li>

&lt;/ul>
&lt;/li>

&lt;li>&lt;p>Programs generally must be recompiled with new options, or at least with
old options previously thought of as being exclusively for dynamically-loadable
library code — that is, there wasn’t &lt;em>enough&lt;/em> of a perception gap in the
toolchains’ interfaces! As a result, the guarantee of ASLR is still not
ubiquitous, more than a decade later.&lt;/p>&lt;/li>

&lt;li>&lt;p>Many program errors are still exploitable due to the limited granularity
of what program parts can be efficiently randomized — there is an implicit
guarantee of run-time efficiency that extreme ASLR could violate.&lt;/p>

&lt;ul>

&lt;li>Sometimes even coarse-grained ASLR violates certain extreme performance
requirements.&lt;/li>

&lt;/ul>
&lt;/li>

&lt;li>&lt;p>In applications that give attackers significant but not
directly malicious control over run-time behavior — for example, as any dynamic
programming environment like a web browser &lt;em>must&lt;/em> do — the &lt;a
href="https://www.blackhat.com/presentations/bh-europe-07/Sotirov/Presentation/bh-eu-07-sotirov-apr19.pdf">attacker
can significantly reduce the effective entropy of ASLR&lt;/a>, thus weakening the
already-weak guarantee.&lt;/p>&lt;/li>

&lt;li>&lt;p>Previously low-severity bugs, like single-word out-of-bounds read errors,
become information leaks that can undo all the benefits of ASLR and enable an
attacker to craft a reliable exploit. The implied ‘interface’ of an
out-of-bounds read primitive changes: while an OOB read should be guaranteed not
to happen, the ‘guarantee’ changes from “likely possible but mostly harmless” to
”there goes ASLR... now all those ROP exploits are back in scope.”
Oops.&lt;/p>&lt;/li>

&lt;/ul>

&lt;p>Perhaps because ASLR was not (to my knowledge) clearly documented as a
temporary cat-and-mouse game, engineers have come to rely on it as being the
thing that makes the continued use of unsafe languages acceptable. Unsafe (and
untyped) languages will always be guaranteed to be unsafe, and we should have
used the time ASLR bought us to aggressively replace our software with
equivalents implemented in safe languages. Instead, we linger in a zone of
ambiguity, taking the (slight) performance hit of ASLR yet not effectively
gaining much safety from it.&lt;/p>

&lt;p>Sometimes, interface perception gaps are surfaced, and the interface and
implementation change to close the gap. A classic example is the &lt;a
href="http://bugs.python.org/issue13703">denial-of-service problem in hash
tables&lt;/a>: If an attacker can influence or completely control the keys of the
pairs inserted into a hash table, they can cause the performance to degrade from
the (widely perceived — but usually explicitly disclaimed!) ~ &lt;em>O&lt;/em>(1)
performance guarantee for hash table lookup. Defenders can either explicitly
claim the performance guarantee by randomizing the hash function in a way the
attacker cannot predict, or (if they specified a more abstract interface) switch
to an implementation (such as a red-black tree) that does not suffer from the
problem.&lt;/p>

&lt;h2>The Importance Of Explicit Guarantees&lt;/h2>

&lt;p>The technical strength of a security mechanism is limited when it is not
backed by an explicit contract. Explicit, understandable, tested, and enforced
guarantees, which could reasonably fit into the caller’s mental model, are
best.&lt;/p>

&lt;p>A guarantee that is not also perceived by its callers is limited in
effectiveness. Consider an interface for a map data structure: If the
implementation is guaranteed to be a sorted tree, callers can trust that they
can iterate over the keys in sorted order without having to do any extra work.
But if they don’t understand that part of the interface definition, they might
mistakenly waste time and space by extracting all the keys into an array and
pointlessly re-sorting it. The problem is reversed if the interface is
explicitly defined to be (say) a hash table, but the caller does not realize
that.&lt;/p>

&lt;p>Similarly, a security guarantee that callers do not perceive — but which is
present — can cause callers to miscalculate their risk as being higher than it
is. While it might seem that is OK, because callers will “err on the side of
caution”, in fact the misperception can have an opportunity cost. (In a sense, a
self-denial-of-service.)&lt;/p>

&lt;p>A non-guarantee that is not perceived can also become dangerous. For example,
&lt;a
href="http://www.chromium.org/Home/chromium-security/security-faq#TOC-Why-aren-t-physically-local-attacks-in-Chrome-s-threat-model-">although
documentation explicitly disclaims it&lt;/a>, users often perceive that programs
can maintain (e.g.) confidentiality for the user’s data even when the underlying
platform is under the physical control of an attacker. Such an attacker’s
capabilities tend to be well outside the users’ mental models; and in any case,
documentation (a secondary interface definition) is a poor substitute for a
user-visible interface definition in the GUI (a primary definition).&lt;/p>

&lt;p>Interface misperceptions are sometimes widely or strongly held, and can
become implicit or even explicit guarantees, and can force brittleness or even
breakage into the interface. As an extreme example, consider the User Account
Control feature introduced in Windows Vista. After it was released, Microsoft
published a blog post (a secondary interface definition) and &lt;a
href="http://blogs.technet.com/b/markrussinovich/archive/2007/02/12/638372.aspx">tried
to roll back the expectations&lt;/a> that callers developed when reading the
primary definitions (the GUI and &lt;a
href="http://en.wikipedia.org/wiki/User_Account_Control#Requesting_elevation">aspects
of the API&lt;/a>):&lt;/p>

&lt;blockquote>It should be clear then, that neither UAC elevations nor Protected
Mode IE define new Windows security boundaries. Microsoft has been communicating
this but I want to make sure that the point is clearly heard. Further, as Jim
Allchin pointed out in his blog post Security Features vs Convenience, Vista
makes tradeoffs between security and convenience, and both UAC and Protected
Mode IE have design choices that required paths to be opened in the IL wall for
application compatibility and ease of use.&lt;/blockquote>

&lt;p>Perhaps the core problem with UAC, Integrity Levels, and User Interface
Privilege Isolation is that one interface, the security principal (in Windows,
represented by the &lt;a
href="http://msdn.microsoft.com/en-us/library/Aa374909.aspx">access token&lt;/a>),
is too hard to compose with another interface: the traditional
multi-process/single principal windowing environment for presenting user
interfaces. Modern platforms require a &lt;a
href="http://www.chromium.org/Home/chromium-security/prefer-secure-origins-for-powerful-new-features">2-part
security principal&lt;/a> (see the Background section in that document), composable
with a user interface paradigm that allows users to distinguish the many
cooperating principals. (Consider the &lt;a
href="https://www.usenix.org/legacy/event/sec04/tech/full_papers/shapiro/shapiro.pdf">EROS
Trusted Windowing System&lt;/a> as an example alternative.)&lt;/p>

&lt;h2>Don’t Imagine Interfaces Or Guarantees&lt;/h2>

&lt;p>At the beginning of this blog post, I poked a little fun at WAFs. Making fun
of WAFs is traditional picnic banter in my tribe (application security
engineers), so I feel it is only fair to put a little sacred cow hamburger on
the grill, too. Here are 2 examples.&lt;/p>

&lt;p>&lt;a
href="http://rdist.root.org/2010/01/07/timing-independent-array-comparison/">Constant-time
array comparison&lt;/a> to defeat &lt;a
href="http://en.wikipedia.org/wiki/Timing_attack">timing side-channel
attacks&lt;/a>. Consider for example the HMAC defense against CSRF: &lt;code>token =
HMAC_SHA256(secret_key, session_token + action_name)&lt;/code>. It should be
computationally infeasible for the attacker to ever guess or learn the token
value, but a timing side-channel, such as that introduced by a naïve byte array
comparison allows the attacker to guess the token in a feasible amount of time
and attempts (proportional to N = number of bits in token). A canonical solution
is to use an array comparison function that always takes the same amount of
time, rather than returning as soon as it finds a mismatch.&lt;/p>

&lt;p>The trouble with this is that, apart from the code being slightly subtle,
there is no interface guaranteeing that the code will indeed take the same
amount of time on all inputs. Several things are permissible, given the
documented interfaces between the programmer and the ultimate execution
context:&lt;/p>

&lt;ul>

&lt;li>&lt;p>the compiler might find a way to optimize the function;&lt;/p>&lt;/li>

&lt;li>&lt;p>the CPU’s &lt;code>XOR&lt;/code> instruction might not take the same amount of
time to compute all inputs; or&lt;/p>&lt;/li>

&lt;li>&lt;p>the machine (real, or virtual!) might even transform and optimize the
code before running it.&lt;/p>

&lt;ul>

&lt;li>For example, some processor cores accept code from one instruction set as
input, but transform it to another instruction set before running it in the
processor core.&lt;/li>

&lt;/ul>
&lt;/li>

&lt;/ul>

&lt;p>Does the expected timing guarantee still hold, given these interfaces and
their non-guarantee? As Lawson says, the solution is fragile and you have to
test it every time the execution environment changes.&lt;/p>

&lt;p>An additional, essentially fatal problem is that many real-world applications
are implemented in very high-level languages like Python and Java, where there
are even more layers of abstraction and therefore even less of a constant-time
interface guarantee.&lt;/p>

&lt;p>An alternative solution, which I learned from Brad Hill, is to forget about
trying to run in constant time, and instead to &lt;a
href="https://www.isecpartners.com/blog/2011/february/double-hmac-verification.aspx">blind
the attacker by making what timing information they learn useless&lt;/a>. Rather
than directly comparing the timing-sensitive tokens (say, SAML blob signatures
or CSRF tokens), HMAC the received blob and the expected blob again (with a new,
separate HMAC key), and then compare those HMAC outputs (with any comparison
function you want, even &lt;code>memcmp&lt;/code>). The attacker may indeed observe a
timing side-channel — but the timing information will be random relative to the
input. This is due to the straightforward, documented, and tested interface
guarantee of the HMAC function as a pseudo-random function. And it works as
expected in &lt;em>any&lt;/em> language, on any computing substrate.&lt;/p>

&lt;p>Consider another cryptography-related security conundrum: the supposed need
to clear secrets from RAM when the secrets are no longer needed, or even to
encrypt the RAM (presumably decrypting it in registers?). This is supposed to
ensure that live process RAM never hits the disk (as in e.g. swap space), nor is
available to an attacker who can read the contents of RAM. The usual threat
scenario invoked to warrant this type of defense is that of a physically-local
forensic attacker, usually of relatively high capability (e.g. capable of
performing a &lt;a href="http://en.wikipedia.org/wiki/Cold_boot_attack">cold boot
attack&lt;/a> or a live memory dump). The goal is to not reveal secrets (e.g. Top
Secret documents, passwords, encryption keys, et c.) to such an attacker.&lt;/p>

&lt;p>The trouble with this goal is that there can be no interface guarantee that
clearing memory in one area will fully erase all copies of the data. The virtual
memory managers of modern operating systems, and the dynamic heap allocators of
modern language run-times, in fact guarantee very little in the way of memory
layout or deterministic behavior. Instead they provide guarantees of
more-or-less high performance, which additional security guarantees could
complicate or render infeasible.&lt;/p>

&lt;ul>

&lt;li>&lt;p>If you &lt;a
href="http://linux.die.net/man/3/realloc">&lt;code>realloc&lt;/code>&lt;/a> memory, the
userland run-time or the kernel might make a copy that you can no longer
reliably reference (so you can’t reliably clear it).&lt;/p>&lt;/li>

&lt;li>&lt;p>When you free memory, the kernel might not zero the pages out until the
last second before giving them to the next requestor. Thus, the time window in
which they are prone to discovery by the forensic attacker increases.&lt;/p>&lt;/li>

&lt;li>&lt;p>Kernel APIs like &lt;a
href="https://developer.apple.com/library/mac/documentation/Darwin/Reference/ManPages/man2/mlock.2.html">&lt;code>mlock&lt;/code>&lt;/a>,
which purport to lock memory into physical RAM pages (stopping the pages from
being swapped out to disk), do not necessarily work the way you expect, or even
at all.&lt;/p>&lt;/li>

&lt;li>&lt;p>In a garbage-collected run-time, essentially any amount of copying,
moving, and reallocating is possible. There can be no guarantee that a piece of
data is stored in exactly 1 location in RAM, and that you can clear it.&lt;/p>&lt;/li>

&lt;li>&lt;p>The same holds for virtual machines, of course.&lt;/p>&lt;/li>

&lt;/ul>

&lt;p>Essentially, there can be no guarantee that a high-capability forensic
attacker cannot find secrets in RAM or swapped-out process memory; the more
complex the operating system and run-time, the less likely it is that you can
even probabilistically defeat such an attacker.&lt;/p>

&lt;p>The most you can realistically do in the general case is mitigate the
problems with full disk encryption and whatever degree of physical security you
can get. In specific cases, such as cryptographic keys, you can keep the keys in
a tamper-resistant, tamper-evident &lt;a
href="http://en.wikipedia.org/wiki/Hardware_security_module">hardware security
module&lt;/a>.&lt;/p>

&lt;h2>“Conclusion”&lt;/h2>

&lt;p>This post is partly an attempt to investigate why the “security vs.
convenience” dichotomy is false. I think it’s worse than a false dichotomy,
really; it’s a fundamental misconception of what security is and of what an
interface is — and of what ‘convenience’ (an impoverished view of usability)
is.&lt;/p>

&lt;p>But also it’s an attempt to re-frame security engineering in a way that
allows us to imagine more and better solutions to security problems. For
example, when you frame your interface as an attack surface, you find yourself
ever-so-slightly in a panic mode, and focus on how to make the surface as small
as possible. Inevitably, this tends to lead to cat-and-mouseism and poor
usability, seeming to reinforce the false dichotomy. If the panic is acute, it
can even lead to nonsensical and undefendable interfaces, and a proliferation of
false boundaries (as we saw with Windows UAC).&lt;/p>

&lt;p>If instead we frame an interface as a defense surface, we are in a mindset
that allows us to treat the interface as a shield: built for defense,
&lt;em>testable&lt;/em>, &lt;em>tested&lt;/em>, covering the body; but also light-weight
enough to carry and use effectively. It might seem like a semantic game; but in
my experience, thinking of a boundary as a place to build a point of strength
rather than thinking of it as something that must inevitably fall to attack
leads to solutions that in fact withstand attack better while also functioning
better for friendly callers.&lt;/p>

&lt;p>The safest interface is still no interface — don’t multiply interfaces
unnecessarily. But when you must expose something, expose a well-tested shield
rather than merely trying to narrow your profile or hide behind a tree.&lt;/p>

&lt;h2>And Now, Your Moment Of Zen&lt;/h2>

&lt;p>&lt;a
href="https://twitter.com/rootkovska/status/498227129969295360">https://twitter.com/rootkovska/status/498227129969295360&lt;/a>&lt;/p></description><author>Chris Palmer</author><guid>2014/08/10/security-as-a-class-of-interface-guarantee/index.html</guid><pubDate>Sun, 10 Aug 2014 00:00:00 +0000</pubDate></item><item><title>Aftermaths by Kodacrome</title><link>https://noncombatant.org/2014/07/31/aftermaths-by-kodacrome/index.content</link><description>&lt;h1>&lt;em>Aftermaths&lt;/em> by Kodacrome&lt;/h1>

&lt;p>&lt;time>31 July 2014&lt;/time>&lt;/p>

&lt;p>I’ve been longing for a full-length release from Kodacrome ever since their
too-short &lt;em>Perla&lt;/em> EP. The combination of Elissa’s cool and collected
vocals with her and Ryan’s clean and warm production is
golden. &lt;em>Aftermaths&lt;/em> is understated, moody, chill, electronic pop with
just enough surprising head-turns. The record is minimal yet full-sounding; the
minimalism serves to clarify the musical ideas and showcase the excellent
production, rather than being an affectation to hide behind.&lt;/p>

&lt;p>I haven’t listened to the digital release yet, but the vinyl version really
rewards high volume. The record is so spare, but you find yourself swimming in
it. Awesome.&lt;/p>

&lt;p>Every song in &lt;em>Aftermaths&lt;/em> is a solid hit, but for me particular high
points are the spooky “Buggy Bumper”, the beautiful vocal melody in “Strike The
Gold”, the harmony lesson in “Panama”, and the dramatic sound design in
“Solitary And Elect”. The wonderful video singles are &lt;a
href="https://www.youtube.com/watch?v=N2wxlUO8aIk">“Immaculada”&lt;/a> and &lt;a
href="https://www.youtube.com/watch?v=YZc4mQ7tsbY&amp;amp;list=UUXq8B6MW6wcjQrKY5P4h45w">“Strike
The Gold”&lt;/a>.&lt;/p>

&lt;p>Buy &lt;a href="https://kodacrome.bandcamp.com/">everything by Kodacrome on
Bandcamp&lt;/a>, and &lt;a
href="https://www.youtube.com/channel/UCXq8B6MW6wcjQrKY5P4h45w">enjoy their
YouTube channel&lt;/a>!&lt;/p></description><author>Chris Palmer</author><guid>2014/07/31/aftermaths-by-kodacrome/index.html</guid><pubDate>Thu, 31 Jul 2014 00:00:00 +0000</pubDate></item><item><title>Privacy And Security Settings in Chrome</title><link>https://noncombatant.org/2014/03/11/privacy-and-security-settings-in-chrome/index.content</link><description>&lt;h1>Privacy And Security Settings in Chrome&lt;/h1>

&lt;p>&lt;time>11 March 2014&lt;/time>&lt;/p>

&lt;aside>

&lt;p>Update 29 October 2015: My colleague Mike West packaged up these settings as
a &lt;a
href="https://chrome.google.com/webstore/detail/palmerized-chrome/ecmhflkoahhjjpddfopclbhiogelneoc">Chrome
extension&lt;/a>. So, now you can just install that rather than noodling through
all these settings.&lt;/p>

&lt;p>Also, be aware that Chrome’s Settings UX has changed a bit since I wrote
this.&lt;/p>

&lt;/aside>

&lt;p>&lt;a href="https://www.google.com/intl/en/chrome/browser/">Chrome&lt;/a> has a lot
of handy privacy and security options, but it isn’t always obvious how to use
them. In this post I’ll demonstrate my favorites, and try to explain a bit about
what they do.&lt;/p>

&lt;p>My goal with these configuration changes is to get Chrome to expose less
attack surface to potentially malicious web pages, and to be less chatty on the
network. I definitely can’t and don’t guarantee that they will work for you or
solve any particular problem you have. But maybe you’ll find this to be a fun
learning experience. (Also, although I work for Google on the Chrome Security
team, I am not blogging in any official capacity, and I don’t have an omniscient
view of Chrome security.)&lt;/p>

&lt;p>Chrome has a feature that allows you to create multiple “profiles”, each with
their own distinct settings. Because we want to change the settings in a way
that will make some web sites work less well (or even not at all), we won’t want
to be locked in that mode. Therefore, we need to create a new, distinct profile
to use as the private/secure mode. That way, you can always go back to a regular
profile easily, to get normal web functionality.&lt;/p>

&lt;p>First, create a new profile:&lt;/p>

&lt;figure>&lt;img loading="lazy" alt="Create a new profile."
src="01-create-new-profile.png" width="746" height="610"/>&lt;figcaption>Create a
new profile.&lt;/figcaption>&lt;/figure>

&lt;p>After creating the new profile, you get a new window running that profile
(note the cat icon in the upper right corner):&lt;/p>

&lt;figure>&lt;img loading="lazy" alt="After creating a new profile." width="747"
height="612" src="02-after-profile-creation.png"/>&lt;figcaption>After creating a
new profile.&lt;/figcaption>&lt;/figure>

&lt;p>In this privacy- and security-sensitive special profile, do not sign in to
Chrome. Signing in to Chrome, also known as Chrome Sync, is a convenient feature
that syncs all your settings across all your signed-in Chrome profiles on all
your devices, and makes it easier to log in to Google services. You might like
it in your regular mode profile, but we want this profile be more loosely
coupled to the cloud.&lt;/p>

&lt;p>Go to the &lt;strong>Settings&lt;/strong> page &lt;em>in the new profile’s
window&lt;/em>, and click on “Show advanced settings...” (shown here at the
bottom):&lt;/p>

&lt;figure>&lt;img loading="lazy" alt="Show Advanced Settings."
src="03-advanced-settings.png" width="786" height="612"/>&lt;figcaption>Show
Advanced Settings.&lt;/figcaption>&lt;/figure>

&lt;p>Scroll down to the &lt;strong>Privacy&lt;/strong> section of the
&lt;strong>Settings&lt;/strong> page, and check or un-check the various options as you
see fit. Here’s how I set them for this profile:&lt;/p>

&lt;figure>&lt;img loading="lazy" alt="My preferred Privacy settings."
src="04-privacy-settings.png" width="786" height="611"/>&lt;figcaption>My preferred
Privacy settings.&lt;/figcaption>&lt;/figure>

&lt;p>These options (except for Do Not Track) cause Chrome to send extra traffic on
the network (some of that traffic is encrypted), and is a prime candidate for
un-checking — especially if you intend to use Chrome with &lt;a
href="https://www.torproject.org/">Tor&lt;/a>. For more information, see the &lt;a
href="https://www.google.com/intl/en/chrome/browser/privacy/whitepaper.html">Chrome
Privacy Whitepaper&lt;/a>. (In particular, think carefully about disabling phishing
and malware protection; see &lt;a
href="//www.google.com/intl/en/chrome/browser/privacy/whitepaper.html#malware">its
section in the privacy whitepaper&lt;/a>.)&lt;/p>

&lt;p>Click on that &lt;strong>Content settings...&lt;/strong> button here in
the &lt;strong>Privacy&lt;/strong> section, as well:&lt;/p>

&lt;figure>&lt;img loading="lazy" alt="Block 3rd party data and clear all upon exit."
src="04a-cookies-local-data.png" width="721" height="366"/>&lt;figcaption>Block 3rd
party data and clear all upon exit.&lt;/figcaption>&lt;/figure>

&lt;p>I’ve changed the &lt;strong>Cookies&lt;/strong> and site data settings, as you can
see: “Block third-party cookies and site data” means that when you are reading
e.g. http://blog.example.com, an ad included  in the page from
http://ad-company.com cannot set new cookies or site data. “Keep local data only
until I quit my browser” means that Chrome will clear the locally-stored data
(like cookies and &lt;a href="http://diveintohtml5.info/storage.html">HTML5
LocalStorage&lt;/a>) when you quit. (This is similar to, but not exactly the same
as, &lt;a href="https://support.google.com/chrome/answer/95464?hl=en">what Chrome’s
Incognito mode provides&lt;/a>.)&lt;/p>

&lt;p>Scroll down and you will see many more options for &lt;strong>Content
settings&lt;/strong>. I’ll highlight some that are particularly important. First,
block JavaScript by default:&lt;/p>

&lt;figure>&lt;img loading="lazy" alt="Block JavaScript by default."
src="05-no-javascript.png" width="343" height="132"/>&lt;figcaption>Block
JavaScript by default.&lt;/figcaption>&lt;/figure>

&lt;p>However, you can optionally re-enable JavaScript in HTTPS pages:&lt;/p>

&lt;figure>&lt;img loading="lazy" alt="Enable JavaScript on HTTPS page loads."
src="06-javascript-exceptions.png" width="549" height="409"/>&lt;figcaption>Enable
JavaScript on HTTPS page loads.&lt;/figcaption>&lt;/figure>

&lt;p>I like to do this so that I can get rich JavaScript functionality in web
sites like Twitter and Gmail that go to the trouble of authenticating themselves
(and their code) using HTTPS — but sites serving unauthenticated junk cannot run
JavaScript. It’s interesting how many sites still work without JavaScript.
(Sometimes they even work slightly better.)&lt;/p>

&lt;p>Next, we disallow external protocol handlers, and we block all plug-ins:&lt;/p>

&lt;figure>&lt;img loading="lazy" alt="Disallow external protocol handlers and block
all plugins." src="07-no-handlers-block-plugins.png" width="549"
height="340"/>&lt;figcaption>Disallow external protocol handlers and block all
plugins.&lt;/figcaption>&lt;/figure>

&lt;p>Important note about blocking plug-ins: The “Click to play” option means that
plug-ins are disabled by default, but that you can (left-)click on their area on
the screen to run them. However, that left-click is &lt;a
href="http://en.wikipedia.org/wiki/Clickjacking">clickjackable&lt;/a>. It’s better
to select “Block all”, which is really “right-click to play” — yes, you can
still run plug-ins when you want to. To run plug-ins, right-click on their
screen area, which brings up a native-type (operating system) context menu, and
select &lt;strong>Run This Plug-in&lt;/strong>:&lt;/p>

&lt;figure>&lt;img loading="lazy" alt="Run This Plug-in"
src="screen-shot-2014-01-19-at-9-52-26-pm.png" width="644"
height="571"/>&lt;figcaption>You can run or not run plug-ins at
run-time.&lt;/figcaption>&lt;/figure>

&lt;p>Thus, you can be ensured that plug-ins run only when you want them to.&lt;/p>

&lt;p>Next, we disable location services and notifications:&lt;/p>

&lt;figure>&lt;img loading="lazy" alt="Disable location services and notifications."
src="08-no-location-no-notifications.png" width="517"
height="341"/>&lt;figcaption>Disable location services and
notifications.&lt;/figcaption>&lt;/figure>

&lt;p>Disallow sites from taking over the mouse or capturing data from media
sensors:&lt;/p>

&lt;figure>&lt;img loading="lazy" alt="Disallow sites from taking over the mouse or
capturing data from media sensors." src="09-no-mouse-control-no-media.png"
width="587" height="405"/>&lt;figcaption>Disallow sites from taking over the mouse
or capturing data from media sensors.&lt;/figcaption>&lt;/figure>

&lt;p>Turn off un-sandboxed plugins and don’t allow automatic downloads:&lt;/p>

&lt;figure>&lt;img loading="lazy" alt="No un-sandboxed (NPAPI) plugins and no
automatic downloads." src="10-no-unsandboxed-no-auto-download.png" width="591"
height="347"/>&lt;figcaption>No un-sandboxed (NPAPI) plugins and no automatic
downloads.&lt;/figcaption>&lt;/figure>

&lt;p>Do not remember passwords or form field entries:&lt;/p>

&lt;figure>&lt;img loading="lazy" alt="Do not remember passwords or form field
entries." src="11-no-passwords-no-forms.png" width="600"
height="139"/>&lt;figcaption>Do not remember passwords or form field
entries.&lt;/figcaption>&lt;/figure>

&lt;p>Tell Chrome not to auto-detect what language the page is in, to ask where to
place each download, and not to fetch certificate revocation data:&lt;/p>

&lt;figure>&lt;img loading="lazy" alt="Don’t auto-translate, ask where to place each
download, and don’t fetch certificate revocation data."
src="12-languages-downloads-revocation.png" width="536"
height="347"/>&lt;figcaption>Don’t auto-translate, ask where to place each
download, and don’t fetch certificate revocation data.&lt;/figcaption>&lt;/figure>

&lt;p>Note that you can still use Google Translate by right-clicking on a page and
selecting &lt;strong>Translate to English&lt;/strong> (or whatever your native
language is). Un-checking “Offer to translate...” disables the automatic
language detection functionality.&lt;/p>

&lt;p>We leave certificate revocation disabled by default because &lt;a
href="http://en.wikipedia.org/wiki/Online_Certificate_Status_Protocol">the
protocol that does it&lt;/a> can leak information about your browsing to a
server.&lt;/p>

&lt;p>Finally, visit chrome://plugins and affirmatively disable the ones you don’t
need, for good measure:&lt;/p>

&lt;figure>&lt;img loading="lazy" alt="Disable plug-ins."
src="screen-shot-2014-01-19-at-10-09-03-pm.png" width="774"
height="678"/>&lt;figcaption>Disable plug-ins.&lt;/figcaption>&lt;/figure>

&lt;p>Have fun!&lt;/p></description><author>Chris Palmer</author><guid>2014/03/11/privacy-and-security-settings-in-chrome/index.html</guid><pubDate>Tue, 11 Mar 2014 00:00:00 +0000</pubDate></item><item><title>Followup To Downloading Software Safely</title><link>https://noncombatant.org/2014/03/05/followup-to-downloading-software-safely/index.content</link><description>&lt;h1>Followup To Downloading Software Safely&lt;/h1>

&lt;p>&lt;time>5 March 2014&lt;/time>&lt;/p>

&lt;p>I’ve received some emails, tweets, and Hacker News comments about my post &lt;a
href="http://noncombatant.org/2014/03/03/downloading-software-safely-is-nearly-impossible/">Downloading
Software Safely Is Nearly Impossible&lt;/a>. Thanks for reading and I hope you got
a kick out of my mumblings.&lt;/p>

&lt;p>I’d like to address some of the comments and questions people had, as briefly
as possible.&lt;/p>

&lt;ul>

&lt;li>&lt;p>Yes, you need a trusted computing base (TCB). I alluded to this when I
said “You’re pretty sure the NSA did not &lt;a
href="http://www.forbes.com/sites/erikkain/2013/12/29/report-nsa-intercepting-laptops-ordered-online-installing-spyware/">interdict
it during shipment&lt;/a>, and thus that it comes only with the flaky goatware
Microsoft, Lenovo, and any number of Lenovo’s business partners intended for it
to have.” Our goal as security engineers is to limit the size of the TCB. It is,
after all, quite goaty already...&lt;/p>&lt;/li>

&lt;li>&lt;p>The TCB includes the set of X.509 trust anchors for our TLS
library.&lt;/p>&lt;/li>

&lt;li>&lt;p>Yes, I harp on and on about HTTPS. That is because authenticating the
delivery channel — while not necessarily sufficient to indicate code integrity —
is the bare minimum effort we should require from our software sources.
Especially for software that is related to cryptography and security. Here is
GnuPG’s bug tracker; would you want to log into it or report security-sensitive
bugs using it? :&lt;/p>

&lt;/li>

&lt;/ul>

&lt;figure>&lt;img alt="GnuPG’s bug tracker: Not inspiring confidence."
src="gnupg-bug-tracker.png" width="787" height="518"
loading="lazy"/>&lt;figcaption>Not inspiring confidence.&lt;/figcaption>&lt;/figure>

&lt;ul>

&lt;li>&lt;p>Also note that there are at least 2 different problems with HTTPS in that
post: HTTPS not being available, and the HTTPS site differing in contents from
the HTTP site. Again, for a software distribution site, we’d like &lt;a
href="http://noncombatant.org/2014/01/16/security-smells-for-modern-software/">something
that smells a bit better&lt;/a>.&lt;/p>&lt;/li>

&lt;li>&lt;p>Some people claim that PGP keyservers don’t need to use HTTPS, because
the keys authenticate themselves with the &lt;a
href="http://en.wikipedia.org/wiki/Web_of_trust">web of trust&lt;/a>. And it’s
true, the WoT does allow us to fairly easily distinguish &lt;a
href="http://pgp.mit.edu/pks/lookup?op=vindex&amp;amp;search=0x47518EC82F1123AD">this
fake key&lt;/a> from &lt;a
href="http://pgp.mit.edu/pks/lookup?op=vindex&amp;amp;search=0xC11B36DC9C7DD150">this
real key&lt;/a> for EFF’s Seth Schoen. But,&lt;/p>

&lt;ul>

&lt;li>&lt;p>Seth is one of the most well-connected people in the WoT, so a key with
only 1 signature stands out as odd. Would a fake key for a normal person stand
out so well? The WoT is not as good an authentication mechanism as we might hope
it to be. As nice as it is, verifying software packages based on PGP keys we
grab from key servers is thus not a slam-dunk alternative to or replacement for
HTTPS — and nevermind the usability delta between HTTPS and PGP.&lt;/p>&lt;/li>

&lt;li>&lt;p>By now, we understand that metadata for communications is at least as
valuable as the contents, in many cases. Shouldn’t PGP users have
confidentiality in their directory lookups? Yes.&lt;/p>&lt;/li>

&lt;/ul>

&lt;/li>

&lt;li>&lt;p>Yes, as many commentators noted, we should use something like &lt;a
href="http://technet.microsoft.com/en-us/library/cc750035.aspx">Authenticode&lt;/a>:
binaries should be signed, and their signatures checked at run- or install-time.
However, that still requires a TCB of code-signing trust anchors (the same
companies that are your TLS trust anchors), and the difficulty for users of
verifying the code authors is at least as difficult as verifying the
authenticity of an HTTPS web origin. I.e., not super easy. Definitely better
than nothing.&lt;/p>&lt;/li>

&lt;li>&lt;p>This is an extremely hard problem, no doubt about it. Although my post
is very snarky and sarcastic, I don’t think it’s an easy problem. I also fight
the problem uphill.&lt;/p>&lt;/li>

&lt;li>&lt;p>A big part of the solution is to isolate sources of code based on their
cryptographic identity. This is how Android works, and it is how the open web
works (when you use HTTPS or other authenticated origins). I’m not very
knowledgeable about iOS, but I understand they also rely on code-signing and on
sandboxing. If the isolation is strong, much of the risk is reduced — remember,
a big part of my problem was that PuTTY (or any program) runs with the full
privilege of my user account on the platform. Reduce the privilege, reduce the
problem.&lt;/p>

&lt;ul>

&lt;li>If course, now the problem is exposing a privilege-granting UI to users so
that applications can share with explicit approval. One size does not fit all,
and that continues to be a hard secure UX problem.&lt;/li>

&lt;/ul>

&lt;/li>

&lt;li>&lt;p>Finally, I’m not really a fan of Web Crypto. I think more mistakes will
be made with it than successes; it’s just that I also think that of native-code
crypto. The problem does not lie with the implementation environment, but with
the (often perverse) incentives developers have combined with the high level of
expertise needed to use cryptography appropriately and well. Clearly, all the
people who hope to use web crypto to replace TLS, implement DRM, achieve
security against the server that sent the JS, implement homebrew
challenge-response protocols, and so on are in for a heartbreak. But still,
there are potentially good applications for cryptographic algorithms exposed to
JavaScript, and native code does not have a privileged place in crypto. If
anything, due to the lack of privilege separation in legacy platforms, native
code is a worse place to put powerful code.&lt;/p>&lt;/li>

&lt;/ul></description><author>Chris Palmer</author><guid>2014/03/05/followup-to-downloading-software-safely/index.html</guid><pubDate>Wed, 05 Mar 2014 00:00:00 +0000</pubDate></item><item><title>TrustyCon Recap And Video</title><link>https://noncombatant.org/2014/03/03/trustycon-recap-and-video/index.content</link><description>&lt;h1>TrustyCon Recap And Video&lt;/h1>

&lt;p>&lt;time>3 March 2014&lt;/time>&lt;/p>

&lt;p>Last Thursday we had a great time at &lt;a
href="https://trustycon.org/">TrustyCon&lt;/a>, the trustworthy &lt;a
href="http://arstechnica.com/information-technology/2014/01/trustycon-security-counter-convention-planned-for-rsa-refusniks/">alternative
to the RSA Conference&lt;/a>. Many thanks are due to the conference &lt;a
href="https://trustycon.org/sponsors/">sponsors&lt;/a> and organizers: iSEC
Partners, EFF, and DEFCON. My old iSEC boss &lt;a
href="http://unhandled.com/about/">Alex Stamos&lt;/a>, and lots of EFF employees,
put in a lot of volunteer hours to make the conference a success. Thank you!&lt;/p>

&lt;p>I really like single-track conferences. Everyone has a shared experience, and
there is much less of the “lobby-con” or “bar-con” phenomenon, which I don’t
enjoy much. This only works if all the talks are good, and at TrustyCon they
sure were. My favorite was &lt;a href="http://www.cs.princeton.edu/~felten/">Ed
Felten&lt;/a>’s talk that closed out the day. Annalee Newitz has &lt;a
href="http://io9.com/this-lecture-is-the-one-primer-you-need-on-nsa-surveill-1533564028">a
good write-up of it on io9&lt;/a>.&lt;/p>

&lt;p>The &lt;a href="https://www.youtube.com/watch?v=lkO8SNiDSw0">entire conference
is on YouTube&lt;/a>. My talk, co-presented with &lt;a
href="http://crypto.stanford.edu/~dabo/">Dan Boneh&lt;/a>, starts at about 4:33:00
— yes, 4 hours 33 minutes; the entire conference is 1 long video. The sound cuts
out at the beginning but then it comes back quickly, don’t worry. Boneh’s topic,
cryptographic software obfuscation, should amuse and disturb you equally. :)&lt;/p></description><author>Chris Palmer</author><guid>2014/03/03/trustycon-recap-and-video/index.html</guid><pubDate>Mon, 03 Mar 2014 00:00:00 +0000</pubDate></item><item><title>Downloading Software Safely Is Nearly Impossible</title><link>https://noncombatant.org/2014/03/03/downloading-software-safely-is-nearly-impossible/index.content</link><description>&lt;h1>Downloading Software Safely Is Nearly Impossible&lt;/h1>

&lt;p>&lt;time>3 March 2014&lt;/time>&lt;/p>

&lt;aside>
 &lt;p>NOTE: I have written &lt;a href="/2014/03/05/followup-to-downloading-software-safely/">a follow-up post to
 respond to some questions this post may raise&lt;/a>.&lt;/p>
&lt;/aside>

&lt;p>Let’s say you have a brand-new Windows laptop and you’re just oh, so
 happy. You’re pretty sure the NSA did not &lt;a
 href="http://www.forbes.com/sites/erikkain/2013/12/29/report-nsa-intercepting-laptops-ordered-online-installing-spyware/">interdict
 it during shipment&lt;/a>, and thus that it comes only with the flaky goatware
 Microsoft, Lenovo, and any number of Lenovo’s business partners intended for
 it to have. Now all you need is an SSH client so that you can connect to
 your Linux machines, and all will be peachy. Here is how to get an SSH
 client.&lt;/p>

&lt;ol>

 &lt;li>Do a web search for &lt;a href="https://www.google.com/search?q=windows+ssh+client&amp;amp;oq=windows+ssh+client">[
 windows ssh client ]&lt;/a>.&lt;/li>

 &lt;li>Follow the first hit to &lt;a href="http://www.putty.org/">http://www.putty.org/&lt;/a>. Now, since you want
 to get the good and true PuTTY that Simon Tatham wrote, and not some
 unauthenticated malware, you check for the lock icon and the “https://” URL
 scheme. It’s not there — worrying, considering that Tatham is supposedly an
 encryption software developer.&lt;/li>

 &lt;li>No need to worry, though; &lt;a href="http://www.whois.com/whois/putty.org">putty.org is not even owned by
 Tatham&lt;/a>. It’s currently owned by someone named “denis bider”, who
 presumably just likes to domain-squat on other people’s product names and
 provide links. OK. Let’s follow the link to...&lt;/li>

 &lt;li>&lt;a
 href="http://www.chiark.greenend.org.uk/~sgtatham/putty/download.html">http://www.chiark.greenend.org.uk/~sgtatham/putty/download.html&lt;/a>.
 Ahh, this has Tatham’s name right in the path part of the URL, so... wait,
 is that good? Actually, no; only the hostname can indicate site
 ownership. &lt;a href="http://www.whois.com/whois/greenend.org.uk">Richard
 Kettlewell currently owns greenend.org.uk&lt;/a>.&lt;/li>

 &lt;li>Look for, and fail to find, the lock icon and the “https://” URL scheme.
 Again, shouldn’t cryptography and security software — like all software — be
 delivered always and only via an authenticated service?&lt;/li>

 &lt;li>Manually add the “https://”. Note that the site does not respond to
 HTTPS. Begin to doubt that this is the right site.&lt;br />

 &lt;figure>&lt;img alt="Screenshot showing that PuTTY is not available via HTTPS." src="no-https-putty.png"
 width="733" height="461" loading="lazy" />
 &lt;figcaption>PuTTY is not available via
 HTTPS.&lt;/figcaption>
 &lt;/figure>

 &lt;/li>

 &lt;li>Not to worry! Scroll down and note that Tatham offers links to RSA and
 DSA cryptographic signatures of the binaries, e.g. &lt;a
 href="http://the.earth.li/~sgtatham/putty/latest/x86/putty.exe.RSA">http://the.earth.li/~sgtatham/putty/latest/x86/putty.exe.RSA&lt;/a>.
 Note that &lt;a href="http://www.whois.com/whois/earth.li">earth.li is
 currently owned by Jonathan McDowell&lt;/a>. When you click the link to the
 signature, you do indeed get an RSA signature of something, but there is no
 way to know for sure who the signer was or what they signed — any attacker
 who could have compromised the site to poison the executable PuTTY programs
 (or performed a man-in-the-middle attack on your connection to the site)
 could also just as easily have compromised the signatures.&lt;/li>

 &lt;li>Attempt to download the signature via HTTPS instead, &lt;a
 href="https://the.earth.li/~sgtatham/putty/latest/x86/putty.exe.RSA">https://the.earth.li/~sgtatham/putty/latest/x86/putty.exe.RSA&lt;/a>,
 and note that the server responds with a 404. Become increasingly
 suspicious.&lt;br />

 &lt;figure>&lt;img alt="Screenshot showing that the RSA signature file is not found." src="https-signature-404.png"
 width="666" height="403" loading="lazy" />
 &lt;figcaption>Is this a bad sign? It feels
 bad.&lt;/figcaption>
 &lt;/figure>

 &lt;/li>

 &lt;li>Take a breather to read &lt;a href="http://www.chiark.greenend.org.uk/~sgtatham/putty/keys.html">Tatham’s
 explanation of how overly-complex his signing infrastructure is&lt;/a>, but not
 why the delivery channel is anonymous.&lt;/li>

 &lt;li>Briefly wonder if Tatham’s PGP keys are noted in a central registry,
 such as MIT’s PGP key server. &lt;a href="http://pgp.mit.edu/pks/lookup?search=tatham&amp;amp;op=index">Nope&lt;/a>.&lt;/li>

 &lt;li>Briefly wonder if it matters that MIT’s PGP key server is
 unauthenticated.&lt;br />

 &lt;figure>&lt;img alt="Screenshot showing that the MIT key server is
unauthenticated." src="no-https-keyserver.png" width="745" height="503" loading="lazy" />
 &lt;figcaption>The MIT key server is
 unauthenticated.&lt;/figcaption>
 &lt;/figure>

 &lt;/li>

 &lt;li>Recall that even if you could get Tatham’s PGP key from an authenticated
 key server, you’d still need to download a PGP program. Rather than repeat
 the steps in this tutorial for GnuPG, give up and decide to download an
 unauthenticated copy of PuTTY.&lt;/li>

 &lt;li>Note that Tatham refers you to &lt;a
 href="http://www.pc-tools.net/win32/freeware/md5sums/">http://www.pc-tools.net/win32/freeware/md5sums/&lt;/a>
 for an MD5 calculator for Windows, and briefly consider at least checking
 the anonymous (hence useless) MD5 digest for PuTTY. Noting that
 www.pc-tools.net also does not respond to HTTPS, forego that waste of
 time.&lt;/li>

 &lt;li>Having downloaded putty.exe, think long and hard before clicking on it.
 Note that when you execute it, it will run with the full privilege of your
 user account on this Windows machine. It will have the ability to read,
 delete, and modify all your documents and emails, and will be able to post
 your porn collection to Wikipedia.&lt;/li>

 &lt;li>Hope that it does not.&lt;/li>

 &lt;li>Click on putty.exe anyway. Connect to your account on your Linux server,
 which is now &lt;em>also&lt;/em> under the control of an unauthenticated program
 from the internet. Consider that, if the download was not poisoned, this
 thing calling itself “PuTTY” was written by a developer who might know how
 to implement RSA in C, but who does not know how or why to use RSA. (Are you
 even connected to your real Linux server, at this point? Hard to know.)&lt;/li>

 &lt;li>Note that, suddenly, &lt;a href="http://www.w3.org/TR/WebCryptoAPI/">Web
 Crypto&lt;/a> is starting to look damn good despite &lt;a
 href="http://rdist.root.org/2010/11/29/final-post-on-javascript-crypto/">the
 objections of the native code chauvinists&lt;/a>. At least JavaScript runs
 under the &lt;a href="http://en.wikipedia.org/wiki/Same-origin_policy">same
 origin policy&lt;/a> and is sandboxed by &lt;a
 href="http://www.chromium.org/developers/design-documents/process-models">Chrome’s
 multi-process model&lt;/a>, so it wouldn’t have the full run of your Windows
 user account.&lt;/li>

 &lt;li>Despair.&lt;/li>

&lt;/ol></description><author>Chris Palmer</author><guid>2014/03/03/downloading-software-safely-is-nearly-impossible/index.html</guid><pubDate>Mon, 03 Mar 2014 00:00:00 +0000</pubDate></item><item><title>Maps And Their Applications</title><link>https://noncombatant.org/2014/03/02/maps-and-their-applications/index.content</link><description>&lt;h1>Maps And Their Applications&lt;/h1>

&lt;p>&lt;time>2 March 2014&lt;/time>&lt;/p>

&lt;p>This morning I was hanging out with my &lt;a
href="http://hackbrightacademy.com/">Hackbright&lt;/a> mentee, and we discussed
how one of her programming problems could be solved using a Python
dictionary or JavaScript object. In fact, you can use a dictionary in lots
of ways. Here are some:&lt;/p>

&lt;ul>

&lt;li>As a set (an unordered group of elements, each element appearing only
once). For example, you can get the unique elements of a list or array by
collapsing them into the keys of a dictionary.&lt;/li>

&lt;li>As the underlying storage for the fields of a dynamic object. “Dynamic
object” here means “an object that gets fields added or removed”. E.g. in
JavaScript, you can add new fields and values at any time to an object,
while in Java or C the fields of an object are static and unchanging once
defined. (And, for that reason, accessing the fields of a Java or C object
can be done in a much faster way.)&lt;/li>

&lt;li>As a &lt;a href="http://en.wikipedia.org/wiki/Sparse_array">sparse
array&lt;/a>.&lt;/li>

&lt;li>As the storage for a &lt;a
href="http://en.wikipedia.org/wiki/Memoization">memoized function&lt;/a> (which
can, in turn, be a way to optimize expensive functions, including expensive
recursive functions). &lt;a
href="https://wiki.python.org/moin/PythonDecoratorLibrary#Memoize">With
Python decorators, you can easily memoize any function&lt;/a>, and the
canonical way to do that is with a dictionary.&lt;/li>

&lt;li>Many other cache applications.&lt;/li>

&lt;li>&lt;a href="http://en.wikipedia.org/wiki/Dictionary_coder">Data compression&lt;/a>.&lt;/li>

&lt;/ul>

&lt;p>For the rest of this post I’ll use the term &lt;em>map&lt;/em> to refer to what
various languages/APIs/sources in the literature call &lt;em>dictionaries&lt;/em>,
&lt;em>hashes&lt;/em>, “objects” (only? in a JavaScript context), &lt;em>associative
arrays&lt;/em>, &lt;em>symbol tables&lt;/em>, or &lt;em>tables&lt;/em>. A map is any data
structure that groups a dynamic number of &lt;em>key-value pairs&lt;/em> together,
and allows us to retrieve values by key, to insert new key-value pairs, and
to update the values associated with keys. We almost always require that the
data structure allow us to do these operations very quickly. (After all,
we’re going to be using them all the time to solve lots of problems!)&lt;/p>

&lt;p>Most, but not all, languages come with some kind of map interface built-in. Notably, the C language does not (but C++ does).&lt;/p>
&lt;p>You can implement a map in many ways. Here are some examples:&lt;/p>

&lt;ul>

&lt;li>A simple &lt;a href="http://en.wikipedia.org/wiki/Linked_list">linked
list&lt;/a> of pairs. This will be slow (O(n)), and insufficient for general
use.&lt;/li>

&lt;li>A &lt;a href="http://en.wikipedia.org/wiki/Hash_table">hash table&lt;/a>. This
is generally very fast (roughly O(1)), although it requires you to have a
good hash function for your key type. Most languages allow you to provide a
custom hash function for your object types (e.g. the &lt;code>__hash__&lt;/code>
method in Python, or the &lt;code>hashCode&lt;/code> method in Java).&lt;/li>

&lt;li>A &lt;a href="http://en.wikipedia.org/wiki/Binary_search_tree">binary
search tree&lt;/a>. Fast (O(lg n)). Unlike in a hash table, the keys will be
ordered.  This could be a useful property.&lt;/li>

&lt;li>A &lt;a href="http://en.wikipedia.org/wiki/Skip_list">skip list&lt;/a>.&lt;/li>

&lt;/ul>

&lt;p>Note that although a general-purpose map is useful for many problems, it is
not always ideal for a particular problem. For example, although you can use a
map as a set, it’s a bit of a waste of space — it’s a set of key-value pairs,
but you only need the key. Similarly, maybe you need not only to take the unique
elements from a group of elements, but also to print them out in sorted order.
If your dictionary type is implemented as a hash table, you’ll have to sort the
keys (at an additional cost of O(n lg n) plus the memory allocation to store the
keys in an array). By contrast, if your dictionary is implemented as a binary
search tree, after you are done inserting all the elements, they’ll already be
sorted. (The trade-off is that it might have cost more to insert the elements.
When in doubt, test!)&lt;/p>

&lt;p>Because one size does not fit all, many languages provide a variety of
map and set implementations. For example, C++ has &lt;a
href="http://www.cplusplus.com/reference/map/map/">map&lt;/a>, &lt;a
href="http://www.cplusplus.com/reference/set/">set&lt;/a>, &lt;a
href="http://www.cplusplus.com/reference/unordered_map/">unordered_map&lt;/a>,
and &lt;a
href="http://www.cplusplus.com/reference/unordered_set/">unordered_set&lt;/a>.
The &lt;a
href="http://docs.oracle.com/javase/7/docs/api/java/util/Map.html">Java Map
interface&lt;/a> has many implementations. Other languages, like Python, Perl,
Ruby, and JavaScript, provide just one map implementation — usually a hash
table of some kind. Some, like Python, also provide a distinct &lt;a
href="http://docs.python.org/2/library/stdtypes.html#set">set&lt;/a> type or
API, and you should use it when it fits your needs.&lt;/p>

&lt;p>It’s a good exercise to implement a map yourself, in at least one way, in
at least one language. I recommend starting with a simple hash table, and
then working up to a good binary search tree like a &lt;a
href="http://en.wikipedia.org/wiki/Red%E2%80%93black_tree">red-black
tree&lt;/a>.&lt;/p></description><author>Chris Palmer</author><guid>2014/03/02/maps-and-their-applications/index.html</guid><pubDate>Sun, 02 Mar 2014 00:00:00 +0000</pubDate></item><item><title>A Favorite Pedal: Strymon El Capistan</title><link>https://noncombatant.org/2014/02/09/a-favorite-pedal-strymon-el-capistan/index.content</link><description>&lt;h1>A Favorite Pedal: Strymon El Capistan&lt;/h1>

&lt;p>&lt;time>9 February 2014&lt;/time>&lt;/p>

&lt;p>So here’s another favorite guitar effects pedal of mine, the &lt;a
 href="http://www.strymon.net/products/elcapistan/">Strymon El
 Capistan&lt;/a>:&lt;/p>

&lt;figure>&lt;img alt="Strymon El Capistan" src="el-capistan.jpg" width="800" height="791" loading="lazy" />
 &lt;figcaption>Strymon El
 Capistan&lt;/figcaption>
&lt;/figure>

&lt;p>This a &lt;em>very&lt;/em> nice machine. It’s a digital signal processor with
 software to emulate an old-timey magnetic tape-based echo machine, like the
 &lt;a href="http://en.wikipedia.org/wiki/Echoplex">Echoplex&lt;/a>. The Echoplex
 is fragile, has very limited delay time, and over time the tape would get
 stretched, worn out, wrinkled, and generally start to sound very weird. El
 Capistan emulates all the weirdness (except the fragility!), and adds a few
 more features. My favorite feature is the quite good &lt;a
 href="http://en.wikipedia.org/wiki/Reverberation#Spring_reverberators">spring
 reverb&lt;/a> emulation. Here is my guitar dry (guitar → El Capistan → speaker
 emulator → mixing board → Garage Band), and then again with the reverb on
 and a tiny amount of slapback (very short) echo:
&lt;/p>

&lt;audio controls>
 &lt;source src="el-capistan-demo-1.mp3" />
 &lt;a href="el-capistan-demo-1.mp3">Download&lt;/a>
&lt;/audio>

&lt;p>Here’s a snippet of “Sunny” by Bobby Hebb with the reverb and
 slapback:&lt;/p>

&lt;audio controls>
 &lt;source src="el-capistan-demo-2.mp3" />
 &lt;a href="el-capistan-demo-2.mp3">Download&lt;/a>
&lt;/audio>

&lt;p>A good echo pedal must have a tap tempo feature (the button on the left),
 allowing you to set the delay time by tapping your foot. Here I use it to
 repeat what I play, delayed by a dotted eight-note, to do a fake version of
 “Frame By Frame” by King Crimson:&lt;/p>

&lt;audio controls>
 &lt;source src="el-capistan-demo-3.mp3" />
 &lt;a href="el-capistan-demo-3.mp3">Download&lt;/a>
&lt;/audio>

&lt;p>Another great feature of Echoplexes (that El Capistan emulates — of
 course) is that it had multiple playback heads, allowing you to get multiple
 echo times from the same input signal. Here I use it (with the spring reverb
 too) to do a pretty bad rendition of the introduction of “Fight The Fight”
 by Living Colour:&lt;/p>

&lt;audio controls>
 &lt;source src="el-capistan-demo-4.mp3" />
 &lt;a href="el-capistan-demo-4.mp3">Download&lt;/a>
&lt;/audio>

&lt;p>For “Fight The Fight” I used El Capistan’s stereo output feature which
 adds a wonderful sense of space and a bit of a ping-pong feeling to the
 multi-head echo.&lt;/p>

&lt;p>El Capistan can do almost anything you could want from an echo machine,
 but that makes it complicated. It has a sound-on-sound mode that I can only
 occasionally figure out — but it sounds great when I get it. (Dammit Jim,
 I’m a software engineer, not a pedal doctor!) If I can reliably understand
 how to make it go I’ll post another sample using it.&lt;/p>

&lt;p>For simplicity and immediate gratification, I recommend the unstoppable
 &lt;a href="http://www.bossus.com/gear/productdetails.php?ProductId=958">Boss
 DD-7 delay&lt;/a>. (I have 2, and could definitely put a 3rd to good use.) But
 for hours of wacky fun and classic &lt;a href="http://en.wikipedia.org/wiki/Delia_Derbyshire">Delia Derbyshire sci-fi
 sounds&lt;/a>, you want El Capistan.
&lt;/p></description><author>Chris Palmer</author><guid>2014/02/09/a-favorite-pedal-strymon-el-capistan/index.html</guid><pubDate>Sun, 09 Feb 2014 00:00:00 +0000</pubDate></item><item><title>A Favorite Pedal: Psilocybe Phaser</title><link>https://noncombatant.org/2014/02/03/a-favorite-pedal-psilocybe-phaser/index.content</link><description>&lt;h1>A Favorite Pedal: Psilocybe Phaser&lt;/h1>

&lt;p>&lt;time>3 February 2014&lt;/time>&lt;/p>

&lt;p>I think I’ll try to start blogging some sound samples of some of my
 favorite guitar effects pedals. Randomly, I’ll start with the &lt;a
 href="http://www.homebrewelectronics.com/products.htm">HomeBrew
 Electronics&lt;/a> Psilocybe Phaser.&lt;/p>

&lt;figure>&lt;img alt="Home Brew Electronics Psilocybe Phaser" src="psilocybe-phaser.jpg" width="800" height="979"
 loading="lazy" />
 &lt;figcaption>Home Brew Electronics Psilocybe
 Phaser&lt;/figcaption>
&lt;/figure>

&lt;p>It’s a bit more versatile — the Shift 1 and Shift 2 switches change the
 speed and EQ significantly — but it never gets off-the-rails chewy like the
 classic MXR Phase 90. I mostly use its gentle sweep but it can get
 Univibe-like (if the Univibe were insane) if you crank the Regen and Speed
 all the way. Here are some sound samples!&lt;/p>

&lt;p>I recorded this with the neck pickup of my Strat in single-coil mode,
 straight into a speaker emulator:&lt;/p>

&lt;audio controls>
 &lt;source src="phaser-demo-1.mp3" />
 &lt;a href="phaser-demo-1.mp3">Download&lt;/a>
&lt;/audio>

&lt;p>This is with the Strat bridge pickup in single-coil mode, into the &lt;a
 href="http://www.strymon.net/products/elcapistan/">Strymon El Capistan&lt;/a>
 doing nothing but emulating a spring reverb, and my Precision bass with the
 &lt;a href="http://www.stewmac.com/shop/Electronics,_pickups/Components:_Black_Ice_overdrive/Black_Ice.html">Black
 Ice&lt;/a> (passive fuzz) turned on:
&lt;/p>

&lt;audio controls>
 &lt;source src="phaser-demo-2.mp3" />
 &lt;a href="phaser-demo-2.mp3">Download&lt;/a>
&lt;/audio>

&lt;p>Finally, this is with the bridge pickup in single-coil mode, with the
 Strymon doing a little echo as well as spring reverb:&lt;/p>

&lt;audio controls>
 &lt;source src="phaser-demo-3.mp3" />
 &lt;a href="phaser-demo-3.mp3">Download&lt;/a>
&lt;/audio>

&lt;p>I’ll probably write about the El Capistan next. It is a gem for sure.&lt;/p></description><author>Chris Palmer</author><guid>2014/02/03/a-favorite-pedal-psilocybe-phaser/index.html</guid><pubDate>Mon, 03 Feb 2014 00:00:00 +0000</pubDate></item><item><title>Security Smells For Modern Software</title><link>https://noncombatant.org/2014/01/16/security-smells-for-modern-software/index.content</link><description>&lt;h1>Security Smells For Modern Software&lt;/h1>

&lt;p>&lt;time>16 January 2014&lt;/time>&lt;/p>

&lt;p>These seem like good minimum standards, maybe.&lt;/p>

&lt;ul>

&lt;li>Implement the application in a &lt;strong>memory- and type-safe
language&lt;/strong>. Appeals to use an unsafe language for performance must be
substantiated with profile traces based on real-world usage. (Not
microbenchmarks.) Even then, only implement the performance-sensitive
components in the unsafe language.&lt;/li>

&lt;li>The application must have &lt;strong>high unit test coverage&lt;/strong>.&lt;/li>

&lt;li>If the &lt;strong>application parses data, include fuzzers&lt;/strong> in the
source tree and continuously run them on at least one (preferably thousands) of
servers.&lt;/li>

&lt;li>If the application communicates on the network, it must use
&lt;strong>secure (authenticated, confidential) transport only&lt;/strong> (not
optionally). Preferably, peers should pin each others’ public keys.&lt;/li>

&lt;li>&lt;strong>Fix security-relevant bugs in the open&lt;/strong>, and clearly
mark them as such.&lt;/li>

&lt;li>Provide &lt;strong>frequent updates&lt;/strong>, delivered securely (e.g.
signed and automatically — not manually — validated).&lt;/li>

&lt;li>&lt;strong>Minimize dependencies&lt;/strong>, and ensure that all dependencies
are up-to-date.&lt;/li>

&lt;/ul></description><author>Chris Palmer</author><guid>2014/01/16/security-smells-for-modern-software/index.html</guid><pubDate>Thu, 16 Jan 2014 00:00:00 +0000</pubDate></item><item><title>Anaïs Nin’s Challenge</title><link>https://noncombatant.org/2013/12/10/anais-nins-challenge/index.content</link><description>&lt;h1>Anaïs Nin’s Challenge&lt;/h1>

&lt;p>&lt;time>10 December 2013&lt;/time>&lt;/p>

&lt;p>It’s strange how difficult and frightening it can be to write words on paper.
But it really is. I can barely stand to do it. &lt;a
href="http://www.brainpickings.org/index.php/2013/09/20/anais-nin-on-writing-1947/">Here
is Anaïs Nin&lt;/a>:&lt;/p>

&lt;blockquote>It is in the moments of emotional crisis that human beings reveal
themselves most accurately. … The heightened moments … are the moments of
revelation. It is the moment when the real self rises to the surface, shatters
its false roles, erupts and assumes reality and identity. The fiery moments of
passionate experience are the moments of wholeness and totality of the
personality.&lt;/blockquote></description><author>Chris Palmer</author><guid>2013/12/10/anais-nins-challenge/index.html</guid><pubDate>Tue, 10 Dec 2013 00:00:00 +0000</pubDate></item><item><title>What Is Security Engineering (archive post)</title><link>https://noncombatant.org/2013/12/10/what-is-security-engineering-archive-post/index.content</link><description>&lt;h1>What Is Security Engineering (archive post)&lt;/h1>

&lt;p>&lt;time>10 December 2013&lt;/time>&lt;/p>

&lt;p>&lt;em>To make sure I keep a copy of this post, &lt;a
href="https://hackbrightacademy.com/blog/software-security-engineering/">originally
posted at the Hackbright blog&lt;/a>, here it is.&lt;/em>&lt;/p>

&lt;p>As a Hackbright student or alumna, you probably plan to participate in
building the foundation of our shiny new automated world. (Thanks for
joining us! We need you.)&lt;/p>

&lt;p>Software, firmware, and computing hardware underlie essentially all
aspects of our society — the &lt;a
href="http://www.edn.com/design/automotive/4423428/Toyota-s-killer-firmware--Bad-design-and-its-consequences">safety
systems in our cars&lt;/a> (and trains, and airplanes), our &lt;a
href="http://money.cnn.com/2012/08/09/technology/knight-expensive-computer-bug/">financial
system&lt;/a>, &lt;a
href="http://www.darkreading.com/management/stuxnet-expert-proposes-new-framework-fo/240160846">critical
infrastructure&lt;/a> like energy and water purification, our &lt;a
href="https://twitter.com/alexhern/status/402365655250644992/photo/1">healthcare
system&lt;/a>, and our &lt;a
href="http://www.gamesindustry.biz/articles/2013-03-27-ea-drm-is-a-failed-dead-end-strategy">culture&lt;/a>.
Even hand-crafted clothing is sold on &lt;a
href="http://www.etsy.com/">Etsy&lt;/a> and is made of &lt;a
href="http://www.nytimes.com/2013/09/20/business/us-textile-factories-return.html?_r=0">cotton
spun by a robot&lt;/a>.&lt;/p>

&lt;p>But it’s not enough that our infrastructure merely work. It has to work
well and reliably under all kinds of pressure: human error (operator — and
developer!), bad weather, bad luck, radio interference, hardware failure,
network outages, criminal malfeasance. Even war.&lt;/p>

&lt;p>Security engineering requires adopting a new mindset, at once cautious
and conservative, yet also willing to calculate risks and experiment. Either
perspective on its own is not enough; we must be of two minds to
succeed.&lt;/p>

&lt;p>Software security engineers are the professional pessimists who insist
that &lt;a
href="https://blog.twitter.com/2013/keeping-our-users-secure">Twitter must
encrypt and authenticate all its network traffic&lt;/a> even though it might
seem less important than, say, banking. (Ironically, we then &lt;a
href="http://arstechnica.com/security/2013/04/why-your-password-cant-have-symbols-or-be-longer-than-16-characters/">beg
and plead with banks to adopt security&lt;/a> at least as good as Twitter’s.)
We worry about &lt;a
href="https://www.usenix.org/legacy/event/leet08/tech/full_papers/king/king.pdf">how
impossible it is to audit the hardware which we have to assume is
safe&lt;/a>. &lt;a
href="http://arstechnica.com/security/2013/11/smart-tv-from-lg-phones-home-with-users-viewing-habits-usb-file-names/">Normal
people see a TV&lt;/a>, but we see &lt;a
href="http://en.wikipedia.org/wiki/Telescreen">Winston Smith’s
telescreen&lt;/a>. We are those annoying friends who remind their co-workers
that &lt;a href="http://en.wikipedia.org/wiki/Integer_overflow">computers
cannot, in fact, correctly add two numbers together&lt;/a> (not without &lt;a
href="http://en.wikipedia.org/wiki/Arbitrary-precision_arithmetic">significant
help&lt;/a>, at least).&lt;/p>

&lt;p>Software security engineers are the professional optimists who try to
make computers work safely in spite of &lt;a
href="http://en.wikipedia.org/wiki/Murphy%27s_law">Murphy’s best
efforts&lt;/a> — we will try to &lt;a
href="http://www.cl.cam.ac.uk/~rja14/Papers/satan.pdf">program Satan’s
computer&lt;/a>. We dream of a world in which &lt;a
href="http://en.wikipedia.org/wiki/Google_driverless_car">robot
cars&lt;/a> tell each other only the truth about their position and speed. We
dream of a world in which credit card and ATM fraud is mere statistical
noise. We dream of a world in which &lt;a
href="http://www.youtube.com/watch?v=TzR7R6fBr00">your phone is really off
when you turn it off&lt;/a>, and which keeps your communications with your
doctor confidential when it is on.&lt;/p>

&lt;p>We dream of a world in which &lt;a
href="http://arstechnica.com/gadgets/2012/10/drm-be-damned-how-to-protect-your-amazon-e-books-from-being-deleted/">books
cannot be burned&lt;/a>.&lt;/p>

&lt;h2>Resources&lt;/h2>

&lt;p>If you’re interested in security engineering (and I hope you are, even if
you don’t choose to make it your specialty), you can get involved at any
point in your career. One of the best ways to get started is — as
always — simply getting your hands dirty.&lt;/p>

&lt;ul>

&lt;li>Use &lt;a href="https://www.wireshark.org/">Wireshark&lt;/a> to learn what is
happening on your network, and learn about the structure of network packets
and connections.&lt;/li>

&lt;li>Use an &lt;a href="http://portswigger.net/burp/proxy.html">HTTP proxy like
Burp&lt;/a> to learn what your browser is saying to web servers, and learn what
it takes to intercept encrypted communications.&lt;/li>

&lt;li>Check out &lt;a href="http://lcamtuf.coredump.cx/">Michal Zalewski&lt;/a>’s
excellent &lt;em>&lt;a
href="https://code.google.com/p/browsersec/wiki/Main">Browser Security
Handbook&lt;/a>&lt;/em> to learn why, exactly, the nytimes.com web site cannot
read your Gmail. (Hopefully.)&lt;/li>

&lt;li>If you’re interested in cryptography, an excellent beginning book is &lt;a
href="http://www.amazon.com/Cryptography-Engineering-Principles-Practical-Applications/dp/0470474246">&lt;em>Cryptography
Engineering&lt;/em>&lt;/a> by Ferguson, Schneier, and Kohno.&lt;/li>

&lt;li>It’s important and hilariously fun to learn the C programming language,
and to learn &lt;a
href="http://www.amazon.com/Expert-Programming-Peter-van-Linden/dp/0131774298">how
C programs can go so badly wrong&lt;/a>. &lt;a
href="http://lldb.llvm.org/tutorial.html">Get your hands dirty with a
debugger and disassembler&lt;/a>, and learn what the machine is really
doing.&lt;/li>

&lt;/ul>

&lt;p>And, as always, find a &lt;a href="http://www.baythreat.org/">good&lt;/a> &lt;a
href="http://ccc.de/">community&lt;/a> to &lt;a
href="http://infosecmentors.com/">learn with&lt;/a>. Or &lt;a
href="http://observationdeck.io9.com/help-fund-a-feminist-makerspace-in-seattle-1467872208">build
your own&lt;/a>!&lt;/p></description><author>Chris Palmer</author><guid>2013/12/10/what-is-security-engineering-archive-post/index.html</guid><pubDate>Tue, 10 Dec 2013 00:00:00 +0000</pubDate></item><item><title>Arvo Pärt</title><link>https://noncombatant.org/2013/12/10/arvo-part-if-you-listen-to-only-one-of-his-works/index.content</link><description>&lt;h1>Arvo Pärt&lt;/h1>

&lt;p>&lt;time>10 December 2013&lt;/time>&lt;/p>

&lt;p>My favorite of his is &lt;em>&lt;a
href="http://en.wikipedia.org/wiki/Kanon_Pokajanen">Kanon
Pokajanen&lt;/a>&lt;/em>.&lt;/p>

&lt;p>Perhaps I’m inclined to favor it since the libretto is written in a
borderline-&lt;a
href="https://en.wikipedia.org/wiki/Artistic_language">artlang&lt;/a>.&lt;/p>

&lt;p>There can be some Kierkegaardian wallowing in some of his music.
But &lt;em>Kanon Pokajanen&lt;/em> is beautiful and powerful from start to finish.
There’s a simple purity to choral music; there is no chance to hide
compositional flaws in fashion or timbre. Any beauty is true human beauty, any
flaw is a real flaw.&lt;/p>

&lt;p>Almost all of the music I love is machine music — but if I had my life to
live over again, I know what I would do: compose music, and mostly for
voices.&lt;/p></description><author>Chris Palmer</author><guid>2013/12/10/arvo-part-if-you-listen-to-only-one-of-his-works/index.html</guid><pubDate>Tue, 10 Dec 2013 00:00:00 +0000</pubDate></item><item><title>Autodidact Software Engineering Bibliography</title><link>https://noncombatant.org/2013/08/11/autodidact-software-engineering-bibliography/index.content</link><description>&lt;h1>Autodidact Software Engineering Bibliography&lt;/h1>

&lt;p>&lt;time>11 August 2013&lt;/time>&lt;/p>

&lt;div id="toc">&lt;/div>

&lt;p>What little I know about software engineering, I largely taught myself
through books, conversations with more knowledgeable friends, and just plain
getting my hands on some code. Of all the books I’ve read, here are some of the
ones I think helped me the most when I was coming up, and some new ones that are
good.&lt;/p>

&lt;p>I’m covering only books here, not magazine or journal articles and not web
sites.&lt;/p>

&lt;h2>Beginning&lt;/h2>

&lt;p>&lt;a
href="https://www.amazon.com/C-Programming-Language-2nd-Edition/dp/0131103628">&lt;em>The
C Programming Language&lt;/em>&lt;/a>, by Brian Kernighan and Dennis Ritchie. Even if
you never end up using C, this book is a masterpiece of concise technical
writing. Modern languages have excellent texts too: &lt;a
href="https://www.amazon.com/Programming-Language-Addison-Wesley-Professional-Computing/dp/0134190440">&lt;em>The
Go Progamming Language&lt;/em>&lt;/a> by Alan Donovan and Brian Kernighan, and &lt;a
href="https://doc.rust-lang.org/book/">&lt;em>The Rust Programming
Language&lt;/em>&lt;/a>, by Steve Klabnik and Carol Nichols.&lt;/p>

&lt;p>&lt;a
href="https://www.amazon.com/Practice-Programming-Addison-Wesley-Professional-Computing/dp/020161586X">&lt;em>The Practice
of Programming&lt;/em>&lt;/a> by Rob Pike and Brian Kernighan. Also a masterpiece of
concision, and also rewards multiple readings. Covers lots of ground in an
approachable and fun way.&lt;/p>

&lt;p>&lt;a href="http://www.cs.bell-labs.com/cm/cs/pearls/">&lt;em>Programming
Pearls&lt;/em>&lt;/a> and &lt;a
href="https://www.amazon.com/More-Programming-Pearls-Confessions-Coder/dp/0201118890/ref=sr_1_3">&lt;em>More
Programming Pearls&lt;/em>&lt;/a>, by Jon Bentley. A wonderful compendium of
algorithms, puzzles, and creative solutions.&lt;/p>

&lt;h2>Moving Forward&lt;/h2>

&lt;p>&lt;a
href="https://www.amazon.com/UNIX-Linux-System-Administration-Handbook/dp/0134277554">&lt;em>UNIX
And Linux System Administration Handbook&lt;/em>, 5th Edition&lt;/a>, by Evi Nemeth et
al.&lt;/p>

&lt;p>&lt;em>&lt;a href="https://www.amazon.com/books/dp/0262033844">Introduction to
Algorithms&lt;/a>&lt;/em> by Thomas Cormen, Charles Leiserson, Ron Rivest, and
Clifford Stein. This is the standard serving of vegetables.&lt;/p>

&lt;p>&lt;a
href="https://www.amazon.com/Expert-Programming-Peter-van-Linden/dp/0131774298">&lt;em>Expert
C Programming: Deep C Secrets&lt;/em>&lt;/a>, by Peter van der Linden. C is a jungle
of Claymore mines, punji stakes, and unnaturally large insects. Oh my god, we
are all going to die. Learn precisely how your demise will come in this
disturbing novella. (This book could also go in the Security category,
below.)&lt;/p>

&lt;p>&lt;a href="http://hop.perl.plover.com/">&lt;em>Higher-Order Perl&lt;/em>&lt;/a>, by Mark
Jason Dominus. A fun and practical (modulo Perl) course on functional
programming. &lt;a
href="https://github.com/MostlyAdequate/mostly-adequate-guide">&lt;em>Professor
Frisby’s Mostly Adequate Guide To Functional Programming&lt;/em>&lt;/a> is somewhat
along the same lines, using JavaScript.&lt;/p>

&lt;p>&lt;a href="http://shop.oreilly.com/product/0636920033707.do">&lt;em>Effective
Modern C++&lt;/em>&lt;/a>, by Scott Meyers. Helps keep the madness at bay.&lt;/p>

&lt;h2>Operating Systems&lt;/h2>

&lt;p>&lt;a
href="https://www.amazon.com/Design-Operating-System-Prentice-Hall-Software/dp/0132017997">&lt;em>The
Design of the Unix Operating System&lt;/em>&lt;/a>, by Bach; or, &lt;a
href="https://www.amazon.com/books/dp/0201702452">&lt;em>The Design and
Implementation of the FreeBSD Operating System&lt;/em>&lt;/a>, by McKusick and
Neville-Neil. Reading both might be overkill, but that didn’t stop me.&lt;/p>

&lt;p>&lt;a
href=""https://www.amazon.com/Windows-Internals-Part-architecture-management/dp/0735684189/ref=pd_lpo_sbs_14_img_0">&lt;em>Windows
Internals&lt;/em>, 7th Edition&lt;/a>, by Pavel Yosifovich, Mark Russinovich, David
Solomon, and Alex Ionescu. A complex but thorough design, well implemented and
wonderfully documented.&lt;/p>

&lt;p>&lt;a
href="https://www.amazon.com/TCP-Illustrated-Vol-Addison-Wesley-Professional/dp/0201633469">&lt;em>TCP/IP
Illustrated, vol. 1: The Protocols&lt;/em>&lt;/a>, by Richard Stevens. Solid bedrock
for understanding networking.&lt;/p>

&lt;h2>Security&lt;/h2>

&lt;p>&lt;a href="https://www.cs.virginia.edu/~evans/cs551/saltzer/">&lt;em>The Protection Of
Information In Computer Systems&lt;/em>&lt;/a>, by Jerome Saltzer and Michael
Schroeder. Foundational.&lt;/p>

&lt;p>&lt;a
href="https://www.amazon.com/Cryptography-Engineering-Principles-Practical-Applications/dp/0470474246">&lt;em>Cryptography
Engineering&lt;/em>&lt;/a>, by Niels Ferguson, Bruce Schneier, and Tadayoshi Kohno.
Practical and accessible.&lt;/p>

&lt;p>&lt;a
href="https://www.amazon.com/The-Software-Security-Assessment-Vulnerabilities/dp/0321444426">&lt;em>The
Art of Software Security Assessment&lt;/em>&lt;/a>, by Mark Dowd, John McDonald, and
Justin Schuh. A thorough guide to theory and practice.&lt;/p></description><author>Chris Palmer</author><guid>2013/08/11/autodidact-software-engineering-bibliography/index.html</guid><pubDate>Sun, 11 Aug 2013 00:00:00 +0000</pubDate></item><item><title>Good Music Lately</title><link>https://noncombatant.org/2013/07/07/recommended-listening-good-music-lately/index.content</link><description>&lt;h1>Good Music Lately&lt;/h1>

&lt;p>&lt;time>7 July 2013&lt;/time>&lt;/p>

&lt;p>In no particular order, here is some music I have enjoyed lately. If you like
it too, buy it!&lt;/p>

&lt;p>There’s Talk: “&lt;a
href="https://therestalk.bandcamp.com/album/tiny-strands">The Salt&lt;/a>” single,
from the forthcoming &lt;em>Tiny Strands&lt;/em> EP. Intense and stunning. You won’t
know what happened, exactly, but you’ll feel it.&lt;/p>

&lt;p>Shannon Curtis: &lt;a
href="https://shannoncurtis.bandcamp.com/album/cinemascope">&lt;em>Cinemascope&lt;/em>&lt;/a>.
Electro-pop love songs. Highlights: the touching “When the Lights Go Down”,
“Keep Swimming”.&lt;/p>

&lt;p>Deerhoof: &lt;a href="https://deerhoof.bandcamp.com/album/milk-man">&lt;em>Milk
Man&lt;/em>&lt;/a>. Lyrical themes: milk, bananas, strawberries, white-knuckled
terror. Every song is a Casey Kasem-approved hit, but the instrumentals are
especially nice to have. Highlights: “Milk Man”, “Desapareceré”, “C”.&lt;/p>

&lt;p>Kodacrome: “&lt;a href="http://emailunlock.com/kodacrome/strike-the-gold">Strike
the Gold&lt;/a>” single. Chill synth-pop that takes an unexpected turn.&lt;/p>

&lt;p>&lt;a href="https://blottedscience.bandcamp.com/">Blotted Science&lt;/a>: &lt;em>The
Machinations of Dementia&lt;/em> and &lt;em>The Animation of Entomology&lt;/em>.
Technical instrumental metal, thankfully without vocals. Not surprisingly, &lt;a
href="https://www.youtube.com/watch?v=jpoL0QBKxHA">metal is an ideal context for
serialism&lt;/a>.&lt;/p>

&lt;p>Go Van Gogh: &lt;a
href="https://govangogh.bandcamp.com/album/now-we-know">&lt;em>Now We
Know&lt;/em>&lt;/a>. Eclectic mix of fun jams from &lt;a
href="http://www.walkershaw.com/">local shirt-maker Walkershaw Man&lt;/a>.&lt;/p>

&lt;p>Built for the Sea: &lt;a
href="https://liarose.bandcamp.com/album/built-for-the-sea">&lt;em>Built for the
Sea&lt;/em>&lt;/a>. Featuring Lia Rose on vocals. A particularly well-recorded album.
Highlights: “My Dear”, “Paper Tigers”.&lt;/p>

&lt;p>Shudder to Think: &lt;em>Live From Home&lt;/em>. One of my favorite art?-rock?
bands reconvened for an excellent live recording. Squalls of noise-melody and
uncountable meters delivered with songy aplomb. Highlights: Every minute.&lt;/p></description><author>Chris Palmer</author><guid>2013/07/07/recommended-listening-good-music-lately/index.html</guid><pubDate>Sun, 07 Jul 2013 00:00:00 +0000</pubDate></item><item><title>Hear Tall Sheep On Baghdad By The Bay</title><link>https://noncombatant.org/2013/06/30/hear-tall-sheep-on-baghdad-by-the-bay/index.content</link><description>&lt;h1>Hear Tall Sheep On Baghdad By The Bay&lt;/h1>

&lt;p>&lt;time>30 June 2013&lt;/time>&lt;/p>

&lt;p>LD, Jeremy, and I represented &lt;a
href="http://radiovalencia.fm/podcasts/?episode=11014">Tall Sheep on Baghdad by
the Bay&lt;/a>, a radio show on local pirate radio station &lt;a
href="http://radiovalencia.fm/">Radio Valencia&lt;/a>. Stream or download!&lt;/p></description><author>Chris Palmer</author><guid>2013/06/30/hear-tall-sheep-on-baghdad-by-the-bay/index.html</guid><pubDate>Sun, 30 Jun 2013 00:00:00 +0000</pubDate></item><item><title>Software Itself Is A Process, Not A Product</title><link>https://noncombatant.org/2013/06/18/software-itself-is-a-process-not-a-product/index.content</link><description>&lt;h1>Software Itself Is A Process, Not A Product&lt;/h1>

&lt;p>&lt;time>18 June 2013&lt;/time>&lt;/p>

&lt;p>...or, “there is no such thing as &lt;a
href="https://wiki.ubuntu.com/LTS">LTS&lt;/a>.”&lt;/p>

&lt;p>Bruce Schneier says that “&lt;a
href="http://www.schneier.com/essay-062.html">security is a process, not a
product&lt;/a>,” meaning that it is an engineering discipline that you must
continually practice, rather than a magic box you can buy. It is becoming
increasingly clear that this is true for software in general: software is not a
fixed thing that you acquire once, but a service or distribution that is &lt;a
href="https://en.wikipedia.org/wiki/Rolling_release">continually updated&lt;/a>.&lt;/p>

&lt;p>Software is a living cultural artifact, a constant dialog between developers
and users.&lt;/p>

&lt;p>It might seem attractive (cheaper, or easier) to treat software as a finished
product. However, old software — that is, any version of a program other than
the latest stable version — is latent &lt;a
href="https://en.wikipedia.org/wiki/Technical_debt">technical debt&lt;/a>. It tends
to be unsafe, unstable, and to lack features that you might find you need. Worse
— much worse — you will come to rely on old APIs and interfaces, and then when
you are absolutely forced to upgrade in a year or 5 from now, all that latent
technical debt will hit you in the face. The giant migration to a new set of
interfaces/features/bugs will be much more painful than all the small migrations
combined. What seemed easy or cheap at first becomes catastrophically and
unnecessarily expensive. Some of the absolute worst software I ever saw as a
security engineering consultant was creepy, freaky old mainframe goatware from
1964. The organizations that paid IBM through the nose to keep it on life
support insisted it was “really stable, man”, but in fact its prehistoric
limitations contributed magnificently to grave and absurd unnecessary risk.&lt;/p>

&lt;p>One of the most famous examples of treating software as a finishable,
finished product is the &lt;a href="http://cr.yp.to/qmail.html">qmail mail server
by Dan Bernstein&lt;/a>. You couldn’t hope for a better test case of the concept:
ground-breaking design, wonderful performance, and &lt;a
href="http://cr.yp.to/qmail/guarantee.html">admirable security quality&lt;/a>.
Bernstein achieved all this, and &lt;a
href="http://cr.yp.to/qmail/qmailsec-20071101.pdf">considered his work
done&lt;/a>. The trouble is, the needs of the email-using community changed. We
wanted SPF and &lt;a href="https://en.wikipedia.org/wiki/DomainKeys">Domain
Keys&lt;/a>, IPv6, and a &lt;a href="http://qmail.org/top.html#addons">whole pile more
stuff&lt;/a>. There is no guarantee that all the third party add-ons that make
qmail viable in the modern world rise to the same level of quality as the
original core, since it lost its technical leadership. It’s abandonware on life
support, just like the mainframe dinosaur sadness.&lt;/p>

&lt;p>Another example is &lt;a
href="http://www.ctan.org/tex-archive/systems/knuth/dist/tex">Donald Knuth’s
TeX&lt;/a> mathematical typesetting system, like qmail the product of a computing
science giant. Knuth admits the eternal imperfection of TeX by using the digits
of pi for version numbers — the current version is 3.1415926 — but in fact the
core TeX has not been updated in many years. It’s still implemented in &lt;a
href="https://en.wikipedia.org/wiki/WEB">a language that generates Pascal&lt;/a>,
itself an obsolete language that must first be translated into C for use on
modern machines. All new functionality comes from ever more crufty, slow, hard
to use, and weirdly-designed layers upon layers of third-party add-ons and
wrappers.&lt;/p>

&lt;p>These are undeniable works of genius, laid low by the belief that they could
be finished products, rather than created with recognition that they must evolve
with their users. Software is simply not like other art forms.&lt;/p>

&lt;p>This is not to say that a program’s original developer must be chained to the
task of maintaining it forever; only to illustrate the point that developers and
users must plan for software to change continually to meet changing needs.&lt;/p></description><author>Chris Palmer</author><guid>2013/06/18/software-itself-is-a-process-not-a-product/index.html</guid><pubDate>Tue, 18 Jun 2013 00:00:00 +0000</pubDate></item><item><title>Biscuits By Living Colour</title><link>https://noncombatant.org/2013/06/15/recommended-listening-biscuits-by-living-colour/index.content</link><description>&lt;h1>&lt;em>Biscuits&lt;/em> By Living Colour&lt;/h1>

&lt;p>&lt;time>15 June 2013&lt;/time>&lt;/p>

&lt;p>Living Colour was and is a challenging, ground-breaking rock band. They take
 a lot of musical and stylistic risks, and almost never miss. Their
 masterpiece, &lt;em>Time’s Up&lt;/em>, is one of the greatest rock albums of all time,
 but today I recommend &lt;a href="https://en.wikipedia.org/wiki/Biscuits_(EP)">the
 Japanese import of &lt;em>Biscuits&lt;/em>&lt;/a>, an EP they released in the &lt;em>Time’s
 Up&lt;/em> era. (Be sure to get the Japanese import; the US release is wonderful
 but the Japanese version has 9 more tracks.)&lt;/p>

&lt;p>A treasure trove of B-sides, covers, and live
 tracks, &lt;em>Biscuits&lt;/em> documents this limit-ignoring, virtuosic, and soulful
 band in one of their most creative phases. Living Colour always expand the
 harmonic and melodic possibilities available in rock music, and listening to
 their live tracks you can hear them spontaneously invent something new and
 beautiful again and again.&lt;/p>

&lt;p>There are some great Living Colour originals on &lt;em>Biscuits&lt;/em>. Highlights
 for me are the insane guitar and drum duet/breakdown in “Money Talks”, and the
 live version of “Information Overload” which will bend your ear. Here is an
 excerpt of the “&lt;a href="https://en.wikipedia.org/wiki/Neuromancer">Wintermute&lt;/a> going insane”
 guitar intro:&lt;/p>

&lt;audio controls>
 &lt;source src="information-overload-excerpt-live.mp3" />
 &lt;a href="information-overload-excerpt-live.mp3">Download&lt;/a>
&lt;/audio>

&lt;p>Living Colour has always done great covers, and &lt;em>Biscuits&lt;/em> has some
 true gems, like Pere Ubu’s “Final Solution” and an incredible rip on Talking
 Heads’ “Memories Can’t Wait”. None of the covers are mere remakes; Living Colour
 always shows a new dimension to an old song, and always renews a sense of wonder
 about what music can make possible. My favorite cover from &lt;em>Biscuits&lt;/em> is
 Al Green’s “Love and Happiness”, because vocalist Corey Glover opens all the way
 up and does the song true justice:&lt;/p>

&lt;audio controls>
 &lt;source src="love-and-happiness-excerpt.mp3" />
 &lt;a href="love-and-happiness-excerpt.mp3">Download&lt;/a>
&lt;/audio>

&lt;p>As David Letterman said, &lt;a href="https://www.youtube.com/watch?v=WhMuGPMzvS8">“If this song don’t drop ya,
 then yer not hooked up right.”&lt;/a>&lt;/p>

&lt;p>&lt;a
 href="https://www.amazon.com/Biscuits-Living-Colour/dp/B00004VP0N/ref=sr_1_fkmr1_1?ie=UTF8&amp;amp;qid=1371186402&amp;amp;sr=8-1-fkmr1&amp;amp;keywords=living+colour+biscuits+japanese+import">Only
 1 left in stock at Amazon&lt;/a>! And yes, it is worth every penny.&lt;/p></description><author>Chris Palmer</author><guid>2013/06/15/recommended-listening-biscuits-by-living-colour/index.html</guid><pubDate>Sat, 15 Jun 2013 00:00:00 +0000</pubDate></item><item><title>Homebrew Harmony: The Oblique Blues Scale</title><link>https://noncombatant.org/2013/06/15/homebrew-harmony-the-oblique-blues-scale/index.content</link><description>&lt;h1>Homebrew Harmony: The Oblique Blues Scale&lt;/h1>

&lt;p>&lt;time>15 June 2013&lt;/time>&lt;/p>

&lt;p>Lately I’ve been interested in scales that contain clusters of half-steps.
 Obviously, the Minor Blues scale (A C D E♭ E G) is a well-known member of that
 family, but many others are possible. For example, I call this one the Oblique
 Blues scale, because its blue note sneaks up on you:&lt;/p>

&lt;p>&lt;em>A B C D E F G♭&lt;/em>&lt;/p>

&lt;audio controls>
 &lt;source src="oblique-blues-scale.mp3" />
 &lt;a href="oblique-blues-scale.mp3">Download&lt;/a>
&lt;/audio>

&lt;p>Perhaps it has an older name, but to me it’s Oblique Blues. As you can see,
 it’s just like A minor except that its 7th is diminished (G♭); you can also
 think of it as C major with a diminished 5th (G♭). The cluster of half-steps is
 E F G♭.&lt;/p>

&lt;p>Tweaking that one note generates some really interesting chords:&lt;/p>

&lt;p>
 Am: &lt;em>A C E&lt;/em>&lt;br />
 Am (diminished 7): &lt;em>A C E G♭&lt;/em>&lt;br />
 Bo: &lt;em>B D F&lt;/em>&lt;br />
 Bø7: &lt;em>B D F A&lt;/em>&lt;br />
 &lt;strong>C (♭5): &lt;em>C E G♭&lt;/em>&lt;br />
 Cmaj7 (♭5): &lt;em>C E G♭ B&lt;/em>&lt;/strong>&lt;br />
 Dm: &lt;em>D F A&lt;/em>&lt;br />
 Dm7: D F A C&lt;br />
 &lt;strong>E (dim 3): &lt;em>E G♭ B&lt;/em>&lt;br />
 E7 (dim 3): &lt;em>E G♭ B D&lt;/em>&lt;/strong>&lt;br />
 F: &lt;em>F A C&lt;/em>&lt;br />
 Fmaj7: &lt;em>F A C E&lt;/em>&lt;br />
 &lt;strong>G♭(aug 3): &lt;em>G♭ B D&lt;/em>&lt;br />
 G♭maj7 (aug 3): &lt;em>G♭ B D F&lt;/em>&lt;/strong>
&lt;/p>

&lt;audio controls>
 &lt;source src="oblique-blues-chords.mp3" />
 &lt;a href="oblique-blues-chords.mp3">Download&lt;/a>
&lt;/audio></description><author>Chris Palmer</author><guid>2013/06/15/homebrew-harmony-the-oblique-blues-scale/index.html</guid><pubDate>Sat, 15 Jun 2013 00:00:00 +0000</pubDate></item><item><title>Playing With Tall Sheep At Bottom Of The Hill In SF</title><link>https://noncombatant.org/2013/06/14/playing-with-tall-sheep-at-bottom-of-the-hill-in-sf/index.content</link><description>&lt;h1>Playing With Tall Sheep At Bottom Of The Hill In SF&lt;/h1>

&lt;p>&lt;time>14 June 2013&lt;/time>&lt;/p>

&lt;p>I’m super-excited to play at &lt;a href="http://www.bottomofthehill.com/">Bottom
of the Hill&lt;/a> with Tall Sheep on 26 June! We’re opening for &lt;a
href="http://valleysvalleys.bandcamp.com/">Valleys&lt;/a> and &lt;a
href="http://weeknightmusic.bandcamp.com/">Weeknight&lt;/a>.&lt;/p>

&lt;figure>&lt;img alt="Flyer for Valleys, Weeknight, and Tall Sheep at Bottom Of The
Hill" src="tall-sheep-both-flyer.jpg" width="800" height="1127"
loading="lazy"/>&lt;figcaption>&lt;/figcaption>&lt;/figure></description><author>Chris Palmer</author><guid>2013/06/14/playing-with-tall-sheep-at-bottom-of-the-hill-in-sf/index.html</guid><pubDate>Fri, 14 Jun 2013 00:00:00 +0000</pubDate></item><item><title>Some Pics From The Tall Sheep EP Release Show</title><link>https://noncombatant.org/2013/06/13/some-pics-from-the-tall-sheep-ep-release-show/index.content</link><description>&lt;h1>Some Pics From The Tall Sheep EP Release Show&lt;/h1>

&lt;p>&lt;time>13 June 2013&lt;/time>&lt;/p>

&lt;p>This past May 5th, my band Tall Sheep played a show at &lt;a
href="http://www.cafedunord.com/">Cafe du Nord in SF&lt;/a> to celebrate the
release of our new EP, &lt;a href="http://tallsheep.bandcamp.com/">&lt;em>Of Birds In
Propellers&lt;/em>&lt;/a>. &lt;a href="http://lofisymphony.com/">Major Powers and the
Lo-Fi Symphony&lt;/a> and Taxes were nice enough to play with us. It was a great
show! Our good friend Kate McKinley took some pictures. Thanks Kate!&lt;/p>

&lt;p>Personnel: Brad Harbidge (drums); me (bass and guitar); LD Dean (guitar and
vocals); Jeremy Anderson (keys). Brad also played on the recording, which we did
at the wonderful &lt;a href="http://tinytelephone.com/">Tiny Telephone in San
Francisco&lt;/a>. I love playing in a rhythm section with Brad!&lt;/p>

&lt;figure>&lt;img loading="lazy" alt="Tall Sheep EP 2013-05-05 07"
src="tallsheepep-2013050507.jpg" width="800"
height="533"/>&lt;figcaption>&lt;/figcaption>&lt;/figure>

&lt;figure>&lt;img loading="lazy" alt="Tall Sheep EP 2013-05-05 01"
src="tallsheepep-2013050501.jpg" width="800"
height="533"/>&lt;figcaption>&lt;/figcaption>&lt;/figure>

&lt;figure>&lt;img loading="lazy" alt="Tall Sheep EP 2013-05-05 02"
src="tallsheepep-2013050502.jpg" width="800"
height="800"/>&lt;figcaption>&lt;/figcaption>&lt;/figure>

&lt;figure>&lt;img loading="lazy" alt="Tall Sheep EP 2013-05-05 03"
src="tallsheepep-2013050503.jpg" width="800"
height="533"/>&lt;figcaption>&lt;/figcaption>&lt;/figure>

&lt;figure>&lt;img loading="lazy" alt="Tall Sheep EP 2013-05-05 04"
src="tallsheepep-2013050504.jpg" width="800"
height="800"/>&lt;figcaption>&lt;/figcaption>&lt;/figure>

&lt;figure>&lt;img loading="lazy" alt="Tall Sheep EP 2013-05-05 05"
src="tallsheepep-2013050505.jpg" width="800"
height="1200"/>&lt;figcaption>&lt;/figcaption>&lt;/figure>

&lt;figure>&lt;img loading="lazy" alt="Tall Sheep EP 2013-05-05 06"
src="tallsheepep-2013050506.jpg" width="800"
height="800"/>&lt;figcaption>&lt;/figcaption>&lt;/figure>

&lt;figure>&lt;img loading="lazy" alt="Tall Sheep EP 2013-05-05 08"
src="tallsheepep-2013050508.jpg" width="800"
height="800"/>&lt;figcaption>&lt;/figcaption>&lt;/figure></description><author>Chris Palmer</author><guid>2013/06/13/some-pics-from-the-tall-sheep-ep-release-show/index.html</guid><pubDate>Thu, 13 Jun 2013 00:00:00 +0000</pubDate></item><item><title>Simple Computer Security</title><link>https://noncombatant.org/2013/06/02/simple-computer-security/index.content</link><description>&lt;h1>Simple Computer Security&lt;/h1>

&lt;p>&lt;time>2 June 2013&lt;/time>&lt;/p>

&lt;p>&lt;strong>Don’t panic.&lt;/strong> The internet is far, far more valuable than it
is dangerous. In general, internet security is about pushing down the cost of
unnecessary losses and increasing the overall value of the network. This work is
done in the margins; in the big picture, the internet is a clear win. “Cyber”
alarmism is serving somebody — but not you.&lt;/p>

&lt;p>&lt;strong>Redundancy and backup.&lt;/strong> Have a spare machine, a spare network
connection, a secondary email service, or whatever is most important to you.
Have a backup plan &lt;em>that you have actually tested&lt;/em>. (For example, set up
your spares by restoring your backups on to them.) In case of any problem —
loss, theft, hacking, fire, whatever — you will need a fresh system with minimal
disruption.&lt;/p>

&lt;p>&lt;strong>Isolation and compartmentalization.&lt;/strong> Separate your different
sources of data, and separate your different activities. For example, separate
your work computing from your personal computing; separate your military secrets
from your iTunes; separate your digital audio workstation from the guest
computer in your lobby. To combine activities of different degrees of importance
onto one machine is unnecessarily risky, now that computers are so cheap.&lt;/p>

&lt;p>&lt;strong>Keep it simple. Keep it updated.&lt;/strong> Stick with the &lt;em>latest
stable version&lt;/em> of a &lt;em>small number of programs&lt;/em> that you &lt;em>really
need&lt;/em> from a &lt;em>small number of well-established vendors&lt;/em>. If a
platform or app gets updates only rarely or if updating is hard, that is a
severe danger sign. (The current industry standard is that updates arrive
monthly and install in one or two clicks; expect updates to become more frequent
and easier as engineering improves.) Avoid ‘supplementing’ the platform with
software from third-party vendors: avoid plug-ins, extensions, and
pseudo-security utilities like anti-virus software or firewalls.&lt;/p>

&lt;p>&lt;strong>Avoid complexity and distrust magic.&lt;/strong> Prefer tools you
understand and are comfortable with, whatever your level of understanding is.
Resist pressure to adopt complicated recipes, and reject claims like “Product X
will make you safe from Problem Y!”&lt;/p>

&lt;p>&lt;strong>You might need a professional.&lt;/strong> You may have specialized
needs, a particularly acute threat model or dangerous threat actor, or be in
some crisis. In that case, a blog post is not going to be sufficient for you,
and you may need specialized advice/tools/techniques that only a professional
can provide.&lt;/p></description><author>Chris Palmer</author><guid>2013/06/02/simple-computer-security/index.html</guid><pubDate>Sun, 02 Jun 2013 00:00:00 +0000</pubDate></item><item><title>My Favorite Music Of 2012</title><link>https://noncombatant.org/2013/01/01/my-favorite-music-of-2012/index.content</link><description>&lt;h1>My Favorite Music Of 2012&lt;/h1>

&lt;p>&lt;time>1 January 2013&lt;/time>&lt;/p>

&lt;p>These are just some highlights off the top of my head.&lt;/p>

&lt;p>&lt;em>&lt;a
href="https://bukeandgase.bandcamp.com/album/function-falls-ep">Function
Falls&lt;/a>&lt;/em> by &lt;a href="http://www.bukeandgase.com/">Buke and Gase&lt;/a>.
Home-brew electro-acoustic instruments with a penchant for digital pitch
shifters, and a strong beautiful voice. All of their records are available on
Bandcamp!&lt;/p>

&lt;p>&lt;a href="https://en.wikipedia.org/wiki/Koloss">&lt;em>Koloss&lt;/em>&lt;/a> by &lt;a
href="http://www.meshuggah.net/">Meshuggah&lt;/a>. Still the masters of metal
minimalism and/or Bootsy Collins-inspired funk bass. Hits: “Do Not Look Down”,
“Marrow”, “Break Those Bones Whose Sinews Gave It Motion”, all the other tracks.
Killer live show (with Decapitated and Baroness opening!).&lt;/p>

&lt;p>&lt;a href="http://lovethisgiant.com/">&lt;em>Love This Giant&lt;/em>&lt;/a> by &lt;a
href="http://www.ilovestvincent.com/">St. Vincent&lt;/a> and &lt;a
href="http://journal.davidbyrne.com/">David Byrne&lt;/a>. Fresh arrangements and
instrumentation, and great vocal dialogues. St. Vincent is as awesome a singer
as she is a guitarist.&lt;/p>

&lt;p>&lt;a
href="http://www.nonesuch.com/journal/jonny-greenwoods-the-master-soundtrack-out-now-uk-superb-times-extraordinary-daily-telegraph-2012-11-05">&lt;em>The
Master&lt;/em> soundtrack&lt;/a> by Jonny Greenwood. Also &lt;a
href="http://www.nonesuch.com/journal/krzysztof-penderecki-jonny-greenwood-album-stereophile-album-month-spoleto-festival-2012-05-31">this
weird gem&lt;/a> with Krzysztof Penderecki. Narrative and space. Try and buy these
at the &lt;a href="http://www.nonesuch.com/store/jonny-greenwood">online
store&lt;/a>.&lt;/p>

&lt;p>Non-2012 music that I especially loved in 2012:&lt;/p>

&lt;p>Everything by &lt;a
href="http://www.sarahlipstate.com/wordpress/">Noveller&lt;/a> (Sarah Lipstate).
Guitar loops, noise, landscapes. You can get all her stuff on &lt;a
href="https://noveller.bandcamp.com/">Bandcamp&lt;/a>.&lt;/p>

&lt;p>The out-of-print Japanese import of Living Colour’s &lt;em>Biscuits&lt;/em>. So
many awesome live tracks.&lt;/p>

&lt;p>&lt;a href="https://en.wikipedia.org/wiki/Carnival_Is_Forever">&lt;em>Carnival is
Forever&lt;/em>&lt;/a> by &lt;a href="http://www.decapitatedband.net/">Decapitated&lt;/a>. A
triumphant and inventive return from personal tragedy.&lt;/p></description><author>Chris Palmer</author><guid>2013/01/01/my-favorite-music-of-2012/index.html</guid><pubDate>Tue, 01 Jan 2013 00:00:00 +0000</pubDate></item><item><title>My Review Of Distrust That Particular Flavor On io9</title><link>https://noncombatant.org/2012/01/10/my-review-of-distrust-that-particular-flavor-on-io9/index.content</link><description>&lt;h1>My Review Of &lt;em>Distrust That Particular Flavor&lt;/em> On io9&lt;/h1>

&lt;p>&lt;time>10 January 2012&lt;/time>&lt;/p>

&lt;p>io9 published &lt;a
href="https://io9.gizmodo.com/5874889/distrust-that-particular-flavor-reveals-how-autobiographical-william-gibsons-fiction-is">my
review of William Gibson’s essay collection &lt;em>Distrust That Particular
Flavor&lt;/em>&lt;/a>.&lt;/p>

&lt;blockquote>William Gibson is one of our finest science fiction authors, because
he knows that people are the strangest products science has ever produced. And
his new essay collection, &lt;em>Distrust That Particular Flavor&lt;/em>, gives us
insight into how he came to understand that so well, when many other SF authors
struggle to see it.&lt;/blockquote></description><author>Chris Palmer</author><guid>2012/01/10/my-review-of-distrust-that-particular-flavor-on-io9/index.html</guid><pubDate>Tue, 10 Jan 2012 00:00:00 +0000</pubDate></item><item><title>Eternal Truths Of Software</title><link>https://noncombatant.org/2011/03/20/eternal-truths-of-software/index.content</link><description>&lt;h1>Eternal Truths Of Software&lt;/h1>

&lt;p>&lt;time>20 March 2011&lt;/time>&lt;/p>

&lt;p>The discipline of software engineering is young. Although &lt;a href="https://en.wikipedia.org/wiki/Ada_Lovelace">Lady
 Ada&lt;/a> got us started in
 1842 – 1843, it was not until the 1940s that people began programming computers
 in earnest, and it was some decades before we got any systems that would
 survive. Although we do not yet know very much about how to make software, we do
 know a few things that are likely to guide us into the future.&lt;/p>

&lt;p>“When in doubt, use brute force.” (&lt;a href="https://en.wikipedia.org/wiki/Ken_Thompson">Ken Thompson&lt;/a>) “These
 days,
 though, you have to be pretty technical before you can even aspire to
 crudeness.” (&lt;a href="http://www.williamgibsonbooks.com/">William Gibson&lt;/a>,
 in &lt;em>Johnny Mnemonic&lt;/em>)&lt;/p>

&lt;p>“C programmers know the cost of everything and the value of nothing” (&lt;a
 href="http://discuss.fogcreek.com/joelonsoftware/default.asp?cmd=show&amp;amp;ixPost=53978">unknown&lt;/a>),
 while “Lisp programmers know the value of everything and the cost of nothing.”
 (Alan Perlis) However, “We should forget about small efficiencies, say about 97%
 of the time: premature optimization is the root of all evil.” (&lt;a
 href="https://en.wikipedia.org/wiki/Donald_Knuth">Donald Knuth&lt;/a>)&lt;/p>

&lt;p>Because “software engineering is programming integrated over time” (&lt;a
 href="https://www.oreilly.com/library/view/software-engineering-at/9781492082781/ch01.html#:~:text=Within%20Google%2C%20we%20sometimes%20say,software%20in%20the%20first%20place.">Titus
 Winters&lt;/a>) and because computing science predates and will outlast computers,
 “Programs should be written for people to read, and only incidentally for
 machines to execute.” (&lt;a href="https://web.mit.edu/6.001/6.037/sicp.pdf">Harold
 Abelson and Gerald Jay Sussman&lt;/a>)&lt;/p>

&lt;p>Problem Exists Between Keyboard And Chair (PEBKAC). Although novice engineers
 believe this dictum applies to users, experienced engineers know that it applies
 to engineers. This is because “There are two ways of constructing a software
 design; one way is to make it so simple that there are obviously no
 deficiencies, and the other way is to make it so complicated that there are no
 obvious deficiencies. The first method is far more difficult.” (&lt;a
 href="https://en.wikipedia.org/wiki/C._A._R._Hoare">C. A. R. Hoare&lt;/a>) “A
 specification that cannot be fit on one 8.5 x 11 inch piece of paper cannot be
 understood.” (&lt;a href="http://wwwuser.csse.rose-hulman.edu/~ardis/">Mark
 Ardis&lt;/a>)&lt;/p>

&lt;p>Software security is a process, not a product (&lt;a href="https://www.schneier.com/crypto-gram-0005.html">Bruce
 Schneier&lt;/a>), but
 &lt;a href="/2013/06/18/software-itself-is-a-process-not-a-product/">that is true
 of software generally&lt;/a>. Attempts to freeze software in time and make it into
 a finished product have increasingly lower viability over time. “Have one joint
 and keep it well oiled.” (&lt;a href="https://www.imperialviolet.org/2016/05/16/agility.html">Adam
 Langley&lt;/a>)
&lt;/p></description><author>Chris Palmer</author><guid>2011/03/20/eternal-truths-of-software/index.html</guid><pubDate>Sun, 20 Mar 2011 00:00:00 +0000</pubDate></item><item><title>This Place Is Heaven, If You’ll Just Listen</title><link>https://noncombatant.org/2004/01/24/this-place-is-heaven-if-youll-just-listen/index.content</link><description>&lt;h1>This Place Is Heaven, If You’ll Just Listen&lt;/h1>

&lt;p>&lt;time>24 January 2004&lt;/time>&lt;/p>

&lt;p>On the way home from the grocery store just now, I was stopped at a red
light at Market and Castro. Market is quite wide at this point, and the walk
light never lasts long enough for you to get all the way across. A woman was
jogging to get across in time, and with her plastic shopping bag, she
acheived two perfect bars of music.&lt;/p>

&lt;figure>&lt;img alt="Hurrying Woman Clave" src="hurrying-woman-clave.jpg"
loading="lazy" width="801" height="285"/>&lt;figcaption>Hurrying Woman
Clave&lt;/figcaption>&lt;/figure>

&lt;p>It’s a fast, slightly modified 3 – 2 &lt;a
href="http://en.wikipedia.org/wiki/Clave_%28rhythm%29">clave&lt;/a>. After the
first phrase her steps got longer and slower, and the shopping bag dangled
arrythmically. Then the light turned green.&lt;/p></description><author>Chris Palmer</author><guid>2004/01/24/this-place-is-heaven-if-youll-just-listen/index.html</guid><pubDate>Sat, 24 Jan 2004 00:00:00 +0000</pubDate></item></channel></rss>